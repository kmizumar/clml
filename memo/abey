＜阿部（裕）　進捗状況＞ 　（最終更新日:2010/9/13)

(9/13)東北大介護記録データのトピック抽出

・最終的にやりたいこと:トピックの時系列変化を捉えて、ある要介護者の危険な兆候が予測できるとよい。

・現状の問題点
　
  BOW行列のサイズが大きい。154MBほど。CLMLで疎行列が扱えないか？->現状では未対応。
　さしあたり、記事に対応する行を何らかの時間的観点から統合・絞り込みをして行数を減らす。
　->日付で統合。さらに、月単位あるいは上半期・下半期等で絞り込む。

　語彙選択についても改良の余地あり。副詞・形容詞は不要？
　頻出語彙も、稀すぎる語彙も特徴抽出の上では役に立たないので、適切な基準をある程度試行錯誤で見つける必要あり。
　なお、列に相当する語彙の選択は、行に相当するものを決定してから行った方が、ゼロ行・ゼロ列問題を回避できるように思われる。

　おそらく、行を「どのような観点」で統合・絞り込むかが介護記録データの解析では焦点になる。

・派生してでてきた話題

　1.観察者で記事を絞り込んで、バイアスを浮き上がらせる、という解析案。

　2.体温・血圧などの数値データや他の属性データも、自由記述文データ以外にある。
　　これらを組み合わせて統合的に扱う枠組みがつくれないか。->できるとすごい。

現状での機械学習は、人間にできるパターン認識を機械が模倣して高速・大量に処理できるところに、その価値のほとんどがあるのではないか。
人間にはできない真に新しい知見や予測ができるといいのだが。とはいえ、現状では介護の現場で介護者が「あの人はそろそろ危ない
(転倒して骨折でもしそう)」と漠然と感じているようなパターン認識を機械がうまく模倣できるだけでも、かなり価値はあるように思う。
ただこのケースでも、自由記述文データの(NMFやHDP-LDAによる)分析ではなく、自由記述文データを用いた予測、という難しい問題になる。


(9/10)Random-Forestベンチマーク

bc-trainおよびirisデータセットを用いてRandom-Forestの計算速度を比較した。
そのうち、bc-trainのログを残しておく。

;;single
RANDOM-FOREST(7): (time (make-random-forest *bc-train* "Class"))
; While compiling (:INTERNAL (:ANONYMOUS-LAMBDA 26) 0):
Warning: Free reference to undeclared variable *BC-TRAIN* assumed special.
; cpu time (non-gc) 3.618450 sec user, 0.228966 sec system
; cpu time (gc)     0.538918 sec user, 0.007998 sec system
; cpu time (total)  4.157368 sec user, 0.236964 sec system
; real time  4.418353 sec
; space allocation:
;  57,980,146 cons cells, 452,093,744 other bytes, 0 static bytes

;;with fork-future
RANDOM-FOREST(6): (time (make-random-forest *bc-train* "Class"))
; While compiling (:INTERNAL (:ANONYMOUS-LAMBDA 24) 0):
Warning: Free reference to undeclared variable *BC-TRAIN* assumed special.
; Autoloading for MAKE-TWO-WAY-STREAM:
; Autoloading for MAKE-TWO-WAY-STREAM:
; Autoloading for MAKE-TWO-WAY-STREAM:
; Autoloading for MAKE-TWO-WAY-STREAM:
; Fast loading from bundle code/streama.fasl.
; Fast loading from bundle code/streama.fasl.
; Fast loading from bundle code/streama.fasl.
; Fast loading from bundle code/streama.fasl.
; Autoloading for EXCL::GRAY-OPEN:
; Fast loading /local_home/acl82.64/code/streamc.002
;;; Installing streamc patch, version 2.
;   Fast loading from bundle code/efft-932-base.fasl.
;   Fast loading from bundle code/efft-emacs-mule-base.fasl.
;   Fast loading from bundle code/efft-euc-base.fasl.
;   Fast loading from bundle code/efft-utf8-base.fasl.
;   Fast loading from bundle code/efft-void.fasl.
;   Fast loading from bundle code/efft-latin1-base.fasl.
; cpu time (non-gc) 0.636903 sec user, 0.046993 sec system
; cpu time (gc)     0.000000 sec user, 0.000000 sec system
; cpu time (total)  0.636903 sec user, 0.046993 sec system
; real time  2.240699 sec
; space allocation:
;  804,490 cons cells, 65,207,392 other bytes, 0 static bytes

;;R
> system.time(randomForest(Class~.,bc.train))
   ユーザ　　　　システム　　経過
     0.209      0.011      0.222 


(7/26)日立CLSデータの解析(2)

145万件の学習用データからランダムサンプリングによって少数のデータからなる学習用データセット(小)をつくり、
rbf-kernelでgamma=0.5, c=1で学習させた。
また145万件のうち、約2パーセントをテストデータとして用い、サンプリングの比率を変えて精度を測定した。


<全体の1パーセントをランダムサンプリングして得た学習用データセットの場合>
SVM.WSS3(123): (svm-validation * test-vector)
(((-1.0 . 1.0) . 366) ((-1.0 . -1.0) . 3070) ((1.0 . -1.0) . 159) ((1.0 . 1.0) . 25600))
98.2017468744648;;Accracy = (28670/29195)


<全体の5パーセントをランダムサンプリングして得た学習用データセットの場合>
SVM.WSS3(130): (svm-validation * test-vector)
(((-1.0 . 1.0) . 377) ((1.0 . -1.0) . 122) ((-1.0 . -1.0) . 3107) ((1.0 . 1.0) . 25589))
98.29080321972941;;Accracy = (28696/29195)


<全体の10パーセントをランダムサンプリングして得た学習用データセットの場合>
SVM.WSS3(139): (svm-validation * test-vector)
(((-1.0 . 1.0) . 378) ((1.0 . -1.0) . 104) ((-1.0 . -1.0) . 3125) ((1.0 . 1.0) . 25588))
98.34903236855625;;Accuracy = (28713/29195)


<全体の20パーセントをランダムサンプリングして得た学習用データセットの場合>
SVM.WSS3(151): (svm-validation * test-vector)
(((-1.0 . 1.0) . 377) ((1.0 . -1.0) . 95) ((-1.0 . -1.0) . 3134) ((1.0 . 1.0) . 25589))
98.38328480904265;;Accuracy = (28723/29195)


(考察)
まず全体の1パーセントのみを用いて学習させたSVMでも精度がかなり良い（約98.2％）のに驚く。
ALSとは問題が違うので一概には比較できないが、特徴素の選択や前処理が重要であることを痛感する。
ちなみにALSでの判別精度は約94~95%である。

実験の結果では、その後学習データを増やしていけば行くほど、精度がわずかながら向上していく様子が見てとれる。
例えば、10％から20％に学習用データを増やした場合、精度は約0.034向上している。SVMの時間計算量は概ね
O(n^2)なので、学習データ点数が2倍になれば、学習時間は約4倍になる。このケースでは、4倍の学習時間を費やして
約0.034の精度向上（正解件数にして10件の増加）が見合うかどうかの問題になる。
もっとも極端な場合では、1%の学習用データと全件145万件で学習させた場合の学習時間はざっと1万倍にもなる。

以上の結果から、新規学習データがもし得られたとしても、その都度再学習させる意義はきわめて薄いと考える。
(そもそも、145万件の学習用データをすべて使っての学習さえも、やや非効率であろうと私的には思う)。
しかし、もし新規に得られた学習データも反映させたいのであれば以下のような方法も考えられる。
145万件の学習データのうち、サポートベクトルの数は約5万点であり、SVMの学習に必要なのはこれら5万点のデータのみである。
したがって、「サポートベクトル5万点+新規学習データ」を学習データとして再学習させればよい。
これだけでも、再学習時間のかなりの短縮が見込めると思われる。


(7/23)日立CLSデータの解析

<libsvm>
ss.tsv:10次元でデータ行が145万件のデータをlibsvmにかけ、学習時間と判別時間を計測した。
rbfカーネルを用いて、gamma=0.5, c=1.0で学習させた場合、約10時間30分かかった。

[abey@capellini libsvm-2.91]$ time ./svm-train -s 0 -t 2 -g 0.5 -c 1 /local_home/machine-learning/sample/cls-svmFeatureVectors/ss.tsv model
...............................................
optimization finished, #iter = 59106
nu = 0.037682
obj = -52994.328098, rho = 2.210691
nSV = 55016, nBSV = 54445
Total nSV = 55016
37658.188u 9.639s 10:27:54.96 99.9%	0+0k 251712+6096io 1pf+0w

同じデータを用いて判別時間を計測してみたところ、約1時間30分かかった。

[abey@capellini libsvm-2.91]$ time ./svm-predict /local_home/machine-learning/sample/cls-svmFeatureVectors/ss.tsv model result
Accuracy = 98.4312% (1429440/1452222) (classification)
5324.863u 0.769s 1:28:46.77 99.9%	0+0k 0+5680io 0pf+0w


<core vector machine>
CVMは、Ivor W. Tsangらによって提案されたSVMバリアントの一種で、大規模データに対して有効(時間計算量が線形)であるとされているが、
収束判定基準については疑問の声もある。

CVMで145万件のデータを、gamma=0.5, c=1.0 で学習させた結果、約3時間30分かかった。libsvmの結果と比較しても、rho値(分離超平面の切片に相当)及び、
サポートベクトルの数もよく一致している。CVMについては悪い先入観を持っていたが、思ったより悪くないかもしれない。ちなみに並列には動作していない。

[abey@capellini cvm]$ time ./cvm-train_sparse -t 2 -g 0.5 -c 1 /local_home/machine-learning/sample/cls-svmFeatureVectors/ss.tsv model
Gamma 0.5, C = 1
Finished initialization, start optimization
..........................................................................................................................
...........*.....................................*........*
optimization finished, #iter = 176954
nu = 0.037682
obj = -52994.292998, rho = 2.210066
nSV = 55285, nBSV = 54278
Total nSV = 55285
CPU Time = 12164.260000 second
12170.368u 103.916s 3:24:36.62 99.9%	0+0k 0+12296io 0pf+0w

CVMで学習に使ったものと同じデータで判別時間を計測したところ、約1時間30分かかった。
サポートベクトルの数がlibsvmの結果とほぼ同じなので、妥当な結果である。
判別精度もlibsvmで98.4312, cvmで98.4316であり、このデータセットについては、ほぼ同じ精度が出ていることがわかる。

[abey@capellini cvm]$ time ./cvm-predict_sparse /local_home/machine-learning/sample/cls-svmFeatureVectors/ss.tsv model result
element: 608135 pattern: 55285 
Testing Accuracy = 0.9843164474853018 (1429446/1452222) (classification)
CPU Time for prediction = 5801.020000 second
Balanced accuracy = 0.9774625799743668 (classification)

Confusion matrix (#Pos [class 1] = 1293185, #Neg [class 0] = 159037)
                    Predict +ve     Predict -ve
     Target +ve 0.986238627884 0.0137613721161
     Target -ve 0.0313134679351 0.968686532065


Root Mean Squared Error = 0.1252339910515438 (regression)
Mean Absolute Error = 0.01568355251469817 (regression)
Median Absolute	Error = 0 (regression)
Squared	correlation coefficient = 0.8523250192692587 (regression)
5801.390u 0.862s 1:36:43.53 99.9%	0+0k 0+5688io 0pf+0w


今後、CLMLのSVMパッケージでも同じデータを解析していく予定。
具体的には、元の145万件の学習用データから少数のサンプル(5%,10%,20%,...)を抜き出して小さい学習用データをつくり、
判別精度がどのように変化するかを見ていくつもりである。


(7/2)介護ブログからのトピック抽出

Tomyの介護ブログ(http://tomys-kaigo.ldblog.jp/)を多田さんに形態素解析してもらい、
3,4,5,6月分の105エントリ、2012単語をhdp-ldaにかけてトピック抽出を試みた。
この例では比較的わかりやすいトピックが見てとれるように思われる。

<hdp-lda>
(("Topic 1" #("母" "小規模ホーム" "右膝" "状態" "自分" "家" "介護" "ヘルパーさん" "人" "テーピング") . 0.012172973725982505)
 ("Topic 8" #("痰" "抗生剤" "噎せ" "発熱" "看護師" "主治医" "咳" "発生" "肺炎" "対処") . 0.009356100765011872)
 ("Topic 2" #("施設" "利用者" "ケアマネさん" "夏みかん" "変更" "利用" "介護施設" "家族" "スタッフ" "泊まり") . 0.009001139803945749)
 ("Topic 7" #("主治医" "病院" "痛み" "整形外科" "軽減" "負担" "水" "総合病院" "湿布" "レントゲン") . 0.008850082845350066)
 ("Topic 11" #("歯医者" "入れ歯" "歯" "準備" "治療" "根本的" "先生" "良医" "医師" "認知症") . 0.008596977863214703)
 ("Topic 6" #("軸足" "体" "右足" "位置" "上着" "方法" "理学療法士" "肩" "移乗時" "移乗") . 0.00859306021183047)
 ("Topic 4" #("業者" "側溝" "お隣さん" "工事" "修復" "報告" "掃除" "謝り" "介助者" "脱輪") . 0.008592791184808513)
 ("Topic 3" #("尿" "シャワーキャリー" "採取" "処理" "便" "便器" "居間" "タオル" "坊主" "だめ") . 0.008557748877368432)
 ("Topic 5" #("野菜" "ポトフ" "業者さん" "料理" "福祉用具" "カレー粥" "朝食" "定番" "車椅子" "冷凍") . 0.008531844150756165)
 ("Topic 49" #("仕事" "面接" "通い" "両立" "就職" "自分" "制限" "定員オーバー" "フロア" "模索") . 0.008531355334634842))

※単にコーパスからトピックを抽出する段階でもそれなりにノウハウが存在することがわかった。

 BOW行列をつくるさいに、tf*idfスコアでフィルタリングしない方が、hdp-ldaでは良い結果が得られる。
これは、tf*idfスコアの特徴で、各文書にまたがって頻出する語のスコアが低く算出されることによる(term frequency をdocument frequencyで割っているため)。

情報検索のためのベクトル空間モデルでは、tf*idfでフィルタリングしてベクトル化するのが常套だが、トピック抽出ではそうではないので注意が要る。


(参考:nmfによる特徴抽出結果)
Feature 0
痰     0.0495931287700765
業者     0.02850724796081803
側溝     0.01901462890506008
お隣さん     0.015641013370653413
抗生剤     0.011140459932083445
チャーハン     0.010093905735843085
工事     0.008731203366949483
発生     0.008179563229322631
工事責任者     0.007599589157225769
ウマ     0.007599589157225769

Feature 1
野菜     0.03507305700687259
キャベツ     0.025796953738214525
ポトフ     0.02546532526605233
白菜     0.02372537282268417
冷凍     0.020633457519941032
高騰     0.020188593051071534
咳     0.019755218948483276
苦労     0.01669825310328528
スーパー     0.015248849132344889
抗生剤     0.014767284971923087

Feature 2
ミニトマト     0.043811113889274236
畑     0.021399865636458723
苗     0.021168018407518516
連作障害     0.017545298644765853
移植     0.01618791738122602
枯れ草     0.015390346986361825
脇芽     0.012675225674010372
成長     0.012675225672772496
花     0.011479901827094475
栄養不足     0.010450801040058787

Feature 3
便ショック     0.024212879904796005
一緒     0.022766031964706612
冷や汗     0.015301901208473684
頭     0.014692070171762824
看護師     0.01409349590878432
足     0.014080593921882724
便秘     0.01354189150118618
便秘薬     0.013252627012208265
ベッド     0.012024435178583398
噎せ     0.011063529116792956

Feature 4
マスク     0.025691490366305244
喉     0.025488551983412867
口     0.020471555995990983
餃子     0.01562302271638188
口中     0.013763057233693633
食べかす     0.013439418785406988
夕食     0.012881787532595161
停滞     0.012529298188502024
口腔ケア     0.010376873920553923
鼻     0.008131787360855857

Feature 5
利用者     0.026752727123941104
夏みかん     0.02274815930417434
施設     0.022177668147149523
小規模ホーム     0.017989031667987123
家族     0.016063084232485616
ヘルパーさん     0.015217385168445702
利用     0.014773683271354338
名前     0.012991939408259864
要望     0.01171056845065073
人     0.010247926581283706

Feature 6
主治医     0.03453361414713443
看護師     0.0252140504258858
服用     0.020963729957978725
指導     0.015878913164347086
乱用     0.015759741824699868
介護テーブル     0.014268450832412577
整形外科     0.014209298056962145
判断     0.014012961180910328
対処     0.013043649846584173
抗生剤     0.012212662019730045

Feature 7
仕事     0.039915724247567265
介護     0.021268145195163728
面接     0.018595486351977695
両立     0.015516193702933572
就職     0.010008639770716277
突破口     0.009515561002291787
自分     0.009231389947669498
定員オーバー     0.008873280816044353
クリア     0.008553197041088272
模索     0.008236884698644632

Feature 8
テーピング     0.05707188168169596
右膝     0.016199354280562937
歯医者     0.013188945072292235
入れ歯     0.01150315165600258
ビニールテープ     0.010002356017567297
足     0.009756220288757078
準備     0.009272310706774953
買い物     0.009195270975947587
効果     0.0091365318322823
悪化     0.009107515350331838

Feature 9
移乗     0.02480611959335408
軸足     0.019851574721963458
尿     0.018022078002264963
車椅子     0.01641064929655168
シャワーキャリー     0.014726161693374535
ベッド     0.013338677149550617
移乗時     0.01246659620005425
右足     0.011512666279355521
右膝     0.011314824676151108
捻り     0.010489159908054069


(6/28)2010-04~2010-06のyahoo!ニュース-バックナンバー見出し(スポーツ)からのhdp-ldaによるトピック抽出結果
http://backnumber.dailynews.yahoo.co.jp/archives/?d=20100613&dc=201006

※各文書単位がニュースの見出しのため、各文書はかなり小さい（名詞にして3~4単語ほどのものが大半）
そのせいか、いまひとつ得られたトピックの解釈が難しいものが多い。

2010-04
(("Topic 48" #("下" "島袋" "誰" "盗塁" "パ" "影響" "初戦" "噴火" "モト" "鵬") . 0.010320801152420036)
 ("Topic 14" #("太もも" "ラグビー" "最低" "張り" "上原" "転落" "駅" "会見" "打球" "頭") . 0.010319257315312934)
 ("Topic 31" #("結婚" "助っ人" "152" "白星" "真央" "私服" "遅刻" "イケシオ" "30" "度") . 0.010318482393748203)
 ("Topic 77" #("ひじ" "絶望" "田沢" "上申" "千春" "生徒" "調" "先生" "伊" "ペア") . 0.010317713478510883)
 ("Topic 90" #("落合" "優勝" "脳" "幸せ" "エース" "+" "池田" "31" "同級生" "三振") . 0.010317712963765787)
 ("Topic 82" #("27" "活躍" "新人" "松本" "失点" "パナソニック" "バレー" "剛" "高速" "アシスト") . 0.010316944048070608)
 ("Topic 41" #("適時" "超" "キロ" "一転" "柔道" "単独" "盗" "アシスト" "塚田" "杉本") . 0.010316943191255073)
 ("Topic 25" #("夢" "青山" "楽天" "評価" "独立" "黒星" "トリオ" "戦力" "外" "広") . 0.010316942504063892)
 ("Topic 42" #("揚げ物" "職人" "チーム" "俳優" "横綱" "映画" "塁打" "マ" "準備" "先制") . 0.010315400039737927)
 ("Topic 87" #("村主" "製薬" "富山" "所属" "反省" "会見" "ダン" "育成" "休養" "臥") . 0.010314626490801887))

2010-05
(("Topic 3" #("レス" "トー" "初戦" "球場" "ブレービー" "風邪" "野村" "克也" "父" "打席") . 0.009098553172172303)
 ("Topic 26" #("角界" "暴力団" "再起" "心" "栃" "対" "中指" "700" "四十九日" "眼中") . 0.009098553051663136)
 ("Topic 68" #("完投" "割" "稲本" "12" "キラー" "岸" "オリ" "エ" "二塁打" "赤田") . 0.009097927842225649)
 ("Topic 91" #("デンマーク" "妻" "大会" "." "西川" "落選" "ファン" "ドジャース" "岡崎" "誌") . 0.009097927601439498)
 ("Topic 41" #("ツアー" "君" "2022" "一" "本" "大会" "回転" "以上" "報道" "サポート") . 0.009097927360699927)
 ("Topic 59" #("選出" "ナウ" "ジーニョ" "塩" "稀" "進退" "生活" "競技" "ヨ" "つぶし") . 0.009096675615247676)
 ("Topic 31" #("本橋" "代打" "グリフィー" "昼寝" "から" "フェイント" "桃子" "休養" "痛" "的") . 0.009096675013212386)
 ("Topic 56" #("えり" "架け橋" "元朝" "吉田" "登板" "投" "全英オープン" "好調" "29" "マエケン") . 0.009096051249885816)
 ("Topic 85" #("術" "佑" "結婚" "石井" "報道" "帯同" "犬飼" "警告" "29" "全米") . 0.009095426281884905)
 ("Topic 8" #("天皇" "メイル" "賞" "ジャガー" "吉見" "ベイ" "笑顔" "重圧" "ジロ" "区間") . 0.009095425437716301))

2010-06
(("Topic 83" #("今井" "宝塚" "娘" "カープ" "ベロン" "反発" "チーム" "目黒" "イケメン" "結婚") . 0.010428073388153646)
 ("Topic 21" #("北島" "欧州" "平" "連発" "熱烈" "ポルトガル" "康" "50" "冠" "価値") . 0.010426910715078652)
 ("Topic 46" #("高橋" "五十嵐" "トップ" "最多" "吉見" "いびき" "起用" "腕" "マナー" "内") . 0.010425757649824278)
 ("Topic 27" #("きょう" "宮本" "勝昌" "魔術" "講習" "翔" "復活" "以来" "大" "チリ") . 0.01042575730623086)
 ("Topic 6" #("世界" "宮里" "藍" "勝ち" "落選" "原因" "緊急" "スロベニア" "小国" "奪取") . 0.010425754902904977)
 ("Topic 24" #("昭和" "以降" "快勝" "伊藤" "夏場所" "新星" "さん" "前" "周忌" "清水") . 0.010425754562155658)
 ("Topic 96" #("マエケン" "月間" "悔し涙" "大相撲" "内野" "重圧" "記録" "岩瀬" "開幕" "対策") . 0.010424598064825439)
 ("Topic 43" #("痛" "連日" "盗塁" "虎" "矢野" "ひじ" "起用" "甲田" "打点" "切り札") . 0.010424595661702694)
 ("Topic 1" #("ハム" "連敗" "取得" "京都" "問題" "口" "誕生" "余裕" "イタリア" "ロー") . 0.010423438136232456)
 ("Topic 51" #("連敗" "完" "由" "魔境" "違和感" "三振" "山" "理事" "痛恨" "イタリア") . 0.010423437107280975))


(6/17)IBISMLメモ-機械学習はk-nnに向かう?

IBISML第一回研究会に参加して、個人的に興味深かった招待講演は産業総合研究所、津田宏治氏の「複合ソート法による高速な全ペア類似度検索」と
電気通信大学、柳井啓司氏の「一般物体認識における機械学習の利用」であった。

津田氏の講演内容は、類似度が与えられている非常に大きなデータセット内部で、あるデータのk-近傍やイプシロン近傍を計算するというもの。
全ペアで素朴に類似度を計算するとO(n^2)の計算量になるが、データ点数が数千万から数億(!)になろうとする今の状況ではそれでは話にならない。
そこでソートを段階的にし、最初の段階では疑陽性の近傍点検出も許して、候補点のみを再度厳密に計算する手法で高速化をはかっている。

印象として、扱うデータサイズは年々想像以上に巨大になってきており、そこでは線形計算量程度で動く学習アルゴリズムでないと現実的には使えない、
という事情があるように思われる。

柳井氏の講演は一般物体認識に関するもので、画像データに対してその画像が何であるかという名詞タグを機械学習で対応させる話である。
一般物体認識には3つの基本要素があり、

1. 学習データ
2. 特徴抽出
3. 機械学習

から成り立っている。特徴抽出については2004年に画像特徴量の決定版(局所不変特徴量)が発見され、画像はこの特徴の集まり(Bag of Features)として
ベクトル表現される。学習データも長くネックであったが、Webの普及と発達により、膨大な学習データが手に入るようになったことも
一般物体認識の世界では非常に大きな出来事だったらしい。機械学習手法の発展も大きく、よく使われているのはSVMとAdaBoostということである。

柳井氏の講演で一番印象に残っているのが、良質で膨大な学習データセットの重要性を度々主張していたことである。また、そのようなデータライブラリがあれば
機械学習手法としては、きわめて原始的なk-nnだけで十分かもしれないとのことであった。

学習データ…良い本
特徴抽出…目や耳などの感覚器
機械学習…脳

というアナロジーで考えると、一般に機械学習研究者は脳に注力しがちだが、現実への応用を意識すると、クルーシャルなのは「良質・膨大なデータライブラリ」
であるという指摘は示唆に富む。例えば現在では、撮られた写真から撮影場所の位置情報(緯度・経度)を割り出すという話まであるらしく、はじめに聞いたときは
一体どうやって?と思ったのだが、柳井氏によると原理は非常に簡単で、局所不変特徴量によってベクトル化された写真と、google street viewの画像との間で
類似度を計算し、google street viewが持っている緯度・経度情報を対応させるだけである。ここで効いているのは、やはり「良質・膨大なデータライブラリ」と
それに基づく類似度の計算である。講演を聴いていて、今後の機械学習応用のひとつの極は、検索やソートといったシンプルな技術と「良質・膨大なデータライブラリ」に
収斂していく可能性を強く感じた。


(6/16)SVM for Unbalanced Data

正例・負例の重みつき機能の実装を終了したので、libsvmとの比較を行った。下の結果からほぼ同一の精度が出ていることが分かる。
今後はWSS3.SVMに機能を反映させ、テストを行い、Readmeを修正する予定。これでSVMの基本機能は概ね実装したことになる。
その後はnmfとmkl周辺を見ていくつもりである(カルバック・ライブラー情報量をコスト関数にした場合のmkl化の模索など)。


;;weight = 10.0 
SMOTE-SVM(61): (make-svm-learner training-vector rbf-kernel :c 1.0 :weight 10.0)
#<Closure (:INTERNAL MAKE-DISCRIMINANT-FUNCTION 0) @ #x101651e1a2>
SMOTE-SVM(62): (svm-validation * test-vector)
(((1.0 . -1.0) . 201) ((-1.0 . -1.0) . 6241) ((-1.0 . 1.0) . 2040) ((1.0 . 1.0) . 13294))
89.70885378398236;;Accuracy

;;libsvm
[abey@capellini libsvm-2.91]$ ./svm-train -s 0 -t 2 -g 0.5 -c 1 -w-1 10 /local_home/machine-learning/training /local_home/machine-learning/model 
.*
optimization finished, #iter = 1530
obj = -738.509239, rho = -0.688658
nSV = 578, nBSV = 425
Total nSV = 578
[abey@capellini libsvm-2.91]$ ./svm-predict /local_home/machine-learning/test-data /local_home/machine-learning/model /local_home/machine-learning/result 
Accuracy = 89.7089% (19535/21776) (classification)

;;weight = 0.1
SMOTE-SVM(65): (make-svm-learner training-vector rbf-kernel :c 1.0 :weight 0.1)
#<Closure (:INTERNAL MAKE-DISCRIMINANT-FUNCTION 0) @ #x101fd96ad2>
SMOTE-SVM(66): (svm-validation * test-vector)
(((-1.0 . -1.0) . 1753) ((1.0 . -1.0) . 4689) ((-1.0 . 1.0) . 55) ((1.0 . 1.0) . 15279))
78.21454812637766;;Accuracy

;;libsvm
[abey@capellini libsvm-2.91]$ ./svm-train -s 0 -t 2 -g 0.5 -c 1 -w-1 0.1 /local_home/machine-learning/training /local_home/machine-learning/model 
*.*
optimization finished, #iter = 1003
obj = -126.362931, rho = -0.828850
nSV = 821, nBSV = 736
Total nSV = 821
[abey@capellini libsvm-2.91]$ ./svm-predict /local_home/machine-learning/test-data /local_home/machine-learning/model /local_home/machine-learning/result 
Accuracy = 78.2145% (17032/21776) (classification)


(6/11)ちょっと気づいた点(hdp-ldaとnmf他)

;;hdp-lda
("Topic 35" #("新潟" "豊栄" "小千谷" "渡辺" "東京" "長岡" "小林" "鳥屋野" "津南" "妙高高原") . 0.02444346223102492))

;;nmf
Feature 3
#<DIMENSION NAME: 豊栄, TYPE: NUMERIC, INDEX: 1113.>    17.358054722576046
#<DIMENSION NAME: 新潟, TYPE: NUMERIC, INDEX: 29.>    17.19636770145399
#<DIMENSION NAME: 小千谷, TYPE: NUMERIC, INDEX: 120.>    13.886443778060839
#<DIMENSION NAME: 長岡, TYPE: NUMERIC, INDEX: 686.>    8.679027361288023
#<DIMENSION NAME: 渡辺, TYPE: NUMERIC, INDEX: 429.>    7.485229107512254
#<DIMENSION NAME: 鳥屋野, TYPE: NUMERIC, INDEX: 284.>    6.943221889030419
#<DIMENSION NAME: 津南, TYPE: NUMERIC, INDEX: 334.>    6.943221889030419
#<DIMENSION NAME: 妙高高原, TYPE: NUMERIC, INDEX: 808.>    6.943221889030419
#<DIMENSION NAME: 妙高, TYPE: NUMERIC, INDEX: 19.>    6.075319152901615
#<DIMENSION NAME: 下条, TYPE: NUMERIC, INDEX: 775.>    6.075319152901615

どちらもコーパス内の同種の特徴を補足しているように見える例となっている。


SVM for Unbalanced Dataについては、理論面はおおよそ理解したので、来週から実装に入る予定。
結局一番の問題は、解析的に求めた部分二次計画問題の解がもし実行可能領域になかった場合に、
それを実行可能領域に引き戻す処理(clipping)である。それなりに精緻に場合分け（計8通り）する必要がある。


(6/3)SVM for Unbalanced Data

学習用データ内の正例と負例のバランスが悪い、もしくは一方のクラスを誤判別することの損失がとりわけ大きい場合、
ソフトマージンSVMのペナルティ・パラメータCを正例においてはC+、 負例においてはC-、
とするSVMが自然に考えられ、実際にLibsvmおよびVMSでも採用されている。

CLMLのSVM Package においても、同様のクラス重み付け機能を、Libsvmでの実装を参考に追加する予定である。
現在、参考論文を調査・読解中。


(5/31)SVR, One-Class-SVMの項目をReadmeに追加。


(5/26)One-Class-SVMの動作検証

CLMLにおけるOne-Class-SVMとLibsvmのOne-Class-SVMの動作比較を行った。
具体的には、同一のデータから、同じ二次計画問題の解が求まっているか否かを確認した。

1. CLML

ONE-CLASS-SVM(51): (qp-solver data-vector (make-one-class-svm-kernel :gamma 0.05) 0.001)
#(0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.37110715429364194 0.0 ...)

;;二次計画問題の解
ONE-CLASS-SVM(52): (loop for alpha across * 
		       if (/= 0.0 alpha)
		       do (print alpha))

0.37110715429364194 
0.15290156595970658 
0.3345272350532786 
0.5172520677178445 
0.35960904105326985 
0.11813523256310049 
0.007384518121460737 
0.08686453099307978 
0.08328219706275886 
0.3718399515722278 
0.01609650560963105 
NIL

;;切片
ONE-CLASS-SVM(53): (compute-rho data-vector (make-one-class-svm-kernel :gamma 0.05) **)
1.3506296181406112


2. Libsvm

svm_type one_class
kernel_type rbf
gamma 0.05
nr_class 2
total_sv 11
rho 1.35063 ;;切片

SV;;Libsvmのsolverによる解

0.3711071545160344 1:0.72903216 2:0 3:0 4:0.15555556 5:-0.71428571 6:-0.64705882 7:-1 8:-1 9:1 10:0 11:1 12:1 13:1 14:-1 15:-1 16:0.7571935 17:1 18:0 19:0.68359995 20:1 21:0 22:0 23:-1 24:1 
0.1529015096578925 1:0.8319999 2:0 3:0 4:1 5:-0.85714286 6:-1 7:-0.84615385 8:-1 9:0.60225636 10:1 11:0 12:1 13:-0.85821357 14:-0.89946629 15:-0.94473468 16:0.7571935 17:1 18:0 19:0.68359995 20:1 21:0 22:1 23:-0.63888889 24:1 
0.3345272482514177 1:1 2:0 3:1 4:-0.86666667 5:-1 6:-1 7:-1 8:-1 9:0.9106003 10:0 11:0 12:1 13:-0.81481481 14:-0.96774194 15:-0.96774194 16:-1 17:0 18:0 19:1 20:0 21:1 22:0 23:-0.94444444 24:1 
0.5172520816823354 1:-0.89189196 2:0 3:0 4:-0.82222222 5:-0.19047619 6:-0.82352941 7:-1 8:-1 9:-0.63094133 10:0 11:0 12:0 13:-0.94444444 14:-0.4516129 15:-0.90322581 16:1 17:0 18:1 19:1 20:0 21:1 22:0 23:-1 24:-1 
0.3596090680906546 1:0.65 2:0 3:0 4:-0.46666667 5:-0.9047619 6:-1 7:0.84615385 8:-1 9:0.7160244 10:0 11:0 12:0 13:-0.77777778 14:-0.93548387 15:-1 16:0.7571935 17:1 18:0 19:0.68359995 20:1 21:0 22:1 23:-0.86111111 24:-1 
0.1181352569290213 1:1 2:0 3:1 4:-0.86666667 5:-1 6:-1 7:-1 8:-1 9:0.5172415 10:0 11:0 12:1 13:-0.87037037 14:-0.87096774 15:-0.90322581 16:0.939394 17:0 18:0 19:-0.86984575 20:0 21:0 22:1 23:-0.86111111 24:1 
0.007384537056680487 1:0.6664175 2:1 3:0 4:-0.83514559 5:-0.92969242 6:-0.96745842 7:-0.94799423 8:-0.99717752 9:0.79885066 10:0 11:0 12:0 13:-0.85185185 14:-0.96774194 15:-1 16:1 17:0 18:1 19:1 20:0 21:1 22:1 23:-0.88888889 24:-1 
0.08686452197299155 1:0.18048775 2:0 3:0 4:0.2 5:0 6:0.058823529 7:-1 8:-1 9:0.60225636 10:1 11:0 12:1 13:-0.85821357 14:-0.89946629 15:-0.94473468 16:0.7571935 17:1 18:0 19:0.68359995 20:1 21:0 22:0 23:-1 24:-1 
0.0832821921929414 1:0.26315784 2:0 3:0 4:-0.46666667 5:-0.57142857 6:-0.64705882 7:-1 8:-1 9:-1 10:0 11:0 12:0 13:-1 14:-0.064516129 15:-0.064516129 16:0.7571935 17:1 18:0 19:0.68359995 20:1 21:0 22:0 23:-1 24:1 
0.3718399573537571 1:1 2:0 3:1 4:-0.91111111 5:-1 6:-1 7:-1 8:1 9:-0.0820452 10:0 11:0 12:1 13:-0.90740741 14:-0.64516129 15:-0.96774194 16:1 17:0 18:1 19:0.37028635 20:0 21:0 22:0 23:-0.97222222 24:1 
0.01609647229627351 1:0.6664175 2:1 3:0 4:-0.83514559 5:-0.92969242 6:-0.96745842 7:-0.94799423 8:-0.99717752 9:0.7805643 10:0 11:0 12:0 13:-0.87037037 14:-0.96774194 15:-1 16:-0.06493509 17:0 18:0 19:-0.16387087 20:0 21:0 22:0 23:-1 24:-1 


※両者の結果には、若干の数値計算上の誤差は認められるが、同一のロジックで求解していることが確認できた。


(5/25)One-Class-SVM

異常値・外れ値検出のための教師なしSVMであるOne-Class-SVMを実装中。現在90パーセント程の進捗度。


(5/21)非線形回帰学習器の性能比較

CLML内で非線形回帰モデルを作成する機械学習アルゴリズムとして、決定木・ランダムフォレスト・サポートベクター回帰を選び、
同一のデータを処理させ、各々の回帰性能を二乗平均誤差(MSE)によって比較した。なお、サポートベクター回帰については
ハイパーパラメータ選択の必要があるが、マニュアルで幾つか試した中でもっとも良い結果を出しているものを採用している。

1. 決定木

SVR(100): (decision-tree::make-regression-tree bc-train "Mitoses")
(((("Cell.size" . 5.0)
   (("Bare.nuclei" . 4.0) ("Bare.nuclei" . 1.0) ("Bare.nuclei" . 5.0) ("Bare.nuclei" . 10.0) ("Bare.nuclei" . 2.0)
    ("Bare.nuclei" . 3.0) ("Bare.nuclei" . 8.0) ("Bare.nuclei" . 6.0) ("Bare.nuclei" . 7.0) ("Bare.nuclei" . 9.0) ...))
  ((5.0 . 3) (6.0 . 1) (8.0 . 4) (3.0 . 14) (10.0 . 5) (4.0 . 9) (7.0 . 5) (2.0 . 15) (1.0 . 282))
  ((337 334 329 323 305 295 292 285 280 275 ...) (336 335 333 332 331 330 328 327 326 325 ...)))
 (((("Epith.c.size" . 6.0) (# # # # # # # # # # ...))
   ((6.0 . 1) (7.0 . 3) (10.0 . 4) (8.0 . 3) (4.0 . 8) (5.0 . 3) (2.0 . 7) (3.0 . 10) (1.0 . 47))
   ((2 10 18 20 25 34 41 52 55 71 ...) (1 23 26 28 42 48 53 54 57 74 ...)))
  (((# #) (# # # # # # # # #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #)))
  (((# #) (# # # # #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #))))
 (((("Cl.thickness" . 7.0) (# # # # # # # # # # ...))
   ((4.0 . 1) (10.0 . 1) (7.0 . 2) (3.0 . 4) (8.0 . 1) (2.0 . 8) (1.0 . 235))
   ((7 19 27 31 35 50 51 72 113 115 ...) (0 3 4 5 6 8 9 11 12 13 ...)))
  (((# #) (# # # # # #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# #)))
  (((# #) (# # # # #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #)))))
SVR(101): (decision-tree::regression-tree-validation bc-test "Mitoses" *)
4.363045038244765

2. ランダムフォレスト

SVR(102): (random-forest::make-regression-forest bc-train "Mitoses")
#((((("Marg.adhesion" . 7.0) NIL)
    ((6.0 . 1) (5.0 . 3) (2.0 . 15) (4.0 . 2) (8.0 . 5) (3.0 . 18) (7.0 . 6) (10.0 . 9) (1.0 . 279))
    ((304 297 290 288 287 284 274 268 261 243 ...) (337 336 335 334 333 332 331 330 329 328 ...)))
   (((# NIL) (# # # # # # # #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# #)))
   (((# NIL) (# # # # # # # # #) (# #)) ((# # #) (# # #) (# #)) ((# # #) (# # #) (# # #))))
  ...)
SVR(103): (random-forest::regression-forest-validation  bc-test "Mitoses" *)
2.38451848717276

3. サポートベクター回帰

SVR(104): (make-svr-learner training-vector (make-rbf-kernel :gamma 0.1d0) 10d0 0.01d0)
#<Closure (:INTERNAL MAKE-REGRESSION-FUNCTION 0) @ #x101079e972>
SVR(105): (svr-validation * test-vector)
2.651100613799585

(考察)

予想された結果ではあるが、「決定木 < サポートベクター回帰 < ランダムフォレスト」の順に回帰性能が良くなっている。
とりわけランダムフォレストは、サポートベクター回帰と比較すると、厄介なパラメータ調整が不要なことが大きい。
また、データ前処理としての数値データのスケーリングも不要である。さらにサポートベクターマシン系のアルゴリズムが
ブラックボックス的に予測モデルを構築するのみなのに対して、ランダムフォレストはデータセットに対するインサイトを得る目的での
分析的用途にも応用がある(データ間の近接度を示すproximity matrixや特徴素の有用性であるfeature importanceなど)。

ただ、現状のCLMLにおけるランダムフォレストパッケージはまだまだ遅く、計算速度やスケーラビリティでは
サポートベクターマシン系のアルゴリズムに分がある。これについてはまだ工夫と改良の余地があると思われるので、
折を見てランダムフォレストにはもっと手をいれていきたい。



(5/20)CLML-SVRとLibsvmの比較検証

同一の学習データ、テストデータを用いてCLML-SVRとLibsvm双方で回帰学習器を作成し、
テストデータの予測結果を比較した。検証してみた結果としては(6桁目を四捨五入すれば)同一の値が返ってきており、
アルゴリズム的な意味では、正しくサポートベクター回帰が行われていることが確認できた。

1. CLML-SVR

SVR(150): (make-svr-learner training-vector (make-rbf-kernel :gamma 0.5d0) 0.1d0 0.1d0)
#<Closure (:INTERNAL MAKE-REGRESSION-FUNCTION 0) @ #x1011ce8fe2>
SVR(151): (svr-validation * test-vector)
3.5685153532952616;;Mean Squared Error
;;テストデータ最初の三例の予測値
SVR(152): (loop for i below 3 do (print (funcall ** (svref test-vector i))))

1.0999158078566689 
1.1019834917110467 
1.102763828873443 
NIL


2. Libsvm

[abey@capellini libsvm-2.91]$ ./svm-train -s 3 -t 2 -g 0.5 -c 0.1 -p 0.1 /local_home/machine-learning/bc-train /local_home/machine-learning/model
[abey@capellini libsvm-2.91]$ ./svm-predict /local_home/machine-learning/bc-test /local_home/machine-learning/model /local_home/machine-learning/result
Mean squared error = 3.56852 (regression)

;;Libsvmによる予測値出力ファイルの冒頭三行

1.09991
1.10198
1.10276


(5/19)サポートベクター回帰(SVR)

まだ色々と粗い段階ではあるが、Working Set Selection 3タイプのSMOアルゴリズムを用いたサポートベクター回帰(SVR)を実装した。
これからソースを整理し、動作検証などを行っていく。SVRの後は、異常値検出を行う機械学習アルゴリズムであるOne-Class-SVMを実装する予定。


(実行例)

SVR(166): (make-svr-learner training-vector rbf 0.1d0 0.1d0)
#<Closure (:INTERNAL MAKE-REGRESSION-FUNCTION 0) @ #x100da45e92>
SVR(167): (funcall * (svref test-vector 0))
0.9620790202269824;;テストデータに対するSVRの予測値
SVR(168): (aref (svref test-vector 0) 23)
1.0;;テストデータの真値


(5/13)SVMの使い方メモ

SVMを実際のデータ解析に使用するさい、もっとも汎用的に使われるのはRBFカーネル(Gaussianカーネル)であると思われる。
SVMの使用においては、ユーザがhyper parametersを適切に設定することが大事であるが、これはある程度試行錯誤して決めなければならない。
ここでは、RBFカーネルのhyper parameter であるgammaと、ソフトマージンSVMのペナルティ項Cを、マニュアルである程度適切に選ぶ指針について記す。

gammaを決めるポイントは次の原則である。

gamma:大->(与えられた学習用データについて)神経質なモデル:未知のテストデータについて「過学習の危険性」あり
gamma:小->(与えられた学習用データについて)大雑把なモデル:未知のテストデータについても「大雑把すぎる危険性」あり

実験として、

rbf1:gamma = 0.5
rbf2:gamma = 5
rbf3:gamma = 20

としてRBFカーネルをつくり、c = 10 としてniiの著者同定での教師ありデータを学習させ、
学習用データそれ自体を判別させた結果を示す。

;;gamma = 0.5
PWSS3-SVM(22): (make-svm-learner training-vector rbf1 10)
PWSS3-SVM(23): (svm-validation * training-vector)
(((1.0 . -1.0) . 95) ((-1.0 . -1.0) . 2077) ((-1.0 . 1.0) . 200) ((1.0 . 1.0) . 4886))
95.93551942683935

;;gamma = 5
PWSS3-SVM(24): (make-svm-learner training-vector rbf2 10)
#<Closure (:INTERNAL MAKE-DISCRIMINANT-FUNCTION 0) @ #x10184156b2>
PWSS3-SVM(25): (svm-validation * training-vector)
(((1.0 . -1.0) . 51) ((-1.0 . -1.0) . 2121) ((-1.0 . 1.0) . 106) ((1.0 . 1.0) . 4980))
97.83686966106366

;;gamma = 20
PWSS3-SVM(26): (make-svm-learner training-vector rbf3 10)
#<Closure (:INTERNAL MAKE-DISCRIMINANT-FUNCTION 0) @ #x100aee6222>
PWSS3-SVM(27): (svm-validation * training-vector)
(((1.0 . -1.0) . 23) ((-1.0 . 1.0) . 56) ((-1.0 . -1.0) . 2149) ((1.0 . 1.0) . 5030))
98.91154588040783

上の結果から、gammaが大きくなるほど、学習データに対する判別正解率が上がっている
(すなわち複雑な判別境界面を形成している)ことがわかる。

ならば常に大きいgammaを取ればよいかというと、もちろんそういうことはない。
与えられた学習データに過剰適応した学習器は未知のテストデータに対する判別正解率が低い(過学習)。

そこで先の学習器たちに、学習に使用したものとは異なるテストデータを与え判別させた結果を示す。

;;gamma = 0.5
PWSS3-SVM(12): (svm-validation * test-vector)
(((1.0 . -1.0) . 319) ((-1.0 . -1.0) . 4662) ((-1.0 . 1.0) . 595) ((1.0 . 1.0) . 11361))
94.60353073153452

;;gamma = 5
(((1.0 . -1.0) . 350) ((-1.0 . -1.0) . 4631) ((-1.0 . 1.0) . 496) ((1.0 . 1.0) . 11460))
95.00501859833501

;;gamma = 20
PWSS3-SVM(17): (svm-validation * test-vector)
(((1.0 . -1.0) . 516) ((-1.0 . -1.0) . 4465) ((-1.0 . 1.0) . 440) ((1.0 . 1.0) . 11516))
94.35555293145185

これを見ると、未知のテストデータに対する判別正解率が高いのは、gamma = 5 の場合であり、
学習用データの自己判別ではもっとも正解率が高かった gamma = 20 の学習器の正解率が3つの学習器の中で一番低くなってしまっている。
これから gamma = 20 では過学習が起こっていることがわかる。また、gamma = 0.5 はモデルとしては、やや大雑把であることがわかる。


(参考:gamma = 0.05の場合)

PWSS3-SVM(33): (svm-validation svm0 training-vector)
(((1.0 . -1.0) . 139) ((-1.0 . -1.0) . 2033) ((-1.0 . 1.0) . 320) ((1.0 . 1.0) . 4766))
93.675943786167
PWSS3-SVM(34): (svm-validation svm0 test-vector)
(((1.0 . -1.0) . 353) ((-1.0 . -1.0) . 4628) ((-1.0 . 1.0) . 814) ((1.0 . 1.0) . 11142))
93.10975969770325


もうひとつのhyper parameterであるCについても下記の原則が成り立つ。

C:大->(与えられた学習用データについて)神経質なモデル
C:小->(与えられた学習用データについて)大雑把なモデル

実験として、gamma = 5 に固定し、Cを変化させた結果を示す。

;;c = 1
PWSS3-SVM(38): (svm-validation svm1 training-vector)
(((1.0 . -1.0) . 95) ((-1.0 . -1.0) . 2077) ((-1.0 . 1.0) . 212) ((1.0 . 1.0) . 4874))
95.77018462386332
PWSS3-SVM(39): (svm-validation svm1 test-vector)
(((1.0 . -1.0) . 384) ((-1.0 . -1.0) . 4597) ((-1.0 . 1.0) . 680) ((1.0 . 1.0) . 11276))
93.7178957312393

;;c = 10
PWSS3-SVM(41): (svm-validation svm2 training-vector)
(((1.0 . -1.0) . 51) ((-1.0 . -1.0) . 2121) ((-1.0 . 1.0) . 106) ((1.0 . 1.0) . 4980))
97.83686966106366
PWSS3-SVM(42): (svm-validation svm2 test-vector)
(((1.0 . -1.0) . 350) ((-1.0 . -1.0) . 4631) ((-1.0 . 1.0) . 496) ((1.0 . 1.0) . 11460))
95.00501859833501

;;c = 100
PWSS3-SVM(44): (svm-validation svm3 training-vector)
(((1.0 . -1.0) . 25) ((-1.0 . 1.0) . 63) ((-1.0 . -1.0) . 2147) ((1.0 . 1.0) . 5023))
98.7875447781758
PWSS3-SVM(45): (svm-validation svm3 test-vector)
(((1.0 . -1.0) . 384) ((-1.0 . -1.0) . 4597) ((-1.0 . 1.0) . 478) ((1.0 . 1.0) . 11478))
94.91055086497019

Cの値が大きくなるほど、学習用データそれ自体に対する判別正解率は上がっていくことがわかるが、
C = 100 では未知のテストデータに対する判別正解率は、C = 10 の時より低い(過学習)。
また、C = 1 では学習用データ、テストデータ共に、判別正解率が低い。これはCの値が小さすぎて
得られた学習モデルが大雑把すぎることを示している。

まとめると、以下のようになる。

gamma, C が大きい -> 神経質で複雑なモデル(学習時間:遅い)
gamma, C が小さい -> 大雑把で単純なモデル(学習時間:速い)

※最悪なのは、むやみに大きなgamma,cを設定することで、いたずらに学習時間がかかるわりには、精度の良くない学習器しか得られないという羽目に陥る。
複雑であるよりは単純な方がベターだが、かといって単純すぎてもうまくない。


(参考:gamma = 5で固定し、Cの値を変えた場合の計算時間の比較)

;; c = 1
PWSS3-SVM(46): (time (make-svm-learner training-vector rbf 1))
; cpu time (non-gc) 16,150 msec user, 0 msec system
; cpu time (gc)     150 msec user, 0 msec system
; cpu time (total)  16,300 msec user, 0 msec system
; real time  16,302 msec
; space allocation:
;  5 cons cells, 216,250,656 other bytes, 0 static bytes
#<Closure (:INTERNAL MAKE-DISCRIMINANT-FUNCTION 0) @ #x10223ef4e2>

;; c = 100
PWSS3-SVM(47): (time (make-svm-learner training-vector rbf 100))
; cpu time (non-gc) 74,590 msec (00:01:14.590) user, 10 msec system
; cpu time (gc)     600 msec user, 0 msec system
; cpu time (total)  75,190 msec (00:01:15.190) user, 10 msec system
; real time  75,220 msec (00:01:15.220)
; space allocation:
;  5 cons cells, 1,139,341,824 other bytes, 0 static bytes
#<Closure (:INTERNAL MAKE-DISCRIMINANT-FUNCTION 0) @ #x101e01c662>


(5/12)SVR(サポートベクター回帰),One-Class-SVM

SVRもOne-Class-SVMも定式化(すなわちある種の二次最適化問題に帰着させる話)はわかりやすい。
問題は、それぞれ少し形が異なる最適化問題を効率的に解くためのsolverの設計である。
libsvmの開発者たちの論文によると、Working Set Selection3と似たSMO-type solverが設計できるようなので、
現在その論文"A Study on SMO-type Decomposition Methods for Support Vector Machines"を読解している。

余談ながら、竹内純一氏によると、機械学習は情報論的側面と計算論的側面の2フェーズからなる。情報論的側面とは
学習の数学的定式化であり、これはしばしば最適化問題の形をとる。理論的な興味からはこの定式化がなされれば十分で、
あとはごく小さい実験用データから得られる小規模な最適化問題を(例えばNUOPTのような)general solverで解いて、
その結果構成された学習器の性能が評価できればよい。

一方の計算論的側面は工学的な関心が主であり、現実の巨大なデータから得られる大規模な最適化問題をいかに効率的に解くかに主眼がある。
機械学習アルゴリズムの実装においては、計算論的側面が常に問題となる。SVMで言えば、情報論的側面はVapnikがつくりあげ、
計算論的側面は、PlattやLibsvmの開発者らの手によっている。

機械学習の計算論的側面とはつまるところ、ある特定の形の最適化問題しか解けないが、
その代わりにlarge scaleかつhigh performanceなsolverを設計するという話である。そのため、元の問題からちょっとでも
変化すると、今までのsolverはそのままでは使えない、といったようなことが起こる。現在、SVRやOne-Class-SVMで直面しているのは
この困難である。


(5/10)
ルータ故障診断に関して、長沼さんからmemo/naganumaをざっと読んで気づいた点があれば…とのことだったので第一感をメモ。

実際に故障しているか否かの判定データは得られないとのことで「教師なし学習の枠組み」になるとのこと。
教師なしの異常値検出ということなら、ちょうど今調査・実装中のOne-Class-SVMが使えそうである。

(クラスタリングではなく)直截に、異常値・外れ値検出の機械学習のスキームで考えられそうな気もする。

ネットワークの状態が時系列的に変化するならば、ある時間間隔でネットワークの状態を行列M(t)として取得し、
それをOne-Class-SVM等の異常値検出アルゴリズムにかけ、異常値と思われるノードを検出し、
それが一定期間・一定回数続けて異常値と判定されたらアラートを発するような仕組みではどうか。

->長沼さんと話してみたところ、目下のストーリーとしては個々のノードの異常検出ではなく、
　ネットワーク総体のマクロな異常を検出するということらしい。それだとOne-Class-SVMではベクトルが違うかもしれない(5/12)。


(5/10)
SVR(サポートベクター回帰)、One-Class-SVM(SVMを利用した教師なしの異常値検出・クリーニング手法)、
nu-SVM(hyper parameter Cの代わりにnuを指定するタイプのSVM)を調査・実装していく。

基本文献は"A Study on SMO-type Decomposition Methods for Support Vector Machines"で
Libsvmの開発者たちの手によるもの。Libsvmで使われているSVM型の機械学習アルゴリズムについて書かれている。


(4/14)Condensed Vector Machinesに関するメモ

基本的アイディアとしては、とにかく「support vectorの数を減らす」ということ。
support vectorを減らすことの利点は次の二点。

1. 学習時間の短縮。
2. 判別時間の短縮(判別にかかる時間はsupport vector の数に比例するので、例えば半分のsupport vectorならば判別時間は半分になる)。

評価実験を見る限りでは、精度は標準的な他のSVM(libsvm)と同等以上で、support vectorの数は約半分になっている。


(4/14)NMF成果発表会プレゼン資料を修正


(3/26)WSS3-SVM

・黄さんにwss3-svmの最適化を依頼

・wss3-svmは現時点ではまだゴミを出している状態だが、SMO-SVMと比較した結果を下記に示す。
training-vectorにはnii-alsのラベルありデータ24195件から10％をランダムに抽出した2419件のデータを使用している。
test-vectorにはその残りの90%である21776件のデータを使用した。
kernelはrbfでgammaは0.5、cは10で実験を行った。下の結果では同一のデータを処理して、wss3-svmの方が30倍ほど速い。
もっともsmo-svmはランダムアルゴリズムなので、処理に要する時間は実行毎に変わりうるが、
何度か試行してみた結果、wss3-svmの方が、少なくとも10倍は速いようである。
また、判別関数もwss3-svmでは少し改良し、ここではsmo-svmのものより4倍ほど速くなっている。

SMO-SVM(138): (time (wss3-svm::make-svm-learner training-vector wss3-svm::rbf 10))
; cpu time (non-gc) 2,710 msec user, 0 msec system
; cpu time (gc)     290 msec user, 0 msec system
; cpu time (total)  3,000 msec user, 0 msec system
; real time  3,020 msec
; space allocation:
;  5 cons cells, 645,494,752 other bytes, 0 static bytes
#<Closure (:INTERNAL WSS3-SVM::MAKE-DISCRIMINANT-FUNCTION 0) @ #x1016e0e072>
SMO-SVM(139): (time (wss3-svm::svm-validation * test-vector))
; cpu time (non-gc) 2,030 msec user, 0 msec system
; cpu time (gc)     150 msec user, 0 msec system
; cpu time (total)  2,180 msec user, 0 msec system
; real time  2,189 msec
; space allocation:
;  43,562 cons cells, 307,303,184 other bytes, 0 static bytes
(((1.0 . -1.0) . 423) ((-1.0 . -1.0) . 5995) ((-1.0 . 1.0) . 1069) ((1.0 . 1.0) . 14289))
93.14842027920646

SMO-SVM(140): (time (make-svm-learner training-vector rbf 10))
; 93771776 bytes tenured without 1 seconds continuous idle time.
; Next gc will be global anyway.
; cpu time (non-gc) 89,420 msec (00:01:29.420) user, 30 msec system
; cpu time (gc)     1,900 msec user, 0 msec system
; cpu time (total)  91,320 msec (00:01:31.320) user, 30 msec system
; real time  91,405 msec (00:01:31.405)
; space allocation:
;  523 cons cells, 2,875,955,248 other bytes, 0 static bytes
#<Closure (:INTERNAL MAKE-DISCRIMINANT-FUNCTION 0) @ #x1024cc6052>
SMO-SVM(141): (time (svm-validation * test-vector))
; cpu time (non-gc) 8,990 msec user, 0 msec system
; cpu time (gc)     0 msec user, 0 msec system
; cpu time (total)  8,990 msec user, 0 msec system
; real time  8,987 msec
; space allocation:
;  43,562 cons cells, 2,090,496 other bytes, 0 static bytes
(((1.0 . -1.0) . 422) ((-1.0 . -1.0) . 5996) ((-1.0 . 1.0) . 1069) ((1.0 . 1.0) . 14289))


・wss3-svmの空間計算量は、実測してみるとO(n^1.8)~O(n^1.9)である。
(これは論文に書かれているスケーリング度合いと一致する)。
これにより、学習に要する時間の概算ができる。
先の実験で、ラベルありデータ10％2419件の処理に約3秒かかっているので、
全ラベルありデータ24195件を処理するのに要する時間は、(* 3.0 (expt 10 1.8)) = 189.29 秒と見積もれる。
実際に計算してみると、以下のようになる。

SMO-SVM(153): (length training-vector)
24195
SMO-SVM(154): (time (wss3-svm::make-svm-learner training-vector wss3-svm::rbf 10))
; 54279952 bytes tenured without 1 seconds continuous idle time.
; Next gc will be global anyway.
; cpu time (non-gc) 162,700 msec (00:02:42.700) user, 30 msec system
; cpu time (gc)     17,810 msec user, 10 msec system
; cpu time (total)  180,510 msec (00:03:00.510) user, 40 msec system
; real time  181,016 msec (00:03:01.016)
; space allocation:
;  520 cons cells, 35,561,239,024 other bytes, 0 static bytes
#<Closure (:INTERNAL WSS3-SVM::MAKE-DISCRIMINANT-FUNCTION 0) @ #x102e3b5202>


(3/26)成果発表会~NMF

発表用スライドは70％ほど完成


(3/15)ペアワイズ分類、レコード照合、名寄せの問題

NIIのAuthor Linking System案件について、SVMによる判別、クラスタリング工程で関わった。
記憶が鮮明なうちに、気づいた点などを後のためにメモしておきたい。


・どういう問題か?->異なる情報源（データベース）で共通するレコードを機械学習の手法を用いて特定・照合する問題。


特徴

・問題自体の起源は古く、普遍的。古くから様々な名称（ペアワイズ分類、レコード照合、名寄せ、など）で呼ばれ、扱われてきた。
・異種データベース間でのレコードを扱うため、欠損値を多く含んだデータを扱う。
・ひとつの機械学習アルゴリズムを適用するだけでは解決しない、総合的な問題性格を持つ。


処理の流れ

1.レコードをパースして、フィールド毎の値（数・文字列）を算出、さらに各フィールド値を正規化する。

2.理想的にはすべてのレコードペアに対して、同一のエンティティを名指しているのか、そうでないのか判別すべきだが、
それだと膨大な数のペアワイズデータを扱うことになり、現実的ではない。そこで、1の処理を経たデータの中から
同一エンティティを名指している可能性の高いペアワイズデータ候補を選択する必要が生じる。ここでは取りこぼしが極力生じないような
候補選択が求められる。すなわち、本来同一エンティティを名指しているはずのペアが候補から漏れることは避けたい。一方で、
ノイズ・ゴミ（本来は同一エンティティを名指していないペア）を多少含んでいても構わない。->再現率重視。

3.2の処理で得られたペアワイズデータに対して機械学習を行い、同一エンティティを名指しているか否かを判別する。
ここでは、本来同一のエンティティを名指していないにも関わらず、同一エンティティを名指していると誤判別することを避けたい->適合率重視。
ここでの処理は実際には、SVMなどによる機械学習にかける以前のデータ前処理と、前処理されたデータの本処理に分けられる。

　・前処理
　　(ペア)カテゴリカルデータの数値への変換、欠損値の補間、判別に有効と思われる特徴素・説明変数の選択、スケーリング。

　・本処理
　　前処理済みデータを用いてSVMなどの教師あり機械学習による判別。

4.判別済みのデータを統合する（クラスタリング）。ペアワイズデータが同一エンティティを名指すという関係は同値関係になるので、同値類を求めることになる。
これについては、Knuthによる古典的に知られた効率的アルゴリズムが存在する。

5.4で形成されたクラスタに含まれているゴミを除く（クリーニング）。


考察

レコード照合問題において、中心的な課題は2の候補選択と3の機械学習による判別である(cf.相澤彰子「異種データベース間でのレコード照合に関する研究動向」)。
すなわち「候補選択->前処理->判別」である。個人的にもっとも今回の案件で重要だと感じた教訓のひとつに、候補選択と機械学習による判別は
独立した処理工程ではありえない、という点が強く挙げられる。

機械学習による判別処理を行うためには、人手でラベル付けされたラベルありデータを判別予測モデル構築のために必要とする。
一般にこのようなラベルありデータは非常に高コストであり、おいそれと準備できるものではない。当然、このようなラベルありデータは既に
何らかの候補選択を経て得られており、候補選択工程はわれわれが既に手にしているラベルありデータに即して、逆算する必要がある。
使えるラベルありデータが限られている以上、任意の候補選択手法が使えるわけでは「ない」。ここは非常に注意を要する点である。

統計および機械学習の基本として、ラベルありデータはこれから予測したいデータ母集団の偏りのないサンプルである必要がある。
もし何らかのバイアスがかかっているラベルありデータを用いて予測モデルを構築しても、当然ながら良い精度は望めない。
ラベルありデータを用いて予測モデルを構築する必要がある案件においては、まずどれだけのラベルありデータが使えるかを把握し、
そこからそれ以外の工程を逆算して求めていく必要があるように思われる。

それ以外に気づいた点として、当初はこのタスクにおいてSVMではなくRandom-Forestの方が精度の面で有効であるように思われた。
しかし、実際に学習器を作成して判別処理を行ってみると、精度こそRandom-Forestの方が1％ほど上回るが、
学習も、新規データの判別もSVMの方が高速であった。学習器については一度作成したものを保存可能なので、
学習時間の差はあまり問題にならないように感じられたものの、新規データの判別速度の違いは大問題である。
ビショップの『パターン認識と機械学習』において、「しかしながら実用上は、多くの計算資源を訓練に投資しても、
コンパクトなモデルを得て新規のデータをすばやく処理する利点の方が大きいことが多い」とあったが、その正しさを痛感した。
最後に、toy data ではないワイルドな実データに多少なりとも触れられたことは、自分にとって良い経験となった。


今後の改良点

・判別前処理->距離学習手法を取り入れた(ペア)カテゴリカルデータの数値化。欠損値のより賢い扱い。
・判別本処理->SVMのアルゴリズム高速化。ペアワイズ分類に特化したカーネルの使用も検討。
・過去につくられたレコード照合システムに関する文献を調べてみても、クリーニング工程に関しては標準的な手法というものがどうも確立されていない様子。
　それゆえ、試行錯誤や工夫の余地が色々あると思われる。


参考文献リスト（以下のものはすべてネットで入手可能）

相澤彰子 「異種データベース間でのレコード照合に関する研究動向」
小山聡 「異なる例からの素性の組合せを用いたペアワイズ分類の学習」
Mikhail Bilenko. Adaptive Duplicate Detection Using Learnable String Similarity Measures
Mikhail Bilenko. Learning to Combine Trained Distance Metrics for Duplicate Detection in Databases
Liu Yang. An Overview of Distance Metric Learning
Liu Yang. Distance Metric Learning: A Comprehensive Survey
Lifang Gu. Record Linkage: Current Practice and Future Directions
Erhard Rahm. Data Cleaning: Problems and Current Approaches

判別後のクラスタリングについては、Numerical Recipes in C. 8.6 Determination of Equivalence Classes が参考になる。


(3/8)成果発表会、内容素案


発表時間は40分、スライドは20枚前後を想定


仮タイトル「CL-Machine-LearningにおけるNMF（非負行列因子分解）パッケージについて」


・CLMLとは->知識工学部で開発している統計・機械学習パッケージ

 ・CLMLの特長->プラットフォーム非依存、fork-futureによる並列化、Intel MKLによる高速な行列演算

・NMFについて

 ・NMFとは何か（NMF:分析的機械学習アルゴリズム<->予測的機械学習アルゴリズム(e.g.SVM,Random-Forest)）

 ・NMFができると何が嬉しいのか->次元縮約、特徴抽出

 ・NMFの理論->歴史および乗法的更新アルゴリズムの紹介(論文紹介、スライド3~4枚使用)

 ・NMFの理論的問題点1 局所解に収束(大域最適解への収束は未保証、ランダムな解から出発するため、分解結果が毎回異なりうる)

 ・NMFの理論的問題点2 kをどう決めるか? ->rho-k, c^3m, ノンパラメトリックベイズ(?) (もっとも悩ましい問題)

・NMFの実装について

 ・Lispの良い点->・rapidにprototypeを作成、それを後から効率的にチューニング可能
                ・対話的開発環境のためテスト・デバッグがしやすい(NMFではデバッグの苦労はなし)

 ・実装において苦労した点->パフォーマンス・チューニング
　 実際には、黒田さん、黄さんがチューニングを担当(難しかった点、今後の個人的課題)

 ・MKL版とのパフォーマンス比較(スライドで結果を提示し、デモで実際に比較)
　(デモ1)通常版とMKL版での行列分解パフォーマンス比較

・NMFパッケージによる分析例・及びデモ(スポーツコーパスデータを用いて)

　・BOW表現（コーパスデータ->非負行列への変換プロセス）
　
　・weighting schemeの重要性(tf*idf)<-分析的機械学習におけるひとつの肝
　　「データの元の素性がもっともよく反映・保持されるように、n次元ユークリッド空間上のベクトルとしてデータを表現すること」

　・semantic weightによるクラスタリング結果の誘導(素のNMFではどのようなクラスタができているかは蓋を開けてみないと分からない)
　　(デモ2)semantic-weightを用いて、スポーツコーパス内の記事を「野球」、「サッカー」、「マラソン」の三分野に誘導分類

　・クラスタ誘導の特殊例としてのnmf-search(個人的に工夫した点)
　  (デモ3)・nmf-searchによるスポーツコーパス内の記事・単語検索

　・今後の展開->分類における「雑分類・その他・ゴミ箱」がNMFで実現できないか?

・謝辞


(2/23)SVM
・nii-svmの改善ポイント

データマイニング部雪島さんの2003年度技術レポート「Support Vector Machine」によると、VMSで用いられているSVMの
アルゴリズムは、Plattのオリジナルバージョンではなく、Keerthiによって効率改善されたものであるらしい。
「今回開発したSVMモジュールは、このSMO algorithmを採用した。この報告書で紹介するSMOはオリジナルのSMOではなく、
その改良版であるImproved SMOと呼ばれる解法である」

KeerthiによるSMOの改良版には2種類あり、その内の2つ目がLIBSVMで用いられているようだ。
"The second modification is particular good and used in popular SVM packages such as LIBSVM."
(L.J.Cao, S.S.Keerthi. Parallel Sequential Minimal Optimization for the Training of Support Vector Machines)


(2/2)SVM
testフォルダ以下にtest-nii-svm.clを追加。

多田さんの指摘により、バグを1つ潰すことができたが、
linear-kernel選択時に大きなスラック変数を選ぶと依然として収束が遅いのが気になる。

S.S.Keerthiの論文"Improvements to Platt's SMO Algorithm for SVM Classifier Design"に
PlattのSMOアルゴリズムの改善案が示されている。significantly faster than the original SMO
on all benchmark data sets triedとのこと。


(2/1)SVM

まだ問題はありますが、SVMのα版をnii-svm.clとして、machine-learningにpushしました(defsystemには未登録)。
またテスト用データとして、目的変数を1.0と-1.0に置換したbc-train-for-svm.csvと
bc-test-for-svm.csvも追加しました。

問題点

・linear-kernelで大きなスラック変数Cを指定したときの収束が未だ遅い。
・rbf-kernelでも実行毎に多少のズレがある。

とはいえ、これらはSMOアルゴリズムに本質的に付随するものかもしれない?ので、要調査。
(VMSではrandom-seedをfixしている?)

明日はlisp-unitでテストコードを書いて、数式上のミスがないかもう一度見直す予定です。


(sample usage)

NII-SVM(43): (setf svm-bc-train (read-data-from-file "sample/bc-train-for-svm.csv"
						 :type :csv
						 :csv-type-spec '(double-float double-float double-float double-float double-float double-float double-float double-float double-float double-float)))
#<UNSPECIALIZED-DATASET>
DIMENSIONS: Cl.thickness | Cell.size | Cell.shape | Marg.adhesion | Epith.c.size | Bare.nuclei | Bl.cromatin | Normal.nucleoli | Mitoses | Class
TYPES:      UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN
DATA POINTS: 338 POINTS
NII-SVM(44): (setf svm-bc-test (read-data-from-file "sample/bc-test-for-svm.csv"
						 :type :csv
						 :csv-type-spec '(double-float double-float double-float double-float double-float double-float double-float double-float double-float double-float)))
#<UNSPECIALIZED-DATASET>
DIMENSIONS: Cl.thickness | Cell.size | Cell.shape | Marg.adhesion | Epith.c.size | Bare.nuclei | Bl.cromatin | Normal.nucleoli | Mitoses | Class
TYPES:      UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN
DATA POINTS: 345 POINTS
NII-SVM(45): (setf training-vector (dataset-points svm-bc-train))
#(#(5.0 4.0 4.0 5.0 7.0 10.0 3.0 2.0 1.0 1.0) #(6.0 8.0 8.0 1.0 3.0 4.0 3.0 7.0 1.0 1.0) #(8.0 10.0 10.0 8.0 7.0 10.0 9.0 7.0 1.0 -1.0)
  #(2.0 1.0 2.0 1.0 2.0 1.0 3.0 1.0 1.0 1.0) #(4.0 2.0 1.0 1.0 2.0 1.0 2.0 1.0 1.0 1.0) #(2.0 1.0 1.0 1.0 2.0 1.0 2.0 1.0 1.0 1.0)
  #(1.0 1.0 1.0 1.0 2.0 3.0 3.0 1.0 1.0 1.0) #(7.0 4.0 6.0 4.0 6.0 1.0 4.0 3.0 1.0 -1.0) #(4.0 1.0 1.0 1.0 2.0 1.0 3.0 1.0 1.0 1.0)
  #(6.0 1.0 1.0 1.0 2.0 1.0 3.0 1.0 1.0 1.0) ...)
NII-SVM(46): (setf test-vector (dataset-points svm-bc-test))
#(#(5.0 1.0 1.0 1.0 2.0 1.0 3.0 1.0 1.0 1.0) #(3.0 1.0 1.0 1.0 2.0 2.0 3.0 1.0 1.0 1.0) #(4.0 1.0 1.0 3.0 2.0 1.0 3.0 1.0 1.0 1.0)
  #(1.0 1.0 1.0 1.0 2.0 10.0 3.0 1.0 1.0 1.0) #(2.0 1.0 1.0 1.0 2.0 1.0 1.0 1.0 5.0 1.0) #(1.0 1.0 1.0 1.0 1.0 1.0 3.0 1.0 1.0 1.0)
  #(5.0 3.0 3.0 3.0 2.0 3.0 4.0 4.0 1.0 -1.0) #(8.0 7.0 5.0 10.0 7.0 9.0 5.0 5.0 4.0 -1.0) #(4.0 1.0 1.0 1.0 2.0 1.0 2.0 1.0 1.0 1.0)
  #(10.0 7.0 7.0 6.0 4.0 10.0 4.0 1.0 2.0 -1.0) ...)
NII-SVM(47): (setf rbf-kernel (make-rbf-kernel :gamma 0.05))
#<Closure (:INTERNAL MAKE-RBF-KERNEL 0) @ #x1008f9cc32>
NII-SVM(48): (setf svm (make-svm-learner training-vector rbf-kernel 100))
#<Closure (:INTERNAL MAKE-DESCRIMINANT-FUNCTION 0) @ #x10043ef5e2>
NII-SVM(49): (svm-validation svm test-vector)
(((1.0 . -1.0) . 2) ((-1.0 . -1.0) . 120) ((-1.0 . 1.0) . 10) ((1.0 . 1.0) . 213))
NII-SVM(50): (setf svm (make-svm-learner training-vector #'linear-kernel 1))
#<Closure (:INTERNAL MAKE-DESCRIMINANT-FUNCTION 0) @ #x100f851302>
NII-SVM(51): (svm-validation svm test-vector)
(((-1.0 . 1.0) . 7) ((-1.0 . -1.0) . 117) ((1.0 . -1.0) . 5) ((1.0 . 1.0) . 216))


(1/28)SVM

数学的に安全マージンを大きく取った、滅茶苦茶遅いバージョンのSVM、SMOソルバを一応書き上げた。
以下は乳ガンデータ(bc-trainならびにbc-test)を用いた検証結果例である。
二群判別で、1.0は正例を、-1.0は負例を表している。

 MY-SVM(258): (setf svm-learner (smo-solver data-vector #'rbf-kernel 100))
 #<Closure (:INTERNAL MAKE-DESCRIMINANT-FUNCTION 0) @ #x101a249a92>
 MY-SVM(259): (svm-validation svm-learner test-data-vector)
 (((1.0 . -1.0) . 2) ((-1.0 . -1.0) . 120) ((-1.0 . 1.0) . 10) ((1.0 . 1.0) . 213))
 MY-SVM(260): (* 100.0 (/ (+ 120 213) 345))
 96.52173913043478...正解率96.52%

今後は、数学的に同値だが計算量が少ない表現にコードの幾つかの部分を置換して、スピードアップをはかる予定。


(1/21)SVM

・SMOアルゴリズムの実装が佳境に。

(1/15)SVM

・収束判定について

SVMアルゴリズムの終了条件、すなわち収束の判定には次の三つがある。

1. 主問題と同値な双対問題の目的関数の増分がある一定の閾値以下になったら収束したとみなす。
2. 収束するための必要十分条件であるKKT条件を用いて判定する。
3. 主問題の目的関数値と双対問題の目的関数値の差である可能性ギャップによって判定する。

筋が良いのは2か3で、1は問題があるらしい。ヒューリスティックに次に解くべき部分二次計画問題を選ぶ場合、
解の改善があまり起こらない場合がある。そうしたケースでは解の増分が収束判定の許容水準以下になることがあり、
実際には収束していないにも関わらず、収束したと誤判定してしまう。KKT条件を用いた判定については、実装上のノウハウがあるらしく、
オリジナルの条件をちょっとモディファイしてやるとより効率的に判定できるようである。

『サポートベクターマシン入門』pp.169に以下のような記述があり、示唆に富む。

「許容水準は、停止基準を検証するのに用いるが、非常に重要である。なぜなら、正確さを高い水準で達成するのは、
非常に時間を要するが、時間をかけて正確さを追求しても、必ずしもテスト時の正確さに結びつかないからである。
したがって、実用上、近似的に最適条件を保証するため、許容水準を設定しなければならない」

まだ確定ではなく、調査が必要だが、許容水準の経験的に適切な値はどうも10^-3あたりである様子。

SMOを用いたSVMの実装で悩ましいのは、ヒューリスティックに次に解くべき部分二次計画問題を選ぶ箇所である。
最悪の場合、不味いヒューリスティクスの実装でも解の改善が起こる場合は、収束が遅いにも関わらず
いずれは最適解に収束し、アルゴリズムが正しく速く実装されているかどうかのチェックは、
テストデータをかけてみて、うまく判別できるか否かだけでは分からないケースがある。もちろん、あまりに
収束が遅い場合はアルゴリズムの不備が疑えるが、ヒューリスティックな部分問題選出に不備があるにも関わらず、
そこそこの速度で動いてしまう場合というのが考えられる。


(1/15)SVM

・SVM、SMOメモ

SVMは結局のところ、データサンプル数と等しい数の変数からなる凸二次計画問題を解く、という最適化の問題に帰着する。
すなわち、データサンプル数が10000ならば、10000変数の最適化問題を解く必要がある。
ここで既にちょっとした問題があり、このSVMに付随する凸二次計画問題を記述するために、データサンプル数をnとすれば
ナイーブには(n*n)のサイズの行列が必要となる。これが以前にDと書いた行列である。
このDは（おそらく）DerivativeのDに由来し、二次計画問題中の二次式を各変数について二階偏微分して得られる。
スケーラビリティを考えるなら、行列Dを陽に持つべきではない。データマイニングの分野では10000サンプル以上のデータを扱えるか
否かが、スケールするかしないかの簡単なメルクマールになっているらしいが、SVMではこれが素直に当てはまる。
従来の方法ではこの行列Dを陽に持つため、空間計算量がO(n^2)となり、そのためSVMは大規模データの処理に向かないとされてきた。
SMOはこれに対して解決を与えるもので、空間計算量は高々O(n)ですむ。これが大きな利点のひとつである。

SMOは元の二次計画問題を、二変数の部分二次計画問題に逐次的に分解して解くアルゴリズムである。
SMOで最適化問題が解ける理由は次の2点に集約される。

1.凸二次計画問題においては、局所最適解がそのまま大域最適解になっている。
これについては放物線のグラフを考えると直感的にわかる。

2.SMOによる部分二次計画問題では変数が2つなので、さらに制約条件も加味すると
この部分問題は解析的に解ける。また、この部分問題にあらわれる係数行列のサイズは(2*2)である。
そして得られた解から、より大きい解が得られる。有界な単調増大数列は収束するので、
これは一般的には局所最適解であるのだが、1よりこれは自動的に大域解になっている。

それゆえ問題は収束のスピードであるが、SMOではヒューリスティックな方法を用いて
解くべき部分二次計画問題のための二変数を選び出す。そしてこの方法は経験的に収束が速いことが知られている。


・SMOの実装上の難しい点（と現時点で思うところ）

1.部分二次計画問題を解析的に解く際に、訓練データセットに同一のデータサンプル(同一行)があると、0除算が起きる。

2.ヒューリスティックに次に解くべき部分二次計画問題を定める（変数の添字を選択する）ルーチンの設計。

3.収束判定はKKT条件を満たすか否かで行うが、当然数値計算なので、just equal zero という
理論上の条件式を、そのまま書き下すだけではうまく動かない。また、理論上は分離超平面の切片bは
任意のサポートベクターから計算でき、その結果は同一であるべきだが、数値計算上の誤差から
実際には、複数のサポートベクターから得られたbたちの平均を取ったりする必要があるようである。


(1/12)SVM

・(非線形・ソフトマージン)SVMによる二群判別分析の流れ

1. ユーザが前処理を行ったデータセット、使用するkernel関数及びそのパラメータ、そしてスラック変数Cを引数として要求する。
2. データセットとkernel関数及びパラメータから、慣習的に大文字のDで表現されるn次正方行列が定まる。
ここでnはトレーニングデータのサンプル数である。これとスラック変数Cを合わせると、非線形・ソフトマージンSVMで解くべき
凸二次計画問題が決まる。
3. 2で定義された凸二次計画問題を、最急降下法なりSMOなどのソルバーで解く。今回は、SMOによるソルバーを実装している。
4. 3で解いた凸二次計画問題の解から、予測のための識別関数を構成する。
5. 4で構成した学習器を元に、予測を行う。

SVMの処理で難しいのは、1と3であって、とりわけアルゴリズム的には殆ど3のみが問題である。D行列や、識別関数、予測のための計算はシンプルで易しい。
しかし実際にデータをSVMで解析したいと思う際には、データの前処理と使用するkernel関数とそのパラメータ、及びスラック変数Cのチューニングが
精度の高い判別分析には必要となる。世間でよく使われて評判の高いLIBSVMというパッケージでは、このパラメータチューニングを
行うgrid.pyなるモジュールがあり、交差検証をデフォルトで5回行って、最適と思われるパラメータを自動的に算出してくれる。
VMSでもこのような自動パラメータ・チューニングはフォローされていないようであるが、LIBSVMの開発者らのドキュメントを読む限りでは、
自動的なパラメータ・チューニングは必須の機能であるように思われる。言い換えれば、ユーザが勘でパラメータをいじっても、
良い結果に結びつくことは少なく、それがSVMによる判別分析は難しいという印象を形成しているようだ。


・k-nn,SVM,Random-forestの比較

k-nn
分析にかけるデータセットは数値に変換されている必要がある。スケーリングなどの前処理も必要。
多群判別に関してネイティブ。
memory-based-reasoningのため、学習器を構築しないアルゴリズムなので、新データ追加のたびに学習器を再構築する必要がない。
ユーザが決定すべきパラメータは近傍数kと使用距離（大抵はユークリッド）で、悩む部分が(SVMに比べて)少ない。
予測の際には、近傍のデータを見つけるために距離を計算しなければならず、時間がかかる。

SVM
分析にかけるデータセットは数値に変換されている必要がある。スケーリングなどの前処理も必要。
基本的には二群判別のみ。多群判別に拡張することは可能だが、多群判別化は複雑であり問題が多く、二群判別で用いるのが筋が良いようである。
トレーニングデータを用いて学習器を構築する必要がある。新データの追加の度に再トレーニングが必要。
ユーザが決定すべきパラメータとして、kernel選択とそれに付随するパラメータ、スラック変数Cの設定などがあり、難しい。
予測の際には、ある曲面のどちらにデータが属するかを単に計算するだけなので、速い。

Random-forest
分析にかけるデータセットは数値、カテゴリカルデータが混在していても扱うことができる。スケーリングなどの前処理は不要。
多群判別に関してネイティブ。
トレーニングデータを用いて学習器を構築する必要がある。新データの追加の度に再トレーニングが必要。
ユーザが決定すべきパラメータはデフォルトのままでほぼ問題なく、高精度な判別ができる。
予測の際には、デフォルトでは500本の木の枝を辿り、その多数決を取るため、SVMのようなシンプルな予測モデルと比較すると時間がかかる。

(考察)
いずれも予測判別を行うという意味では似たような機械学習アルゴリズムであるが、それぞれ一長・一短あることがわかる。
予測時のスピードを問題にするならSVMがコンパクトな予測モデルをつくるという意味で優れている。実際、ビショップ本こと
『パターン認識と機械学習(上)』のpp.225では、「しかしながら実用上は、多くの計算資源を訓練に投資しても、
コンパクトなモデルを得て新規のデータをすばやく処理する利点の方が大きいことが多い」とある。

Random-forestはかなり大きな予測モデルをつくり、予測時のスピードもSVMと比較すれば速くない。
しかし、判別精度では幾つか報告されている実証研究を見る限り一番良く、精度を第一に考えるならRandom-forestが良い。
東大の機械学習研究者である鹿島久嗣は次のように書いている。
「また、予測モデリングにおいては、予測精度の向上が大きな目的のひとつであり、
1％の予測精度向上が、そのままコスト削減や、利益向上などの効果に結びつきやすいという特徴もあります」

また、Random-forestはk-nnやSVMのように「データをユークリッド空間上の点として表現する」というパラダイムに属さないため、
それに付随して生じる様々な問題（データを数値的に必ず表現しなければならないことからくる制約や、それに伴うスケーリングの問題）を
回避できる利点がある。すなわち、殆ど生に近いラフなデータをそのまま解析したいという際にはRandom-forestが向いている。
また、CLMLでは未実装だがRandom-forestは、予測的機械学習としてだけでなく、データの構造を理解するという目的の
分析的機械学習としても使える。例えば、proximity matrix や variable importanceなど。これは決定木がそもそも
精度の良い予測モデルの構築よりも、ユーザがデータの構造を理解することを目的とした分析的傾向が強いことに由来している。
ちなみに、機械学習の分野では「教師あり学習　supervised learning」と「教師なし学習　unsupervised learning」に区分することが多いが、
これは実相をよく反映してはいないので、「予測的機械学習」と「分析的機械学習」にしてはどうか、と先の鹿島久嗣氏は提案している。
一般に、教師あり学習は予測を、教師なし学習は分析を行うことが多いが、決定木のように教師あり学習でも分析的なものがある。

最後にk-nnの利点としては、アルゴリズム自体の理解が非常に容易なことと、学習器の作成が不要という点が挙げられる。
予測時の計算量は多いが、問題によっては、予測時の速いレスポンスは要求されないが、新データの追加が多い事態が考えられ、
こうしたケースでは学習器作成が不要なk-nnが適している。金融与信問題（融資の応諾・謝絶の判別問題）ではk-nnが向いているらしい。

月並みではあるが、やはり個々の問題に応じて、もっとも適した機械学習アルゴリズムを選択することが肝要なようである。

(1/7)SVM

・カテゴリカルデータの数値への変換(2)

台湾の研究者の手による有名なフリーのSVMライブラリーとしてLIBSVMというものがある。
その開発者たちが書いた"A Practical Guide to Support Vector Classification"という論文には
機械学習による判別分析を行うさいに重要なtipsが幾つも紹介されている。以下は、そこからの備忘のための抜き書きである。


Many beginners use the following procedure now:

・Transform data to the format of an SVM package
・Randomly try a few kernels and parameters
・Test

We propose that beginners try the following procedures first:

・Transform data to the format of an SVM package
・Conduct simple scaling on the data
・Consider the RBF kernel
・Use cross-validation to find the best parameter C and gammma
・Test

Data Preprocessing

・Categorical Feature

SVM requires that each data instances is represented as a vector of real numbers.
Hence, if there are categorical attributes, we first have to convert them into numeric data.
We recommend using m numbers to represent an m-category attribute.
Only one of the m numbers is one, and others are zero.
For example, a three-category attribute such as {red, green, blue} can be represented 
as (1,0,0),(0,1,0),and (0,0,1).
Our experience indicates that if the number of values in an attribute is not too many,
this coding might be more stable using a single number to represent a categorical attribute.

ポイントはデータのスケーリングを行うこと、闇雲にカーネルやパラメータを勘でいじっても精度の良い判別分析はできず、
交差検証法を使って最適なパラメータを割り出す必要があるということである。
またカテゴリカルデータの扱いに関しては、単に属性の数だけ1,2,3,...と数値を割り当てるのではなく、
属性の数がそんなに多くないならば、属性の数だけ次元を増やして0または1を割り当てることで対処した方が経験的に安定している、
ということである。昨日までは単に属性の数だけ整数を対応させれば良い、とナイーブに考えていたので、これは目から鱗であった。
気になって調べてみると、オラクルのSVMにおけるカテゴリカルデータの扱いも、LIBSVMと同様であった。

(1/6)SVM

・カテゴリカルデータの数値への変換、ならびにデータのスケーリング(正規化)の問題について。

アルゴリズムの特性上、ランダムフォレストでは問題にならなかったが、
SVMではカテゴリカルデータを文字列やシンボルではなく、どうしても数値で扱う必要がある。
また、説明変数にカテゴリカルデータが含まれる場合は、単にそれらを適当な整数に置換するだけではダメで、
他の数値型説明変数とのスケーリングの違いも考慮に入れなければならない。

これは『集合知プログラミング』で紹介されていた事例であるが、カップルが成立するか否かの予測モデルを構築する場合、
子供を望むか望まないかというカテゴリカルな説明変数を0か1かで表現し、他方で年齢が説明変数にある場合、
データのスケーリングについて考慮しないと、子供を望む、望まないという（重要と思われる）差異と、
高々1つの年の差が、同程度の差異としてSVMやk-nnのような機械学習アルゴリズムには認識されてしまう。
(ちなみに、決定木やランダムフォレストでは、このようなスケーリングの問題は発生しない)。

以上の理由から、SVMで分析にかけるデータセットにおいては、説明変数中のカテゴリカルデータが適切なスケールで数値に変換されていることが
必要である。また、数値型の説明変数も他の数値型説明変数との間でスケール的にバランスが取れていないと、当然良い予測モデルはつくれない。
例えば、先の事例で年収という説明変数を加えることを考えると、それが分かる。

そこで、本当はread-dataで、このようなデータの前処理(少なくともカテゴリカルデータの数値への変換)ができると良い。
幸いなことに、Rに収められているようなベンチマーク用サンプルデータは既にそのような前処理が成されていることが多い。
すなわち、説明変数はカテゴリカルなものも含めて、適切にスケーリングされている。また、目的変数は2値のカテゴリカルデータである。
乳ガンデータや、spamデータはこの条件を満たす。そこで、今回のSMOを用いたSVMにおいては入力データセットにこれらの条件を仮定したい。
さしあたり、乳ガンデータやspamデータのような素性の良いデータの二群判別問題をSMOを用いたSVMで解けるようにし、
決定木やRFの結果と比較できるようにすることを当面の目標とする。

(1/5)SVM

・ランダムフォレストは一旦切り上げて、SVMをやることになった。
(いずれ折を見て、データセット中の有効な説明変数をランクづけして提示するvariable importance や
RFから導かれる類似度からなるproximity matrix も実装してみたい)。

・今回のSVMで多田さんから求められている機能上の要請としては次の2点がある。

1. ソフトマージンに対応できること(現状のCLMLのSVMではハードマージンのみ)。
2. 最急降下法ではなく、SMO(Sequential Minimal Optimization)と呼ばれる手法を用いて
分離超平面を求める最適化問題を解くこと。従来の方法(最急降下法)に比べて、計算量・メモリ使用量が
削減でき、より大きなデータセットを扱えるようになるらしい。

・他、気になった点など。

1. SVMは基本的には二群判別を行う機械学習アルゴリズムだが、多群判別を行えるようにするか否か。
2. 判別分析だけでなく、回帰分析も行えるようにするか否か。
3. Core Vector Machineという新しい手法も存在するらしい。

(12/28)ランダムフォレスト

・Proximity Matrix

http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm によると、
"one of the most useful tools in random forests"としてproximity matrixが挙げられている。
これはデータセットのサンプル数をNとするとき、N*Nの正方行列として以下のように定義される。
データiとデータjの近接度を、RFを構成するあるtreeにおいて、それを辿っていった際に同じ終端ノードに達するならば
1上げる。これを全treeについて繰り返し、最後に行列の全要素を、RFを構成するtree数で割る。
そうすると、対角成分に1が並んだ行列が得られる。これは要するに類似度そのもので、単位行列からproximity matrix を引けば
距離行列が得られる。

このスキームはNMFにおけるrho-k算出のプロセスと同型であり、この距離行列のcophenetic相関係数を取れば、そのまま
RF版のrho-kが得られる。またそれ以前に、ここで得られた距離行列を使って階層型クラスタリングを行うこともできる。
距離を用いるクラスタリングアルゴリズムにおいては、どの距離を使うかが非常に悩ましい問題であるが、
RFから導出された距離は、判別精度が他の機械学習アルゴリズムより優れている点から見ても有望であるように思う。
いずれにせよ、RFによってデータ間の類似度・距離が定義され、それによるクラスタリングが考えられる。

(12/24)ランダムフォレスト
・READMEにRandom-Forestのセクションを追加。
ランダムフォレストによる判別分析、回帰分析といった基本的機能はおおよそ実装できた。

・今後の追加機能予定。
1.　多田さんから判別予測結果について、結果だけでなくその信憑性についての値（例えば、87パーセントの確率で「著者A」のような）も
出せないか、ということなので、predict-forestでそうした値も返すようにする。

2.　決定木分析の利点は単に判別や回帰ができるだけでなく、帰結に至る推論プロセスが(SVMやニューラルネットワークと異なり)
可視的であるところにある。ランダムフォレストにおいても「有効な説明変数は何か」といったような、データセットそれ自体の
有益な情報を引き出すことが可能であるらしいので、そういった機能も調査し、追加していく予定。例えば、各説明変数を重要度順に並べた
リストを返す関数など。余裕があれば、わざと無効な説明変数(ノイズ)を加えたデータセットをつくり、SVM、K-nn、決定木、RFといった
各学習アルゴリズムのノイズに対する頑健さも測定してみたい。

3.　回帰ランダムフォレストの性能評価がまだ不十分なので、それについて調査していく。現状では残差平方和を用いている。
SVMの回帰版にヒントがありそうなので、そのあたりを調査中。より良い評価指標があれば置換する。


(12/22)ランダムフォレスト・決定木

・READMEにregression-tree-validationを追加。差し当たって評価には残差平方和を使い、
より良い評価指標があればそれに置き換える予定。

・test-random-forestを追加

(12/21)ランダムフォレスト・決定木

・回帰木ならびに回帰森について、気づいた点など
少し調べてみた印象として、非線形回帰モデルの評価というのは、それ自体が難しいひとつのトピックのようである。
判別予測モデルにおける混同行列ほどには明解で万人に受けいられている評価基準は存在しない様子。
線形回帰モデルからのアナロジーで直ちに思いつくのは決定係数（もしくは自由度調整済み決定係数）だが、
非線形回帰モデルに使用するのは妥当ではない、との統計の専門家のコメントをWeb上で発見した（群馬大、青木繁伸氏）。

非線形回帰モデルの評価基準として一番素朴なのは残差平方和(予測値と真値の差の二乗の総和)だが、問題点も多い。
第一に、その数値が何を意味しているのか、その数値の字面だけみていても分かり辛い。
第二に、データサンプル数を固定していないと比較できない。とはいえ、異なる学習器同士での、同一データを用いた
性能評価には、これでも使える。以下は、回帰木と回帰森の性能を試験的に残差平方和によって比較したものである。

・乳ガンデータ
回帰木での残差平方和が813なのに対して、回帰森は567で、回帰森の方が予測精度が良いことがわかる。
RANDOM-FOREST(16): (setf *tree* (make-regression-tree *bc-train* "Cell.size"))
RANDOM-FOREST(18): (verification-regression-tree *bc-test* "Cell.size" *tree*)
812.9077777777777 ;残差平方和
RANDOM-FOREST(19): (setf *forest* (make-regression-random-forest *bc-train* "Cell.size"))
RANDOM-FOREST(22): (verification-regression-forest *bc-test* "Cell.size" *forest*)
566.9093396353804 ;残差平方和

・Germanクレジットデータ
同様の比較をGermanクレジットデータでも行った。やはり残差平方和は回帰森の方が小さい。

RANDOM-FOREST(23): (setf *tree* (make-regression-tree *german-train* "クレジット利用額"))
RANDOM-FOREST(25): (verification-regression-tree *german-test* "クレジット利用額" *tree*)
1.541412724e+9
RANDOM-FOREST(26): (setf *forest* (make-regression-random-forest *german-train* "クレジット利用額"))
RANDOM-FOREST(27): (verification-regression-forest *german-test* "クレジット利用額" *forest*)
7.792298294011347e+8

混同行列を用いた判別予測モデルでの評価は、元のデータセットの「質」についてもある程度の情報をこちら側に
提供してくれるが、残差平方和を用いた非線形回帰モデルでの評価ではそういった情報がまるで得られないのが
難点である。あくまで相対的にこちらの学習器の方が精度が良い、というレベルまでしか分からない。
もうちょっと良い非線形回帰モデルの評価基準がないものか調査を続ける予定。

(12/18)ランダムフォレスト・決定木

・column-name->column-numberで、末端の関数がobject-column-nameから対応する列のインデックスを割り出すのが
無駄なのでそこを修正しようとするも、バグを作ってしまい、それがうまく直らないので一旦保留。

・test-decision-tree.clを修正。

・現状での実行速度

RANDOM-FOREST(43): (time (make-decision-tree *spam-train* "type"))
; 17182576 bytes have been tenured, auto global gc will happen
; the next time lisp is idle for 1 seconds.
; cpu time (non-gc) 41,650 msec user, 10 msec system
; cpu time (gc)     1,690 msec user, 0 msec system
; cpu time (total)  43,340 msec user, 10 msec system
; real time  43,472 msec
; space allocation:
;  479,554,365 cons cells, 2,296,482,176 other bytes, 0 static bytes
(((("charDollar" . 0.056)
   (("george" . 0.0) ("george" . 1.85) ("george" . 20.0) ("george" . 1.17) ("george" . 0.47) ("george" . 0.17)
    ("george" . 1.29) ("george" . 3.03) ("george" . 0.67) ("george" . 1.63) ...))
  ((|spam| . 994) (|nonspam| . 1506))
  ((2497 2493 2489 2486 2485 2480 2472 2464 2461 2456 ...) (2499 2498 2496 2495 2494 2492 2491 2490 2488 2487 ...)))
 (((("hp" . 0.41) (# # # # # # # # # # ...)) ((|nonspam| . 60) (|spam| . 547))
   ((83 118 158 174 188 276 354 426 579 627 ...) (10 11 13 14 17 19 21 27 29 30 ...)))
  (((# #) (# #) (# #)) ((#) (2423 2159 1051 426)) ((#) (2438 2410 2383 2168 2108 2050 2024 2017 1954 1908 ...)))
  (((# #) (# #) (# #)) ((#) (2206 2190 1758 1699 1658 1567 1348 838 680)) ((# # #) (# #) (# # #))))
 (((("charExclamation" . 0.092) (# # # # # # # # # # ...)) ((|nonspam| . 1446) (|spam| . 447))
   ((2 5 8 9 24 28 33 35 42 45 ...) (0 1 3 4 6 7 12 15 16 18 ...)))
  (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #)))
  (((# #) (# #) (# #)) ((# # #) (# #) (# # #)) ((# # #) (# # #) (# # #)))))

RANDOM-FOREST(30): (time (setf *forest* (make-random-forest *bc-train* "Class")))
; 50497600 bytes tenured without 1 seconds continuous idle time.
; Next gc will be global anyway.
; cpu time (non-gc) 5,320 msec user, 0 msec system
; cpu time (gc)     1,440 msec user, 0 msec system
; cpu time (total)  6,760 msec user, 0 msec system
; real time  6,782 msec
; space allocation:
;  58,531,484 cons cells, 457,674,832 other bytes, 0 static bytes

RANDOM-FOREST(35): (time (setf *forest* (make-random-forest *german-train* "顧客種別")))
; 50673936 bytes tenured without 1 seconds continuous idle time.
; Next gc will be global anyway.
; 16869440 bytes have been tenured, auto global gc will happen
; the next time lisp is idle for 1 seconds.
; cpu time (non-gc) 324,440 msec (00:05:24.440) user, 50 msec system
; cpu time (gc)     7,810 msec user, 10 msec system
; cpu time (total)  332,250 msec (00:05:32.250) user, 60 msec system
; real time  332,682 msec (00:05:32.682)
; space allocation:
;  1,666,912,899 cons cells, 17,350,302,880 other bytes, 0 static bytes

RANDOM-FOREST(12): (time (setf *forest* (make-random-forest *spam-train* "type")))
; 21358304 bytes have been tenured, auto global gc will happen
; the next time lisp is idle for 1 seconds.
; 50505744 bytes tenured without 1 seconds continuous idle time.
; Next gc will be global anyway.
; 16994736 bytes have been tenured, auto global gc will happen
; the next time lisp is idle for 1 seconds.
; 50676512 bytes tenured without 1 seconds continuous idle time.
; Next gc will be global anyway.
; 17002752 bytes have been tenured, auto global gc will happen
; the next time lisp is idle for 1 seconds.
; 50414080 bytes tenured without 1 seconds continuous idle time.
; Next gc will be global anyway.
; 17004608 bytes have been tenured, auto global gc will happen
; the next time lisp is idle for 1 seconds.
; 50460432 bytes tenured without 1 seconds continuous idle time.
; Next gc will be global anyway.
; 16777456 bytes have been tenured, auto global gc will happen
; the next time lisp is idle for 1 seconds.
; 50787520 bytes tenured without 1 seconds continuous idle time.
; Next gc will be global anyway.
; cpu time (non-gc) 2,597,630 msec (00:43:17.630) user, 850 msec system
; cpu time (gc)     63,550 msec (00:01:03.550) user, 190 msec system
; cpu time (total)  2,661,180 msec (00:44:21.180) user, 1,040 msec system
; real time  2,664,442 msec (00:44:24.442)
; space allocation:
;  25,002,631,677 cons cells, 143,526,173,040 other bytes, 0 static bytes

(12/16)ランダムフォレスト・決定木

・決定木のREADMEを修正

(12/15)ランダムフォレスト・決定木
・現状では実効速度が極めて遅いので、コードの見直しを行う。

Spamの学習用データから木を一本つくるのに、現在70秒ほどかかる。

DECISION-TREE(172):(time (make-decision-tree *spam-train* "type"))
; 17253152 bytes have been tenured, auto global gc will happen
; the next time lisp is idle for 1 seconds.
; 50676224 bytes tenured without 1 seconds continuous idle time.
; Next gc will be global anyway.
; cpu time (non-gc) 66,800 msec (00:01:06.800) user, 10 msec system
; cpu time (gc)     3,300 msec user, 0 msec system
; cpu time (total)  70,100 msec (00:01:10.100) user, 10 msec system
; real time  70,221 msec (00:01:10.221)
; space allocation:
;  487,145,666 cons cells, 1,867,560,384 other bytes, 0 static bytes
(((("charDollar" . 0.056)
   (("george" . 0.0) ("george" . 1.85) ("george" . 20.0) ("george" . 1.17) ("george" . 0.47)
    ("george" . 0.17) ("george" . 1.29) ("george" . 3.03) ("george" . 0.67) ("george" . 1.63) ...))
  (("spam" . 994) ("nonspam" . 1506))
  ((2497 2493 2489 2486 2485 2480 2472 2464 2461 2456 ...)
   (2499 2498 2496 2495 2494 2492 2491 2490 2488 2487 ...)))
 (((("hp" . 0.41) (# # # # # # # # # # ...)) (("nonspam" . 60) ("spam" . 547))
   ((83 118 158 174 188 276 354 426 579 627 ...) (10 11 13 14 17 19 21 27 29 30 ...)))
  (((# #) (# #) (# #)) ((#) (2423 2159 1051 426))
   ((#) (2438 2410 2383 2168 2108 2050 2024 2017 1954 1908 ...)))
  (((# #) (# #) (# #)) ((#) (2206 2190 1758 1699 1658 1567 1348 838 680)) ((# # #) (# #) (# # #))))
 (((("charExclamation" . 0.092) (# # # # # # # # # # ...)) (("nonspam" . 1446) ("spam" . 447))
   ((2 5 8 9 24 28 33 35 42 45 ...) (0 1 3 4 6 7 12 15 16 18 ...)))
  (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #)))
  (((# #) (# #) (# #)) ((# # #) (# #) (# # #)) ((# # #) (# # #) (# # #)))))

sum-up-resultsとaux-splitにどうも問題がある様子。

効率面で改善が見られたら、n重交差検定や目的変数が数値である回帰版のランダムフォレストを実装していく予定。


(12/10)ランダムフォレスト

・プロトタイプが完成したので、学習用サンプルと検証用サンプルを用いて、決定木とランダムフォレストの判別予測正解率を算出した。
なお、判別予測正解率の数値自体の大きさを単独で考慮しても意味はあまりない。説明変数が目的変数と関連が薄いものであれば、
どんなに良い学習アルゴリズムを用いても、50%前後の判別予測正解率しか望めない。
したがって、他の学習器(ならびに専門家等の人間)の判別予測正解率との比較が問題になる。

1.german-credit-data(学習サンプル:800、検証サンプル:200)

RANDOM-FOREST(6): (time (setf forest (make-random-forest learning-data "顧客種別")))
; cpu time (non-gc) 940,440 msec (00:15:40.440) user, 440 msec system
; cpu time (gc)     19,810 msec user, 110 msec system
; cpu time (total)  960,250 msec (00:16:00.250) user, 550 msec system
; real time  963,063 msec (00:16:03.063)
; space allocation:
;  3,170,793,730 cons cells, 212,890,331,616 other bytes, 109,232 static bytes

左から予測カテゴリ、正解カテゴリ、件数を表している。

RANDOM-FOREST(28): (verification-tree verification-data (make-variable-name-index verification-data) "顧客種別" tree)
((("不良顧客" . "不良顧客") . 22) (("優良顧客" . "不良顧客") . 36) (("優良顧客" . "優良顧客") . 95) (("不良顧客" . "優良顧客") . 47))

未剪定決定木の正解率：(22+95)/200 * 100 = 58.5%

RANDOM-FOREST(29): (verification-forest verification-data (make-variable-name-index verification-data) "顧客種別" forest)
((("不良顧客" . "不良顧客") . 2) (("優良顧客" . "不良顧客") . 56) (("優良顧客" . "優良顧客") . 142))

ランダムフォレスト（500本）の正解率: (2+142)/200 * 100 = 72.0%

なお、VMSで同じデータを分析にかけたところ、BoostingしたSVMが最も好成績で75%の正解率であった。


2. 乳ガンデータ(学習サンプル:338、検証サンプル:345)

RANDOM-FOREST(15): (verification-forest bc-test (make-variable-name-index bc-test) "Class" forest)
((("benign" . "malignant") . 1) (("malignant" . "benign") . 6) (("benign" . "benign") . 217)
 (("malignant" . "malignant") . 121))

ランダムフォレスト（500本）の正解率: (217+121)/345 * 100 = 98.0%

多田さんから頂いたメールによれば、同じデータを用いたVMSでの判別予測正解率は、

> k-nn(k=5) 97.4%
> 決定木 93.3%
> SVM(linear kernel) 96.5%
> SVM(gaussian kernel parameter=0.1) 95.0%
> Boostin(SVM gaussian kernel parameter=0.1) 95.6%

とのことである。

(12/7)ランダムフォレスト

・german-credit-data(1000サンプル、21変数)で、bootstrap sampleから
500本の決定木をランダムに生成した際の時間。

RANDOM-FOREST(151): (time (setf forest (make-forest german-credit-data "顧客種別")))
; cpu time (non-gc) 1,508,310 msec (00:25:08.310) user, 460 msec system
; cpu time (gc)     27,460 msec user, 160 msec system
; cpu time (total)  1,535,770 msec (00:25:35.770) user, 620 msec system
; real time  1,546,983 msec (00:25:46.983)
; space allocation:
;  4,483,309,512 cons cells, 351,768,402,560 other bytes, 0 static bytes
#((((("勤続年数" . "1年未満") (# # # # # # # # # # ...)) (("不良顧客" . 312) ("優良顧客" . 688))
    ((4 5 12 14 15 20 29 33 42 43 ...) (0 1 2 3 6 7 8 9 10 11 ...)))
   (((# #) (# #) (# #)) ((#) (139 241 243 529 570 590 646 958)) ((# # #) (# # #) (# # #)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #))))
  (((("普通・当座預金残高" . "口座未開設") (# # # # # # # # # # ...)) (("不良顧客" . 318) ("優良顧客" . 682))
    ((0 6 7 11 14 16 24 28 29 30 ...) (1 2 3 4 5 8 9 10 12 13 ...)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #))))
  (((("普通・当座預金残高" . "口座未開設") (# # # # # # # # # # ...)) (("優良顧客" . 684) ("不良顧客" . 316))
    ((2 4 5 13 14 15 17 20 25 33 ...) (0 1 3 6 7 8 9 10 11 12 ...)))
   (((# #) (# #) (# #)) ((# # #) (# #) (# #)) ((# # #) (# #) (# # #)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #))))
  (((("定期預金残高" . "100マルク未満") (# # # # # # # # # #)) (("優良顧客" . 674) ("不良顧客" . 326))
    ((1 2 4 6 7 8 10 11 12 13 ...) (0 3 5 9 14 16 19 22 26 28 ...)))
   (((# #) (# #) (# #)) ((# # #) (# #) (# # #)) ((# # #) (# # #) (# # #)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #))))
  (((("勤続年数" . "1年未満") (# # # # # # # # # # ...)) (("優良顧客" . 683) ("不良顧客" . 317))
    ((9 10 15 30 37 40 46 51 52 63 ...) (0 1 2 3 4 5 6 7 8 11 ...)))
   (((# #) (# #) (# #)) ((#) (129 265 542 832 878 922 986)) ((# # #) (# #) (# # #)))
   (((# #) (# #) (# #)) ((# # #) (# #) (# # #)) ((# # #) (# # #) (# # #))))
  (((("普通・当座預金残高" . "口座未開設") (# # # # # # # # # # ...)) (("不良顧客" . 296) ("優良顧客" . 704))
    ((1 2 4 6 10 11 12 13 14 15 ...) (0 3 5 7 8 9 17 18 20 22 ...)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #))))
  (((("普通・当座預金残高" . "口座未開設") (# # # # # # # # #)) (("不良顧客" . 306) ("優良顧客" . 694))
    ((1 2 3 4 7 10 12 17 24 25 ...) (0 5 6 8 9 11 13 14 15 16 ...)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# #)) ((# # #) (# # #) (# # #)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #))))
  (((("クレジット履歴" . "問題履歴あり") (# # # # # # # # # # ...)) (("不良顧客" . 309) ("優良顧客" . 691))
    ((0 1 2 5 6 7 10 16 19 25 ...) (3 4 8 9 11 12 13 14 15 17 ...)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #))))
  (((("クレジット利用額" . 10961) (# # # # # # # # # # ...)) (("不良顧客" . 275) ("優良顧客" . 725))
    ((22 33 46 95 175 200 202 260 288 289 ...) (0 1 2 3 4 5 6 7 8 9 ...)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# #)) ((#) (22 46 202 260 289 414 440 450 549 666 ...)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# # #)) ((# # #) (# # #) (# # #))))
  (((("普通・当座預金残高" . "口座未開設") (# # # # # # # # # # ...)) (("優良顧客" . 701) ("不良顧客" . 299))
    ((3 5 9 11 12 13 15 19 20 30 ...) (0 1 2 4 6 7 8 10 14 16 ...)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# #)) ((# # #) (# # #) (# # #)))
   (((# #) (# #) (# #)) ((# # #) (# # #) (# #)) ((# # #) (# # #) (# # #))))
  ...)


(12/3)階層型クラスタリングの見直し

cophenetic-matrixのアルゴリズム自体を少し変更し、効率改善を試みた。

旧hcでのrho-kプロファイル結果

NMF(6): (prof:show-call-graph)
Time profile of sampled pc values by function, children, and parents.

Total times below 1.0% will be suppressed.
Parent and child times less 2.0% of the node will be suppressed.
Sampling stopped after 13959 samples taken for the time profiler.

Sample represents 151.6 seconds of processor time (out of a total of 151.6)

  %     %                       Parent
 self total   total local  Function
 Time  Time    secs   %         Child

  0.0 100.0   151.6   0.0   ... "start"
              151.6 100.0        ... "start_reborn_lisp"
-----------------------------------------------------
              151.6 100.0        ... "start"
  0.0 100.0   151.6   0.0   "start_reborn_lisp"
              151.6 100.0        "first_lisp_thread"
-----------------------------------------------------
              151.6 100.0        "start_reborn_lisp"
  0.0 100.0   151.6   0.0   "first_lisp_thread"
              151.6 100.0        EXCL::LISP-THREAD-START
-----------------------------------------------------
              151.6 100.0        "first_lisp_thread"
  0.0 100.0   151.6   0.0   EXCL::LISP-THREAD-START
              151.6 100.0        EXCL::RUN-INITIAL-THREAD
-----------------------------------------------------
              151.6 100.0        EXCL::LISP-THREAD-START
  0.0 100.0   151.6   0.0   ... EXCL::RUN-INITIAL-THREAD
              151.6 100.0        ... EXCL::THREAD-RESET-CATCHER
-----------------------------------------------------
              151.6 100.0        ... EXCL::RUN-INITIAL-THREAD
  0.0 100.0   151.6   0.0   ... EXCL::THREAD-RESET-CATCHER
              151.6 100.0        ... EVAL
-----------------------------------------------------
              151.6 100.0        ... EXCL::THREAD-RESET-CATCHER
  0.0 100.0   151.6   0.0   EVAL
              151.6 100.0        UNWIND-PROTECT
-----------------------------------------------------
              151.6 100.0        EVAL
  0.0 100.0   151.6   0.0   UNWIND-PROTECT
              151.6 100.0        RHO-K
-----------------------------------------------------
              151.6 100.0        UNWIND-PROTECT
  0.0 100.0   151.6   0.0   RHO-K
               89.2  58.9        COPHENETIC-MATRIX
               62.4  41.1        ROW-AVERAGE-CONSENSUS-MATRIX
-----------------------------------------------------
               89.2 100.0        RHO-K
  0.0  58.9    89.2   0.0   COPHENETIC-MATRIX
               83.2  93.2        HC::SORT-FOR-HC
                5.7   6.4        AVERAGE
-----------------------------------------------------
               83.2 100.0        COPHENETIC-MATRIX
  0.0  54.9    83.2   0.0   HC::SORT-FOR-HC
               83.2 100.0        SET-DIFFERENCE
-----------------------------------------------------
               83.2 100.0        HC::SORT-FOR-HC
  0.0  54.9    83.2   0.0   SET-DIFFERENCE
               83.2 100.0        MEMBER
-----------------------------------------------------
               83.2 100.0        SET-DIFFERENCE
 35.4  54.9    83.2  64.5   MEMBER
               18.1  21.7        EXCL::EQUAL-NOT-EQ
               11.4  13.7        (:INTERNAL HC::SORT-FOR-HC 0)
-----------------------------------------------------
               62.4 100.0        RHO-K
  0.0  41.1    62.4   0.0   ROW-AVERAGE-CONSENSUS-MATRIX
               62.2  99.8        NMF-EUC
-----------------------------------------------------
               62.2 100.0        ROW-AVERAGE-CONSENSUS-MATRIX
  0.3  41.1    62.2   0.8   ... NMF-EUC
               29.8  47.8        M-TIMES-N
               29.7  47.7        A*B-I-J
-----------------------------------------------------
               29.7  61.3        NMF-EUC
               18.8  38.7        M-TIMES-N
 29.1  32.0    48.5  91.0   A*B-I-J
                3.5   7.2        "new_double_float"
-----------------------------------------------------
               29.8 100.0        NMF-EUC
  3.8  19.6    29.8  19.1   M-TIMES-N
               18.8  63.1        A*B-I-J
                4.3  14.5        "new_double_float"
-----------------------------------------------------
               18.1 100.0        MEMBER
 11.9  11.9    18.1 100.0   EXCL::EQUAL-NOT-EQ
-----------------------------------------------------
               11.4 100.0        MEMBER
  7.5   7.5    11.4 100.0   (:INTERNAL HC::SORT-FOR-HC 0)
-----------------------------------------------------
                4.3  47.1        M-TIMES-N
                3.5  38.2        A*B-I-J
                1.0  11.2        NMF-EUC
                0.2   2.1        EXCL::/_2OP
  2.9   6.1     9.2  47.9   "new_double_float"
                3.3  35.5        "new_other"
                1.5  16.6        "sigprocmask"
-----------------------------------------------------
                5.7 100.0        COPHENETIC-MATRIX
  0.5   3.7     5.7  12.0   AVERAGE
                4.1  71.5        HC::CLUSTER-MEMBER
                0.6  10.3        HC::MERGE-TOP
                0.2   4.0        EXCL::EQL-NOT-EQ
-----------------------------------------------------
                3.3  79.4        "new_double_float"
                0.4  10.6        A*B-I-J
                0.4   8.7        M-TIMES-N
  2.7   2.7     4.1 100.0   "new_other"
-----------------------------------------------------
                4.1 100.0r       AVERAGE
                3.9  94.9r       HC::CLUSTER-MEMBER
  0.4   2.7     4.1  15.8   HC::CLUSTER-MEMBER
                3.9  82.6r       HC::CLUSTER-MEMBER
                2.3  49.1r       APPEND
                0.5  11.2r       "gc_setf_protect"
                0.5  10.5r       "qcons"
-----------------------------------------------------
                2.3 100.0        HC::CLUSTER-MEMBER
  1.2   1.5     2.3  82.0   APPEND
                0.2   6.6        "sigprocmask"
                0.1   6.2        "st_restify"
                0.1   3.3        "cons_from_new_page"
-----------------------------------------------------
                1.5  80.9        "new_double_float"
                0.2  11.0        "make_svector"
                0.2   8.1        APPEND
  1.2   1.2     1.9 100.0   "sigprocmask"
-----------------------------------------------------


新hcでのrho-kプロファイル結果

NMF(14): (prof:show-call-graph)
Time profile of sampled pc values by function, children, and parents.

Total times below 1.0% will be suppressed.
Parent and child times less 2.0% of the node will be suppressed.
Sampling stopped after 5952 samples taken for the time profiler.

Sample represents 63.8 seconds of processor time (out of a total of 63.8)

  %     %                       Parent
 self total   total local  Function
 Time  Time    secs   %         Child

  0.0 100.0    63.8   0.0   ... "start"
               63.8 100.0        ... "start_reborn_lisp"
-----------------------------------------------------
               63.8 100.0        ... "start"
  0.0 100.0    63.8   0.0   "start_reborn_lisp"
               63.8 100.0        "first_lisp_thread"
-----------------------------------------------------
               63.8 100.0        "start_reborn_lisp"
  0.0 100.0    63.8   0.0   "first_lisp_thread"
               63.8 100.0        EXCL::LISP-THREAD-START
-----------------------------------------------------
               63.8 100.0        "first_lisp_thread"
  0.0 100.0    63.8   0.0   EXCL::LISP-THREAD-START
               63.8 100.0        EXCL::RUN-INITIAL-THREAD
-----------------------------------------------------
               63.8 100.0        EXCL::LISP-THREAD-START
  0.0 100.0    63.8   0.0   ... EXCL::RUN-INITIAL-THREAD
               63.8 100.0        ... EXCL::THREAD-RESET-CATCHER
-----------------------------------------------------
               63.8 100.0        ... EXCL::RUN-INITIAL-THREAD
  0.0 100.0    63.8   0.0   ... EXCL::THREAD-RESET-CATCHER
               63.8 100.0        ... EVAL
-----------------------------------------------------
               63.8 100.0        ... EXCL::THREAD-RESET-CATCHER
  0.0 100.0    63.8   0.0   EVAL
               63.8 100.0        UNWIND-PROTECT
-----------------------------------------------------
               63.8 100.0        EVAL
  0.0 100.0    63.8   0.0   UNWIND-PROTECT
               63.8 100.0        RHO-K
-----------------------------------------------------
               63.8 100.0        UNWIND-PROTECT
  0.0 100.0    63.8   0.0   RHO-K
               61.0  95.7        ROW-AVERAGE-CONSENSUS-MATRIX
                2.7   4.3        COPHENETIC-MATRIX
-----------------------------------------------------
               61.0 100.0        RHO-K
  0.0  95.7    61.0   0.0   ROW-AVERAGE-CONSENSUS-MATRIX
               60.9  99.8        NMF-EUC
-----------------------------------------------------
               60.9 100.0        ROW-AVERAGE-CONSENSUS-MATRIX
  1.0  95.5    60.9   1.1   NMF-EUC
               29.6  48.6        M-TIMES-N
               28.4  46.6        A*B-I-J
-----------------------------------------------------
               28.4  60.9        NMF-EUC
               18.3  39.1        M-TIMES-N
 66.0  73.2    46.6  90.3   A*B-I-J
                3.4   7.4        "new_double_float"
-----------------------------------------------------
               29.6 100.0        NMF-EUC
  9.5  46.4    29.6  20.4   M-TIMES-N
               18.3  61.7        A*B-I-J
                4.2  14.1        "new_double_float"
-----------------------------------------------------
                4.2  47.7        M-TIMES-N
                3.4  39.3        A*B-I-J
                0.9  10.3        NMF-EUC
                0.2   2.1        EXCL::/_2OP
  6.6  13.7     8.7  48.3   "new_double_float"
                3.0  34.4        "new_other"
                1.5  17.3        "sigprocmask"
-----------------------------------------------------
                3.0  70.2        "new_double_float"
                0.7  15.2        A*B-I-J
                0.5  12.2        M-TIMES-N
  6.7   6.7     4.3  99.8   "new_other"
-----------------------------------------------------
                2.7 100.0        RHO-K
  0.1   4.3     2.7   1.6   COPHENETIC-MATRIX
                2.4  89.4        AVERAGE
                0.2   6.7        HC2::MAKE-SUBLST
-----------------------------------------------------
                2.4 100.0        COPHENETIC-MATRIX
  1.0   3.8     2.4  26.9   AVERAGE
                1.2  48.5        HC2::CLUSTER-MEMBER
                0.5  19.4        HC2::MERGE-TOP
                0.1   4.0        EXCL::EQL-NOT-EQ
-----------------------------------------------------
                1.5  87.0        "new_double_float"
                0.2  11.1        "make_svector"
  2.7   2.7     1.7 100.0   "sigprocmask"
-----------------------------------------------------
                1.2 100.0r       AVERAGE
                1.1  94.5r       HC2::CLUSTER-MEMBER
  0.8   1.8     1.2  45.5   HC2::CLUSTER-MEMBER
                1.1  65.8r       HC2::CLUSTER-MEMBER
                0.4  25.9r       APPEND
                0.1   5.7r       "qcons"
                0.1   3.8r       "gc_setf_protect"
-----------------------------------------------------
                0.4  47.7        M-TIMES-N
                0.4  47.7        A*B-I-J
                0.0   2.3        EXCL::/_2OP
                0.0   2.3        NMF-EUC
  1.4   1.4     0.9 100.0   "(after-libnss_files.so.2-lib)"
-----------------------------------------------------

テストして良いようならば差し替えるつもりです。


(11/30)決定木

目的変数が数値型データの場合に用いる回帰木を実装、READMEに反映した。
分岐指標は分散の差を取り、それが最も大きくなる分割を繰り返し行っている。
以下は、syobu.csvデータで、"花びら長"を目的変数とした場合の回帰木の計算例である。

DECISION-TREE(156): (setf syobu (read-data-from-file "sample/syobu.csv" :type :csv
						    :csv-type-spec '(string integer integer integer integer)))
#<UNSPECIALIZED-DATASET>
DIMENSIONS: 種類 | がく長 | がく幅 | 花びら長 | 花びら幅
TYPES:      UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN
DATA POINTS: 150 POINTS
DECISION-TREE(157): (regression-tree syobu "花びら長" :epsilon 20)
[10 <= 花びら幅?] (mean = 37.58, n = 150)
   Yes->[種類:Versicolor?] (mean = 49.06, n = 100)
      Yes->(mean = 42.60, n = 50)
      No->(mean = 55.52, n = 50)
   No->(mean = 14.62, n = 50)
NIL


車のスピードとブレーキ時の制動距離データ(sample/cars.csv)における適用例。

DECISION-TREE(166): (setf cars (read-data-from-file "sample/cars.csv" :type :csv
						    :csv-type-spec '(double-float double-float)))
#<UNSPECIALIZED-DATASET>
DIMENSIONS: speed | distance
TYPES:      UNKNOWN | UNKNOWN
DATA POINTS: 50 POINTS
DECISION-TREE(167): (regression-tree cars "distance" :epsilon 35)
[18.0 <= speed?] (mean = 42.98, n = 50)
   Yes->[24.0 <= speed?] (mean = 65.26, n = 19)
      Yes->(mean = 92.00, n = 5)
      No->(mean = 55.71, n = 14)
   No->[13.0 <= speed?] (mean = 29.32, n = 31)
      Yes->(mean = 39.75, n = 16)
      No->[10.0 <= speed?] (mean = 18.20, n = 15)
         Yes->(mean = 23.22, n = 9)
         No->(mean = 10.67, n = 6)
NIL

注意として、回帰木ではepsilonパラメータを適切に選ばないと徒らに複雑な木になってしまう。
分類木ではepsilonパラメータの動く範囲は0.0~1.0だが、回帰木では分散差を考えているので
epsilonといいつつも、大きな値を設定しないといけない場合も多く、ユーザによる試行錯誤がある程度必要。

現状では剪定・刈り込みの方法は最もシンプルなものしか実装していないが、ランダムフォレストでは未剪定の木を用いるらしいので
決定木はこれでひとまず終了し、ランダムフォレストに向けてブートストラップ、バギング、ブースティングの調査を進める予定。


(11/24)決定木

決定木の中で最も基本的なCARTを実装した。
目的変数はカテゴリカルデータとしている。今後は目的変数が数値であるような決定木（回帰木）を実装していく予定。
以下は、syobu.csvデータで、"種類"を目的変数とした場合の決定木の計算例である。

DECISION-TREE(45): (setf syobu (read-data-from-file "sample/syobu.csv" :type :csv
						    :csv-type-spec '(string integer integer integer integer)))
#<UNSPECIALIZED-DATASET>
DIMENSIONS: 種類 | がく長 | がく幅 | 花びら長 | 花びら幅
TYPES:      UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN | UNKNOWN
DATA POINTS: 150 POINTS

DECISION-TREE(46): (setf root (make-root-node syobu "種類"))
((("花びら幅" . 10)
  (("がく長" . 59) ("がく長" . 62) ("がく長" . 65) ("がく長" . 63) ("がく長" . 67) ("がく長" . 68) ("がく長" . 58) ("がく長" . 69) ("がく長" . 60)
   ("がく長" . 64) ...))
 (("Virginica" . 50) ("Versicolor" . 50) ("Setosa" . 50))
 ((50 51 52 53 54 55 56 57 58 59 ...) (0 1 2 3 4 5 6 7 8 9 ...)))

DECISION-TREE(47): (setf tree (make-decision-tree syobu "種類" root))
(((("花びら幅" . 10)
   (("がく長" . 59) ("がく長" . 62) ("がく長" . 65) ("がく長" . 63) ("がく長" . 67) ("がく長" . 68) ("がく長" . 58) ("がく長" . 69) ("がく長" . 60)
    ("がく長" . 64) ...))
  (("Virginica" . 50) ("Versicolor" . 50) ("Setosa" . 50))
  ((50 51 52 53 54 55 56 57 58 59 ...) (0 1 2 3 4 5 6 7 8 9 ...)))
 (((("花びら幅" . 18) (# # # # # # # # # # ...)) (("Virginica" . 50) ("Versicolor" . 50))
   ((70 100 101 102 103 104 105 107 108 109 ...) (50 51 52 53 54 55 56 57 58 59 ...)))
  (((# #) (# #) (# #)) ((#) (100 101 102 103 104 105 107 108 109 110 ...)) ((# # #) (# #) (# #)))
  (((# #) (# #) (# #)) ((# # #) (# # #) (# #)) ((# # #) (# #) (# #))))
 ((("Setosa" . 50)) (0 1 2 3 4 5 6 7 8 9 ...)))

DECISION-TREE(48): (print-decision-tree 0 tree)
[10 <= 花びら幅?] ((Virginica . 50) (Versicolor . 50) (Setosa . 50))
   Yes->[18 <= 花びら幅?] ((Virginica . 50) (Versicolor . 50))
      Yes->[49 <= 花びら長?] ((Virginica . 45) (Versicolor . 1))
         Yes->(Virginica:43)
         No->[31 <= がく幅?] ((Virginica . 2) (Versicolor . 1))
            Yes->(Versicolor:1)
            No->(Virginica:2)
      No->[50 <= 花びら長?] ((Virginica . 5) (Versicolor . 49))
         Yes->[16 <= 花びら幅?] ((Virginica . 4) (Versicolor . 2))
            Yes->[53 <= 花びら長?] ((Virginica . 1) (Versicolor . 2))
               Yes->(Virginica:1)
               No->(Versicolor:2)
            No->(Virginica:3)
         No->[17 <= 花びら幅?] ((Virginica . 1) (Versicolor . 47))
            Yes->(Virginica:1)
            No->(Versicolor:47)
   No->(Setosa:50)
NIL

(参考:『集合知プログラミング』のpp.167と本質的に同一の決定木の出力例。評価にはエントロピーを用いている)

DECISION-TREE(49): (print-decision-tree 0 tree2)
[referer:google?] ((Basic . 6) (None . 7) (Premium . 3))
   Yes->[21 <= page?] ((Basic . 1) (None . 1) (Premium . 3))
      Yes->(Premium:3)
      No->[FAQ:No?] ((Basic . 1) (None . 1))
         Yes->(None:1)
         No->(Basic:1)
   No->[referer:slashdot?] ((Basic . 5) (None . 6))
      Yes->(None:3)
      No->[FAQ:No?] ((Basic . 5) (None . 3))
         Yes->[21 <= page?] ((None . 3) (Basic . 1))
            Yes->(Basic:1)
            No->(None:3)
         No->(Basic:4)
NIL

(11/13)RF
・ランダムフォレストならびに決定木に関して、実装に必要な資料は概ね揃った。
ランダムフォレスト実装の前段階として、決定木の実装が必要。

・決定木には幾つか種類（ID3,CART,C4.5など）があるが、さしあたりCARTのプロトタイプを作ることが目標。

・決定木ではカテゴリカルデータを扱う必要があるが、CL Machine-Learning所収の機械学習アルゴリズムには
明示的にカテゴリカルデータを扱った事例がなく、まずはカテゴリカルデータの取扱いから調査。

・決定木実装のためのさらなる小目標として、カテゴリカルデータを含むデータセットから、
グループ分割のためのGini係数、エントロピー、情報利得、情報利得比を計算する関数を実装していく予定。


(11/10)NMF、RF(Random Forest)
・CL Machine-Learning にスパースネス制約を付加したNMFを追加。
これでNMFについては一旦終了し、今後はRF(Random Forest)について調査・研究を進める予定。


(11/5)NMF
・READMEを修正、nmf-search,nmf-corpus-searchを追加。


(11/4)NMF
・READMEを更新、nmf-analysis,nmf-corpus-analysisを追加。


(10/30)NMF

・READMEを更新
カルバック・ライブラー情報量を目的関数とするNMF、nmf-clustering、rho-kを追加・反映した。
他のものも随時追加していく。

・スパースネス制約を付加したNMFアルゴリズムも概ね実装できたので、これもいずれREADMEに追加予定。


(10/27)NMF

・スパースネス制約を付加したNMFについて

主に音声データの特徴抽出を扱うコンテキストで、スパースネス制約を付加したNMFというのが注目されている。
スパースネス表現とは、データを基底の線形結合で表現する際、殆どの成分がゼロであることをいう。すなわち、
ごく少数の特徴的な成分のみが効いているようなデータの表現である。スパースネス制約を付加したNMFとは、
通常のNMFに加えて、因子行列のどちらか（あるいは両方）の列ないし行ベクトルにスパースネスの条件を付加したものであり、
これは複数の人間が話している音声データの特徴抽出（いわゆるカクテル・パーティ問題）への応用が期待されている。

一方で、テキストの特徴抽出やクラスタリングへの応用は今のところあまり望める気配がしない。というのも、
単語-文書行列が元々スパースだからである。目下よく使っているスポーツ関連100記事からなる文書集合の各行ベクトルの
スパースネスの平均を取ったら、以下のようになった（注:1.0に近いほどスパースである）。

PRE-NMF(41): (average-sparseness matrix)
0.8774130105889116

したがって、スパースネス制約を付加したNMFはテキストデータへの応用の見込みは薄いが、音声・画像データの特徴抽出では
重要性が高いようなので、もう少し調査した上で実装してみる予定。そして音声・画像データについてもNMFを適用して
比較・検討を試みたい。


・NMFにおける基本的な問題

1.　kの決定。ここでkとは、NMFでデータをk次元ベクトル空間に縮約する際のkである。同時にこれはNMFで自然なクラスタリングを
行う際のクラスタの個数でもある。ある観点からみた時の最適なkを選ぶ指標(rho-kならびに文書被覆度によるC^3M法など)が
幾つか提案されているが、実際に実装して試してみた感想としては、どうもあまりぱっとしない。

2.　データのベクトル表現。これは必ずしもNMFに限った話ではないのでここに入れるのは不適当だが、NMFによる特徴抽出やクラスタリングが
うまくいくか否かは、元データのベクトル表現がどれだけうまくできているかに「強く」依存していることがわかった。
このベクトル表現過程は元データの種類や性質によって異なる。話をテキストデータに限ってみても、ベクトル表現の提案手法は数十以上ある。
この部分はかなり個別的なノウハウがあるようで、一般化できない。テキストならこれこれ、音声ならこれこれ、というように
下ごしらえの方法は分野により異なる。ベクトル表現する際のバイアスによってNMFの結果や安定度は非常に大きく左右されるので、
このプロセスを抜きにして幾つかあるNMFアルゴリズムやkの良否を比較しても意味は薄い。


(10/21)NMF
NMFのみを用いた情報検索手法について(2)

NMFによる文書分類・特徴抽出の面白い点としては、文書と単語の双対性(duality)が挙げられる。
つまり、単語について分類や特徴抽出ができるならば、似たような手法で文書についても分類や特徴抽出ができる。
これはもっと一般の場合でも成り立つ。データ（テキスト、画像、音声、etc）をベクトルで表現する際、
その基底に相当するデータの構成要素を指定しなければならない。例えば、文書をベクトル表現するなら、単語が
その構成要素（基底）となる。NMFは思想的には、抽象的なメタ基底を想定することで次元縮約を行う手法だが、
その際、次元縮約して表現したいデータ（例えば文書）と共に、元データの単なる構成要素にすぎなかった基底（例えば単語）も、
NMFが導くメタ基底の線形結合で同時に表現される。

いずれにせよ、単語でできることは文書でもでき、逆もまた然り、という関係がNMFでは成り立つので、
今まで単語ベースで行っていたテーマ別分類や、情報検索が、文書ベースで行える。このアイディアに基づく実行例を示す。


1.　あるテーマを体現すると思われる文書を複数選択し、そのテーマをNMFの特徴基底に誘導することで、
文書集合をテーマ別に分類する。

文書集合はスポーツ関連100記事、索引語数1202語のものを使用し、
テーマとする文書は以下の2つを用いた。

テーマ記事:00267780(id 46) 期待されるテーマ:マラソン

　はら・ゆみこ
　大阪国際女子マラソン　走れるって喜び　鮮烈デビュー暗転、けが続き１年半辛酸　
　マラソンデビューとなった２００５年名古屋国際の走りは衝撃的だった。苦痛に顔をゆがめながらも、
軽快なピッチ走法で２時間２４分１９秒の好記録をマークし、初マラソンで優勝。勢いに乗って、
夏の世界選手権ヘルシンキ大会は日本選手最高位の６位入賞を果たした。まさか、その後、１年半近くも、
マラソンを走れなくなるとは、本人も予想していなかった。
　ヘルシンキ大会前に痛めた右足かかとから始まり、くるぶしも故障、さらに右足甲に３か所の疲労骨折が判明した。
痛みが引き練習を再開したら、再発する繰り返し。ヘルシンキでは１０キロ付近で引き離されたとはいえ、
優勝したポーラ・ラドクリフ（英）に勝負を挑んだ。それだけに「夢が目標に近づいた感じがあったのに、
それがどんどん遠ざかってしまって悔しかった。『何で走れないのか』とイライラした」。
　昨秋からようやく継続的な練習ができるようになった。足慣らしの駅伝では本来の走りができず、
悔しい思いもしたが、その分、大阪にかける思いは強い。「結果を出すことで（お世話になった人への）感謝の気持ちを表したい」。
年末から約１か月の中国・昆明合宿も「気持ちよくできた」と充実したトレーニングをこなせたようだ。
　「世界選手権に出て前（６位）より上を目指したい。できればメダルを狙いたい」と前向きな姿勢も取り戻した。
「走る喜びを感じている。レースが楽しみ」と、気負いなく話す２５歳は、初めて挑む大阪で、
再びアグレッシブな走りを見せる覚悟を決めている。（新宮広万）

　写真＝（上）名古屋国際女子マラソンでは初優勝を飾った（２００５年３月）（下）１年半ぶりのマラソンに挑む原


テーマ記事:00265130(id 71) 期待されるテーマ:スケート、アイスホッケー

群馬県渋川市などで開かれている第６２回国体スケート・アイスホッケー競技会「群馬国体」は３０日、
スピード、ショートトラック、フィギュア、アイスホッケーが行われた。
スケート
スピード
少年男子五千メートル予選（４組３位までが決勝へ）２組〈１〉襲田（日光高）７分１３秒６７
ショート
成年男子千メートル予選（１０組２位までが準々決勝へ）７組　〈２〉大橋（阪南大）
　アイスホッケー
成年準決勝
東京　５（１―１　２―０　２―１）２　栃木
得点者【東】田中孝、山本２、塚田、田中翔【栃】星野、小島


・実行結果

PRE-NMF(25): (nmf-analysis (article-theme-weighted-matrix tf*idf*cosine-matrix '(46 71)) 2)
; cpu time (non-gc) 4,510 msec user, 10 msec system
; cpu time (gc)     2,920 msec user, 0 msec system
; cpu time (total)  7,430 msec user, 10 msec system
; real time  7,486 msec
; space allocation:
;  1,206 cons cells, 6,335,875,840 other bytes, 0 static bytes
Feature 0
#<DIMENSION NAME: マラソン, TYPE: NUMERIC, INDEX: 887.>    0.17306133308662405
#<DIMENSION NAME: ヘルシンキ, TYPE: NUMERIC, INDEX: 1198.>    0.1404510903051809
#<DIMENSION NAME: 走り, TYPE: NUMERIC, INDEX: 116.>    0.10379033331855358
#<DIMENSION NAME: 大阪, TYPE: NUMERIC, INDEX: 799.>    0.09030221503761121
#<DIMENSION NAME: 喜び, TYPE: NUMERIC, INDEX: 509.>    0.07322172788490744
#<DIMENSION NAME: デビュー, TYPE: NUMERIC, INDEX: 492.>    0.07240516836138973
#<DIMENSION NAME: 国際, TYPE: NUMERIC, INDEX: 411.>    0.07016745767060927
#<DIMENSION NAME: 名古屋, TYPE: NUMERIC, INDEX: 292.>    0.06731656186465358
#<DIMENSION NAME: 思い, TYPE: NUMERIC, INDEX: 970.>    0.06151382790931218
#<DIMENSION NAME: 世界, TYPE: NUMERIC, INDEX: 1152.>    0.04801551170103985

Feature 1
#<DIMENSION NAME: アイスホッケー, TYPE: NUMERIC, INDEX: 341.>    0.18597870586403342
#<DIMENSION NAME: 田中, TYPE: NUMERIC, INDEX: 1116.>    0.14000064987114832
#<DIMENSION NAME: 群馬, TYPE: NUMERIC, INDEX: 1043.>    0.13979565872563068
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>    0.13521019747147647
#<DIMENSION NAME: 国体, TYPE: NUMERIC, INDEX: 538.>    0.13340642674465208
#<DIMENSION NAME: スケート, TYPE: NUMERIC, INDEX: 707.>    0.11988105211662199
#<DIMENSION NAME: スピード, TYPE: NUMERIC, INDEX: 435.>    0.11538085260744022
#<DIMENSION NAME: 予選, TYPE: NUMERIC, INDEX: 391.>    0.11248096139465284
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>    0.1071176911608939
#<DIMENSION NAME: 星野, TYPE: NUMERIC, INDEX: 767.>    0.10417690159604953

Feature 0
00267780   8.885284322561146
00267800   1.3826316819293953
00261590   1.1553539819384024
00267810   1.1115043046203008
00264150   0.8180063688156007
00267690   0.42048455359905446
00261720   0.36163874927415834
00266680   0.2635188427588634
00267610   0.25874038554657025
00260840   0.2360150781150083

Feature 1
00265130   7.6128568706316955
00264810   1.3569955148240822
00264720   1.3249216672831232
00264380   1.0003631116332385
00265920   0.9982555209419208
00265250   0.9526321118153122
00264550   0.8774481209487742
00265320   0.8445497147447607
00264470   0.840635267603523
00264850   0.7901327263156261
4.0503550326051165

・考察
まず、テーマに設定した記事00267780と記事00265130が、2つの特徴をもっとも反映するトップ記事にそれぞれ選ばれている。
また、この2テーマをもっとも反映する単語群は、特徴0ではマラソン関係のもの、特徴1ではスケート、アイスホッケー関係のものが
選ばれていることが分かる。すなわち、このNMFでは全記事、全索引語を、「テーマ記事00267780成分の強さ」と
「テーマ記事00265130成分の強さ」という観点から分類している。そこで、特徴0においてテーマ記事00267780に次ぐ記事00267800は、
当然マラソン関係の記事であることが期待される。実際に見てみると、テーマ記事と同トピックの大阪国際女子マラソンの記事が
選ばれていることが分かる。また参考に、特徴1で次点の記事、00264810を下に紹介する。

記事:00267800

 さかた・まさみ
　大阪国際女子マラソン　１メートル５１、でっかい夢　
　忘れられない言葉がある。京セラに入社する時、大森国男監督から、こう声をかけられた。「一緒に五輪を目指そう」。
その一言を胸に練習に励んできた。
　目標に向かって大きな一歩となったのが、初マラソンだった昨年の大阪国際。一般参加だったにもかかわらず、
２時間２７分１３秒で４位に食い込み、周囲をあっと言わせた。
　２度目のマラソンに向けて、経験が財産になっている。「長い距離の練習をしても、今年は余裕がある」。確かな自信がみなぎる。
　課題としてきたのが、ラスト１０キロだった。昨年、３５キロまでの各５キロは１６〜１７分台で乗り切ったが、
３５キロからの５キロが１８分４０秒もかかった。その反省から「練習でも、苦しい時に粘っていけるよう意識してきた」。
１年間の練習の成果を、大阪で出すつもりだ。
　神戸市出身で、陸上を本格的に始めたのは中学から。兵庫県の強豪、須磨学園に進み、３年の時には全国高校駅伝を走った経験も持つ。
　マラソン選手にあこがれ、世界で戦うことを夢見始めたのも、そのころだった。シドニー五輪で金メダルに輝いた高橋尚子を見て感動した。
「私も、より長い距離が好き。ああいうランナーになりたいと思った」
　夢は、少しずつだが現実味を帯び始めている。「大阪の世界選手権に選ばれる走りをしたい」。
１メートル５１、３８キロのきゃしゃな体は、意欲がみなぎっている。（霜田聖）

　写真＝再度の大阪挑戦を「楽しみ」と語る坂田


記事:00264810

　群馬県渋川市などで開かれている第６２回国体スケート・アイスホッケー競技会「群馬国体」は３０日、
スピード、ショートトラック、フィギュア、アイスホッケーが行われた。
ショート
ショート
少年男子千メートル予選（８組２位までが準々決勝へ）２組　〈２〉大沼（直江津高）
成年男子千メートル予選（１０組２位までが準々決勝へ）３組　〈２〉青木（山梨学院大）


2. テーマ別分類の特殊例としての類似文書検索

クエリとして、ある文書そのものを取り、そのクエリ文書をテーマとしてNMFの特徴基底に誘導することで、
類似文書検索ができる。

クエリ記事:00261660

【ロンドン＝千葉直樹】サッカーのスペイン１部リーグ、レアル・マドリードのＦＷロナウド（元ブラジル代表）の、
イタリア１部リーグ（セリエＡ）、ＡＣミランへの移籍が３０日、正式に決まった。ミラン側が発表したもので、契約期間は１年半。
　両クラブはこの日、マドリードのレアル球団事務所で、ロナウド本人を交えた最終的な話し合いを行った。
スペインの地元メディアの報道によれば移籍金は７５０万ユーロ（約１１億７７５０万円）で、７００万ユーロを提示したミランと、
８００万ユーロを主張したレアルとの間で協議が続いていた。今季はカペッロ監督の戦力構想から外れていた。


PRE-NMF(48): (nmf-article-search "00261660")
; cpu time (non-gc) 2,280 msec user, 0 msec system
; cpu time (gc)     1,380 msec user, 0 msec system
; cpu time (total)  3,660 msec user, 0 msec system
; real time  3,693 msec
; space allocation:
;  1,206 cons cells, 3,207,704,368 other bytes, 0 static bytes
Feature 0
#<DIMENSION NAME: ユーロ, TYPE: NUMERIC, INDEX: 609.>    0.22859128639222445
#<DIMENSION NAME: スペイン, TYPE: NUMERIC, INDEX: 323.>    0.15313470712342483
#<DIMENSION NAME: マドリード, TYPE: NUMERIC, INDEX: 378.>    0.15313470712342483
#<DIMENSION NAME: ナウ, TYPE: NUMERIC, INDEX: 138.>    0.13934832236449535
#<DIMENSION NAME: ロ, TYPE: NUMERIC, INDEX: 1082.>    0.1312928769019291
#<DIMENSION NAME: ラン, TYPE: NUMERIC, INDEX: 310.>    0.12606151555054787
#<DIMENSION NAME: 移籍, TYPE: NUMERIC, INDEX: 772.>    0.11201404339331933
#<DIMENSION NAME: リーグ, TYPE: NUMERIC, INDEX: 61.>    0.08221394982841077
#<DIMENSION NAME: セリエＡ, TYPE: NUMERIC, INDEX: 327.>    0.0798996764404508
#<DIMENSION NAME: メディア, TYPE: NUMERIC, INDEX: 744.>    0.06799733351980208

Feature 0
00261660   8.793930893336185
00260650   1.3732329079695595
00266240   0.5382099273818414
00266260   0.3165393678118092
00261710   0.24907471636323927
00260670   0.2374707712071695
00264530   0.21322378752469767
00266270   0.1766109315410921
00260700   0.14445598296034845
00261640   0.13891932888498076
4.005380196416142

この結果から見ると、クエリにもっとも近い記事は00260650である。

記事:00260650

　「移籍感謝したい、１人以外はね」　
　【ロンドン＝千葉直樹】サッカーのスペイン１部リーグ、レアル・マドリードからイタリア１部リーグ（セリエＡ）、
ＡＣミランへの移籍が３０日に正式発表されたＦＷロナウド（元ブラジル代表）＝写真はＡＰ＝。来季まで残るレアルとの契約を破棄、
４年半ぶりのセリエＡ復帰となる。しかし、２月から再開される欧州チャンピオンズリーグ（ＣＬ）には、今季すでにレアルの一員として
プレーしているため、規定により出場できない。
　　　　　　　　　
　球団で話し合いを終えたロナウドは３０本近いマイクに囲まれて「人生を大切にしてこれからの成功に懸けたい。
ファンや周囲の仲間に感謝したい。ただし一人を抜かしてね」と話して周囲を驚かせた。
この「一人」がレアルのカペッロ監督を指している事は想像に難くない。太りすぎなど体調管理の失敗もあったが、
規律に厳しい同監督が就任した今季は出場が極端に減った。「試合に出るためにはもっと減量が必要だ」という監督に
「僕は監督に信頼されていない」。本人は発言を否定するが、にぎやかな場外戦の末の移籍決定となった。
４年半ぶりにミラノに戻る。今回の移籍金は、２００２年にインテル・ミラノからレアルに移籍した時の４５００万ユーロ（推定）の
６分の１に減ったが、２度にわたる右ひざのじん帯断裂という大けがを乗り越えた土地は、“怪物”が復活をかけるためにふさわしい場だ。
欧州ＣＬには出場できないが、不正事件で勝ち点を削減されて現在９位のミランを、来季出場権を得る国内リーグ４位以内に
押し上げる戦力としての期待がかかる。


(10/19)NMF
・NMFのみを用いた情報検索手法について

文書-単語行列の重み付けをいじることで任意のテーマを特徴として抽出できるようになり、
テーマに沿った文書分類が可能となった。ところで、情報検索はテーマ別分類の一例として理解することが可能である。
すなわち、クエリ（ここでは単純化のために一語からなる検索語）をテーマとして検索対象の文書を分類したものが、
検索結果に他ならない。このアイディアに基づき、簡単な情報検索システムを実装した。
クエリの語に対して、クエリと関連が高いと思われる文書集合内の10語と、関連性が高いと思われる10記事をスコア順に返す。
なお、文書集合としてはスポーツ関連100記事、索引語数1202語のものを使用した。以下に実行例を示す。

この手法は距離や類似度の選択に悩まずに済むという利点がある反面、検索の度にNMFを特徴数1で行う必要があり、
非効率なのが問題である。ただ、恣意的に距離や類似度を選ばずに済むので、この遺伝子と似ている遺伝子を（なるべく客観的に）見つけたい、という
ような問題においては旧手法より強みがあるかもしれない。


PRE-NMF(40): (nmf-search "西武")
; cpu time (non-gc) 2,210 msec user, 0 msec system
; cpu time (gc)     1,510 msec user, 0 msec system
; cpu time (total)  3,720 msec user, 0 msec system
; real time  3,740 msec
; space allocation:
;  1,206 cons cells, 3,207,704,464 other bytes, 0 static bytes
#<DIMENSION NAME: 西武, TYPE: NUMERIC, INDEX: 1125.>    0.4851927338400536
#<DIMENSION NAME: 所沢, TYPE: NUMERIC, INDEX: 442.>    0.02938886955041649
#<DIMENSION NAME: 埼玉, TYPE: NUMERIC, INDEX: 173.>    0.029073371510233013
#<DIMENSION NAME: 期待, TYPE: NUMERIC, INDEX: 443.>    0.027386602076525476
#<DIMENSION NAME: 松坂, TYPE: NUMERIC, INDEX: 389.>    0.023397450480186648
#<DIMENSION NAME: ポスト, TYPE: NUMERIC, INDEX: 26.>    0.021528650638154068
#<DIMENSION NAME: 入団, TYPE: NUMERIC, INDEX: 255.>    0.021258052515834756
#<DIMENSION NAME: 実力, TYPE: NUMERIC, INDEX: 735.>    0.020691573041720014
#<DIMENSION NAME: 外国, TYPE: NUMERIC, INDEX: 92.>    0.020220721414637186
#<DIMENSION NAME: 生活, TYPE: NUMERIC, INDEX: 1160.>    0.019345118862275506

Feature 0
00261790   9.711717428253962
00266250   4.587297263327648
00261710   1.3953609212932412
00261730   0.0968506596395012
00265240   0.06578862256401193
00267810   0.04877086607846069
00266000   0.046860312087364894
00266270   0.04354693544359299
00265250   0.03953189352253915
00260700   0.03557864232365999
4.008933488467911

記事(00261790)
【西武】新外国人投手のジョンソン（レッズ）が埼玉県所沢市の西武鉄道本社で入団会見。「ポスト松坂」として期待されている
メジャー通算５５勝右腕は「どういう期待かわからないが、自分の実力には自信を持っている」と抱負を語った。
また、糖尿病を抱えながら、野球生活を送っていることについては「同じ症状を持っている人に勇気を与えたい」と語った。＝３０日


PRE-NMF(41): (nmf-search "楽天")
Feature 0
#<DIMENSION NAME: 楽天, TYPE: NUMERIC, INDEX: 573.>    0.41762358312788755
#<DIMENSION NAME: 野村, TYPE: NUMERIC, INDEX: 729.>    0.05681407317727146
#<DIMENSION NAME: 投手, TYPE: NUMERIC, INDEX: 454.>    0.03950845174501929
#<DIMENSION NAME: 田中, TYPE: NUMERIC, INDEX: 1116.>    0.031695793733618034
#<DIMENSION NAME: 投球, TYPE: NUMERIC, INDEX: 79.>    0.029651008235416967
#<DIMENSION NAME: 必勝, TYPE: NUMERIC, INDEX: 566.>    0.027672871644147775
#<DIMENSION NAME: 監督, TYPE: NUMERIC, INDEX: 131.>    0.02765879244146892
#<DIMENSION NAME: 祈願, TYPE: NUMERIC, INDEX: 982.>    0.025009785877601064
#<DIMENSION NAME: 球団, TYPE: NUMERIC, INDEX: 678.>    0.022040991210196658
#<DIMENSION NAME: 大崎, TYPE: NUMERIC, INDEX: 1064.>    0.021916478827876243

Feature 0
00261780   5.676714090471756
00266000   5.612980147355514
00264620   3.3908356253640743
00264500   2.5649261526038916
00261710   1.1032404909519895
00261770   0.14726850779158374
00260660   0.12672531902315565
00266230   0.10908063460043335
00261730   0.10806871228473529
00261750   0.10701192342445741
3.9905564767971295

記事(00261780)
【楽天】野村監督やコーチ、選手、球団職員ら約１００人が、必勝祈願のため仙台市の大崎八幡宮を参拝した。
球団創設から２年間はなかった行事で、野村監督の提案で初めて行われた。
野村監督は「２年続けて不名誉な結果に終わっているので、私自身も今年は言い訳のきかない年と覚悟している」と決意を新たにしていた。＝３０日


PRE-NMF(42): (nmf-search "京都")
Feature 0
#<DIMENSION NAME: 京都, TYPE: NUMERIC, INDEX: 83.>    0.5551577386625024
#<DIMENSION NAME: 修学旅行, TYPE: NUMERIC, INDEX: 338.>    0.0626523619282725
#<DIMENSION NAME: 生徒, TYPE: NUMERIC, INDEX: 716.>    0.03200813428305692
#<DIMENSION NAME: ハット, TYPE: NUMERIC, INDEX: 125.>    0.03196523295068247
#<DIMENSION NAME: ビッグ, TYPE: NUMERIC, INDEX: 1085.>    0.02869642620904825
#<DIMENSION NAME: 長野, TYPE: NUMERIC, INDEX: 980.>    0.02237885855469359
#<DIMENSION NAME: フィギュア, TYPE: NUMERIC, INDEX: 840.>    0.020584275662594565
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>    0.01925503061622964
#<DIMENSION NAME: 黒岩, TYPE: NUMERIC, INDEX: 448.>    0.018364636060864668
#<DIMENSION NAME: 笑顔, TYPE: NUMERIC, INDEX: 256.>    0.016540079168244647

Feature 0
00263050   7.987802991091306
00265180   3.079923328356668
00266820   2.3272374432808163
00267730   0.32028246690372847
00265250   0.11380332013630774
00264550   0.09289659041484835
00265130   0.08852240446343089
00264850   0.08617280234992342
00265920   0.08404389096582861
00264720   0.08231229571574267
4.037126072510506

記事(00263050)
長野市若里のスケート場「ビッグハット」が、３０日から３日間、京都から修学旅行に来た高校生に貸し出されている。
長野冬季五輪以来、ビッグハットの修学旅行生による「貸し切り」は初。
ビッグハット側は「荒川静香選手らの活躍でフィギュア人気に火が付いたおかげ」と喜んでいる。
利用しているのは、京都市の府立洛水高校から修学旅行に来た１年生４３人。
同校によると、修学旅行先は、冬季競技を体験させる狙いから、昨年までの沖縄から長野に変更した。冬の修学旅行の定番といえばスキー場だが、
今回はトリノ五輪で日本選手が活躍したフィギュアやカーリングなどでも会場を借り、生徒の選択肢を広げたという。
生徒たちは、浅田真央選手らが華麗な演技を見せたのと同じリンクに、おそるおそる立った。ピカピカに製氷された氷上で講師の指導を受けると、
次第に慣れて笑顔も出てきた。
生徒の１人、谷田藍里さん（１５）は「テレビでフィギュアの演技を見て興味が出た。少しでも上達して帰りたい」と話していた。

写真＝笑顔でスケート講習を受ける京都の高校生


(10/15)NMF
・NMFによる、与えられたテーマに沿った文書の自動分類手法の提案。

今までのNMFによる文書集合の分析は、文書集合内に存在する隠れた特徴を見出せる利点がある反面、既に分類（テーマ）が
存在する文書集合に対してNMFを適用しても、こちらが意図するテーマに沿った特徴は必ずしも抽出されてこない問題点があった。
どんな特徴(基底)が抽出されてくるかは、実際にNMFにかけてみないと分からないのである。

そこでNMFが抽出してくる特徴(基底)を人為的に誘導できないか考えてみた。もしこれが可能であるならば、
与えられた分類テーマに沿った文書の自動分類が可能となる。さらに、そのテーマの強さを反映する
順序に従って各文書を整列できる。

こちらが意図するテーマへの特徴誘導は、そのテーマを反映することが強く期待される単語（以下、テーマ語と呼ぶ）の重みを変えることで
実現できることが、試行錯誤の末分かった。文書-単語行列におけるテーマ語に相当する列の要素の総和は、文書集合全体におけるその語の影響力の
大きさを示していると解釈できる。各テーマ語の影響力を、文書集合で最大の影響力を持つ語の1.2倍に再重み付けすることで、
NMFが抽出してくる特徴(基底)を、こちらが設定したテーマに誘導することができる。これは単語の重み付けスキームの観点からすれば、
テーマ語に対してのみ、「意味論的重み項」を特別に掛けていることに相当する。

以下は以上のアイディアに基づく実行結果例(特徴抽出及び、文書クラスタリング)である。文書集合はスポーツ関連100記事、
索引語1202語からなる。事前に与えた分類テーマは、「野球」、「マラソン」、「スケート」、「スキー」、
「サッカー」の5テーマとし、これらを同時にテーマ語に設定した。結果を見ると、最も特徴的な5単語として
先に挙げた5つのテーマ語が選ばれていることが分かる。


PRE-NMF(85): (nmf-analysis theme-weighted-matrix 5)
Feature 0
#<DIMENSION NAME: スキー, TYPE: NUMERIC, INDEX: 968.>    0.25459404878594744
#<DIMENSION NAME: ジャンプ, TYPE: NUMERIC, INDEX: 300.>    0.028273436424224016
#<DIMENSION NAME: 大蔵, TYPE: NUMERIC, INDEX: 1175.>    0.02612029298024899
#<DIMENSION NAME: 札幌, TYPE: NUMERIC, INDEX: 931.>    0.02430852425328317
#<DIMENSION NAME: ジュニア, TYPE: NUMERIC, INDEX: 813.>    0.024012486567675902
#<DIMENSION NAME: 委員, TYPE: NUMERIC, INDEX: 1149.>    0.0199331701543754
#<DIMENSION NAME: オリンピア, TYPE: NUMERIC, INDEX: 531.>    0.01959021973518674
#<DIMENSION NAME: ノーラン, TYPE: NUMERIC, INDEX: 1049.>    0.01959021973518674
#<DIMENSION NAME: 野沢温泉, TYPE: NUMERIC, INDEX: 155.>    0.01906438770249266
#<DIMENSION NAME: 山ノ内, TYPE: NUMERIC, INDEX: 233.>    0.01906438770249266

Feature 1
#<DIMENSION NAME: マラソン, TYPE: NUMERIC, INDEX: 887.>    0.2697826029145443
#<DIMENSION NAME: 大阪, TYPE: NUMERIC, INDEX: 799.>    0.05565211681541487
#<DIMENSION NAME: 入賞, TYPE: NUMERIC, INDEX: 1123.>    0.03960703402715414
#<DIMENSION NAME: 世田谷, TYPE: NUMERIC, INDEX: 1157.>    0.03717898349320017
#<DIMENSION NAME: 走り, TYPE: NUMERIC, INDEX: 116.>    0.035383915282749846
#<DIMENSION NAME: 昨年, TYPE: NUMERIC, INDEX: 1015.>    0.03303141522164626
#<DIMENSION NAME: 世界, TYPE: NUMERIC, INDEX: 1152.>    0.02766673904818559
#<DIMENSION NAME: 練習, TYPE: NUMERIC, INDEX: 122.>    0.02729454706827602
#<DIMENSION NAME: 国際, TYPE: NUMERIC, INDEX: 411.>    0.02656502734406873
#<DIMENSION NAME: ヘルシンキ, TYPE: NUMERIC, INDEX: 1198.>    0.025193235867517875

Feature 2
#<DIMENSION NAME: 野球, TYPE: NUMERIC, INDEX: 357.>    0.21492846681374864
#<DIMENSION NAME: 試合, TYPE: NUMERIC, INDEX: 1.>    0.036250649396281115
#<DIMENSION NAME: 県内, TYPE: NUMERIC, INDEX: 175.>    0.03347553348618313
#<DIMENSION NAME: 投手, TYPE: NUMERIC, INDEX: 454.>    0.03281249103597782
#<DIMENSION NAME: 公式, TYPE: NUMERIC, INDEX: 274.>    0.031239591780619167
#<DIMENSION NAME: 中野, TYPE: NUMERIC, INDEX: 711.>    0.02793823551581369
#<DIMENSION NAME: 鶴岡, TYPE: NUMERIC, INDEX: 72.>    0.027022808286742788
#<DIMENSION NAME: 野村, TYPE: NUMERIC, INDEX: 729.>    0.025462643642171358
#<DIMENSION NAME: リーグ, TYPE: NUMERIC, INDEX: 61.>    0.02536078756367313
#<DIMENSION NAME: 所沢, TYPE: NUMERIC, INDEX: 442.>    0.024332862914039535

Feature 3
#<DIMENSION NAME: サッカー, TYPE: NUMERIC, INDEX: 834.>    0.2821606414339851
#<DIMENSION NAME: 宮崎, TYPE: NUMERIC, INDEX: 958.>    0.04632091508159614
#<DIMENSION NAME: ２月, TYPE: NUMERIC, INDEX: 672.>    0.04356531810839675
#<DIMENSION NAME: ＪＦＬ, TYPE: NUMERIC, INDEX: 792.>    0.04319955936272173
#<DIMENSION NAME: 移籍, TYPE: NUMERIC, INDEX: 772.>    0.04127640836275989
#<DIMENSION NAME: ヴェルディ, TYPE: NUMERIC, INDEX: 518.>    0.0371463095156404
#<DIMENSION NAME: 東京, TYPE: NUMERIC, INDEX: 410.>    0.034838960495063916
#<DIMENSION NAME: 監督, TYPE: NUMERIC, INDEX: 131.>    0.03338141663384757
#<DIMENSION NAME: 仙台, TYPE: NUMERIC, INDEX: 898.>    0.028747790610934992
#<DIMENSION NAME: チーム, TYPE: NUMERIC, INDEX: 697.>    0.028344533901478414

Feature 4
#<DIMENSION NAME: スケート, TYPE: NUMERIC, INDEX: 707.>    0.2507928199491046
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>    0.17150950413705482
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>    0.16188952261441708
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>    0.14748993507734498
#<DIMENSION NAME: アイスホッケー, TYPE: NUMERIC, INDEX: 341.>    0.13355971792184185
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>    0.1319666835193611
#<DIMENSION NAME: 群馬, TYPE: NUMERIC, INDEX: 1043.>    0.12102814969414234
#<DIMENSION NAME: スピード, TYPE: NUMERIC, INDEX: 435.>    0.11726244232547009
#<DIMENSION NAME: 国体, TYPE: NUMERIC, INDEX: 538.>    0.1110553263305725
#<DIMENSION NAME: 予選, TYPE: NUMERIC, INDEX: 391.>    0.10978677836280176

Feature 0
00264650   5.318476427096368
00266680   5.042799007981042
00266120   4.476155546128323
00266350   2.3381311260022297
00261720   1.582201337790787
00263050   1.1490549411952118
00266310   0.9869109963600888
00266090   0.46294730563130804
00267610   0.22265766707785295
00266100   0.20976406322049265

Feature 1
00267780   4.4827835630536885
00264150   4.240145487334886
00267800   4.010155423408688
00261590   3.147861167510863
00267810   3.107834854833743
00267690   0.4097721804441557
00267730   0.3373403972942987
00266680   0.33542849028997407
00261720   0.26002856113267653
00266190   0.2130130906475982

Feature 2
00264620   4.502631030877923
00266110   3.38919872551569
00261790   2.6539255383510154
00264500   1.93546476514765
00266150   1.7576603588602773
00265240   1.6155409494444049
00261710   1.58787712676554
00266300   1.388176733811829
00266340   1.1448597785570391
00267730   1.0734545216067328

Feature 3
00267320   4.246390190634634
00264530   1.8443821299480962
00266160   1.6611202303837311
00261620   1.4430334861524798
00261660   1.3611753212507312
00260650   1.2966833238879538
00266320   1.244359746248393
00265580   1.1826119624659732
00266260   1.1505432483468152
00265210   1.1331451393867502

Feature 4
00265130   1.5462061978984754
00264720   1.5034516751741467
00264810   1.3270639941688627
00264380   1.248766912409704
00265600   1.2404435142313501
00265320   1.189474332641185
00265250   1.1395430998910283
00265920   1.116502232357234
00264850   1.0656454110238103
00264550   1.0513210194554794
3.7708887826079613

PRE-NMF(86): (result-article-clustering weight article-id)

0   00264650   5.318476427096368

0   00266680   5.042799007981042

0   00266120   4.476155546128323

0   00266350   2.3381311260022297

0   00261720   1.582201337790787

0   00263050   1.1490549411952118

0   00266310   0.9869109963600888

0   00266090   0.46294730563130804

0   00267610   0.22265766707785295

0   00266050   0.13686614848066328

1   00267780   4.4827835630536885

1   00264150   4.240145487334886

1   00267800   4.010155423408688

1   00261590   3.147861167510863

1   00267810   3.107834854833743

1   00267690   0.4097721804441557

1   00266190   0.2130130906475982

2   00264620   4.502631030877923

2   00266110   3.38919872551569

2   00261790   2.6539255383510154

2   00264500   1.93546476514765

2   00266150   1.7576603588602773

2   00265240   1.6155409494444049

2   00261710   1.58787712676554

2   00266300   1.388176733811829

2   00266340   1.1448597785570391

2   00267730   1.0734545216067328

2   00265120   0.9690944883826402

2   00261800   0.9619625813318546

2   00261780   0.6131988865685216

2   00261730   0.5843952975801978

2   00266070   0.5575028914406508

2   00266000   0.5288387465353934

2   00266040   0.4494930470945303

2   00261760   0.40905865693233484

2   00266230   0.4036147877007395

2   00261770   0.3837449150738389

2   00260700   0.3487825942844842

2   00266010   0.29878433750756656

2   00266080   0.2881393449933354

2   00265960   0.28685616161587757

2   00266330   0.2555590705480866

2   00261750   0.24769790759191218

2   00261600   0.22562943929470086

2   00266100   0.21157544457398877

2   00261670   0.20851416266628564

2   00266170   0.20216365338101766

2   00261810   0.19698989477143855

2   00260670   0.18342711596116193

2   00266030   0.18077108973273157

2   00266290   0.17189112547752095

2   00261610   0.17039769313315367

2   00261650   0.09449129068108156

3   00267320   4.246390190634634

3   00264530   1.8443821299480962

3   00266160   1.6611202303837311

3   00261620   1.4430334861524798

3   00261660   1.3611753212507312

3   00260650   1.2966833238879538

3   00266320   1.244359746248393

3   00265580   1.1826119624659732

3   00266260   1.1505432483468152

3   00265210   1.1331451393867502

3   00266270   1.1000637831639875

3   00260660   0.48588771373948564

3   00261740   0.38535850019689477

3   00266240   0.33509762205724974

3   00266250   0.2874677406006937

3   00265950   0.26750019471835734

3   00266280   0.2070744621464796

3   00267600   0.19735372107431023

3   00261630   0.19450861950220186

3   00266180   0.16130490239592102

3   00266800   0.15781136611360408

3   00261640   0.13781645481317892

3   00260840   0.09127956200121427

4   00265130   1.5462061978984754

4   00264720   1.5034516751741467

4   00264810   1.3270639941688627

4   00264380   1.248766912409704

4   00265600   1.2404435142313501

4   00265320   1.189474332641185

4   00265250   1.1395430998910283

4   00265920   1.116502232357234

4   00264850   1.0656454110238103

4   00264550   1.0513210194554794

4   00264470   1.0160591617249843

4   00266820   0.9385322093506222

4   00264340   0.9113322272009917

4   00265420   0.9051433435540053

4   00264920   0.9043372609144499

4   00265060   0.7931563119675559

4   00264600   0.7626645723416106

4   00265790   0.7478537655194623

4   00265180   0.6560569366082583

4   00265830   0.627002978586169

4   00265970   0.3127110512358426

4   00266020   0.30357764179358926

4   00266940   0.29239568028212154

4   00265800   0.047483641032890045
NIL


実際に、この手法がある程度うまく機能していることの証左として、スキー関連記事(Feature0)として、
下から二番目の順位に分類された記事00267610を見てみよう。



（記事00267610）

予選を終えた国母は首をかしげた。「壁が立っているんですよね……」。ほかの国際大会に比べ、パイプの壁が切り立っており、
ジャンプが「はね返る」感じになるのだという。実際、多くの選手が感触をつかめず、転倒を繰り返した。
迎えた決勝。国母は柔軟な対応力を見せた。“はね返る壁”を利用し、本来、予定になかった後方縦回転にひねりを加えたジャンプにトライ。
試合で初めて披露する大技を成功させ、勝負を決めた。
前日から風邪をひいており、「体が全く動かなかった」と言う。それでも、終わってみれば、貫録すら感じさせる内容で快勝。
トリノ五輪で実力を出せず、予選落ちしたころの、線の細さが消えていた。
今季、世界選手権で日本人初の２位に入るなど、進化を続ける日本のエース。試合後、「金メダルをとらないといけないという気持ちがあった」と
語った横顔が、１８歳の高校生とは思えないほど凛々（りり）しかった。（平野和彦）

　写真＝スノーボード・ハーフパイプ男子で優勝した国母（ロイター）



この記事は、テーマ語である「スキー」という語を含んではいないが、スキー関連記事に分類されている。
（その理由は、「ジャンプ」という「スキー」と関連性の強い語が含まれているためであろう。）
これはこの記事が先の5テーマの中では、もっとも「スキー」に近いという人間の直観と整合している。

今後の課題及び問題点としては、テーマ語の選出及びその重み付けの調整、どのテーマにも属さないと見るのが妥当な文書の識別が挙げられる。
また、NMFを用いて、既に存在する階層的な分類に沿って、文書を自動分類する手法についても考えてみたい。さらに、今回の手法では
「テーマ語」を設定することで、特徴（基底）を誘導したが、文書集合内からテーマを体現すると見込まれる典型的な「テーマ文書」を選出し、
それに基づいて、意味論的重み項を設定する手法も並行的に考えられる。


(10/14)NMF
・C^3M法(cover-coefficient-based clustering methodology)による文書集合のクラスタ数の決定について。

NMFならびにk-meansといった非階層的クラスタリング手法の難点は、ランダムな初期値から出発するため、
実行毎にクラスタリング結果が異なりうることと、先験的にクラスタ個数kを決める必要がある点である。

後者の問題に対して、岸田和明、「文書クラスタリングの技法:文献レビュー」に興味深い手法が紹介されていた。
文書同士の被覆関係という観点から文書集合のクラスタ数を決定するC^3M法である。ここでいう被覆関係とは、
文書Bが文書Aに登場する語彙だけで書ける場合、文書Bは文書Aによって被覆されているという。

極端なケースを想定してみる。各文書が互いに語彙をまったく共有していない場合、各文書がそれぞれひとつのクラスタを形成している
と見るのが、被覆の観点から自然である。逆に、全文書が語彙を等しく共有している場合、これは全体でひとつのクラスタと見るのが
被覆の観点から自然である。C^3M法はこうした発想に基づいて、文書集合のクラスタ数を決定する。


・実行例1
スポーツ関連100記事、1202語の場合。

PRE-NMF(37): (cluster-number matrix)
20.974904271175472

PRE-NMF(40): (cluster-number tf*idf-matrix)
20.974904271175472

PRE-NMF(41): (cluster-number tf*idf*cosine-matrix)
20.974904271175472

この結果を見ると、被覆の観点からは21クラスタに分けるのが妥当そうである。
ここで注目してもらいたいのは、C^3M法は単語の重み付けを変えても影響を受けない点である。
これはC^3M法がある語が出現しているか否か（すなわち文書-単語行列の要素が非零であるか否か）だけに
着目しているアルゴリズムだからである。ただし、語の重み付けが非零の要素をゼロにするようなもの（またはその逆）だと
当然、影響を受ける。また、特徴語ないし索引語の選択もC^3M法の結果に影響を与える。


・実行例2
政治分野80記事、849語の場合。

PRE-NMF(44): (cluster-number matrix)
15.290476048493785

PRE-NMF(46): (cluster-number tf*idf-matrix)
15.290476048493785

PRE-NMF(48): (cluster-number tf*idf*cosine-matrix)
15.290476048493785


・15の特徴でNMFで分析した結果。

PRE-NMF(49): (nmf-analysis tf*idf*cosine-matrix 15)

Feature 0
#<DIMENSION NAME: 問題, TYPE: NUMERIC, INDEX: 317.>    0.10731923369238767
#<DIMENSION NAME: 県, TYPE: NUMERIC, INDEX: 605.>    0.06231256947087358
#<DIMENSION NAME: 隠岐, TYPE: NUMERIC, INDEX: 0.>    0.0463444995485009
#<DIMENSION NAME: 教材, TYPE: NUMERIC, INDEX: 8.>    0.0463444995485009
#<DIMENSION NAME: 竹島, TYPE: NUMERIC, INDEX: 713.>    0.0463444995485009
#<DIMENSION NAME: 市長, TYPE: NUMERIC, INDEX: 751.>    0.02408376483834824
#<DIMENSION NAME: 教授, TYPE: NUMERIC, INDEX: 141.>    0.020945678218843182
#<DIMENSION NAME: 返還, TYPE: NUMERIC, INDEX: 376.>    0.020619961793952472
#<DIMENSION NAME: 島, TYPE: NUMERIC, INDEX: 380.>    0.020619961793952472
#<DIMENSION NAME: 北方領土, TYPE: NUMERIC, INDEX: 499.>    0.020619961793952472

Feature 1
#<DIMENSION NAME: 柳沢, TYPE: NUMERIC, INDEX: 736.>    0.06760531354673541
#<DIMENSION NAME: 辞任, TYPE: NUMERIC, INDEX: 177.>    0.0661709127283973
#<DIMENSION NAME: 国会, TYPE: NUMERIC, INDEX: 575.>    0.061978544248259354
#<DIMENSION NAME: 野党, TYPE: NUMERIC, INDEX: 554.>    0.04625156429415423
#<DIMENSION NAME: 審議, TYPE: NUMERIC, INDEX: 300.>    0.04509527430474052
#<DIMENSION NAME: 首相, TYPE: NUMERIC, INDEX: 537.>    0.044332262400650746
#<DIMENSION NAME: 発言, TYPE: NUMERIC, INDEX: 214.>    0.04125114959019513
#<DIMENSION NAME: 労相, TYPE: NUMERIC, INDEX: 753.>    0.04124660476472449
#<DIMENSION NAME: 党首, TYPE: NUMERIC, INDEX: 612.>    0.04063026012919838
#<DIMENSION NAME: 予算, TYPE: NUMERIC, INDEX: 635.>    0.039535479767629104

Feature 2
#<DIMENSION NAME: 政治, TYPE: NUMERIC, INDEX: 464.>    0.11477507688428375
#<DIMENSION NAME: 事務所, TYPE: NUMERIC, INDEX: 589.>    0.09256609768988833
#<DIMENSION NAME: 資金, TYPE: NUMERIC, INDEX: 793.>    0.08245957004614166
#<DIMENSION NAME: 改正, TYPE: NUMERIC, INDEX: 498.>    0.0630483117983072
#<DIMENSION NAME: 領収, TYPE: NUMERIC, INDEX: 24.>    0.041242429811928084
#<DIMENSION NAME: 規正, TYPE: NUMERIC, INDEX: 808.>    0.04062050543546435
#<DIMENSION NAME: 添付, TYPE: NUMERIC, INDEX: 366.>    0.03354559899296989
#<DIMENSION NAME: 問題, TYPE: NUMERIC, INDEX: 317.>    0.031711486460587815
#<DIMENSION NAME: 中川, TYPE: NUMERIC, INDEX: 54.>    0.03159799527449647
#<DIMENSION NAME: 首相, TYPE: NUMERIC, INDEX: 537.>    0.028467305969234347

Feature 3
#<DIMENSION NAME: ハマス, TYPE: NUMERIC, INDEX: 766.>    0.09073900012495056
#<DIMENSION NAME: 両派, TYPE: NUMERIC, INDEX: 353.>    0.0640810190162125
#<DIMENSION NAME: ファタハ, TYPE: NUMERIC, INDEX: 264.>    0.046736353798892176
#<DIMENSION NAME: サウジ, TYPE: NUMERIC, INDEX: 839.>    0.046551946020033354
#<DIMENSION NAME: 議長, TYPE: NUMERIC, INDEX: 114.>    0.036015034007644525
#<DIMENSION NAME: 内閣, TYPE: NUMERIC, INDEX: 21.>    0.02830872001245702
#<DIMENSION NAME: 交渉, TYPE: NUMERIC, INDEX: 237.>    0.02809660946041527
#<DIMENSION NAME: ガザ, TYPE: NUMERIC, INDEX: 318.>    0.02809660946041527
#<DIMENSION NAME: 国王, TYPE: NUMERIC, INDEX: 186.>    0.027931167612029892
#<DIMENSION NAME: アラブ, TYPE: NUMERIC, INDEX: 611.>    0.027931167612027918

Feature 4
#<DIMENSION NAME: 政治, TYPE: NUMERIC, INDEX: 464.>    0.0822846999085272
#<DIMENSION NAME: 自民党, TYPE: NUMERIC, INDEX: 822.>    0.08193679950243732
#<DIMENSION NAME: 献金, TYPE: NUMERIC, INDEX: 206.>    0.07734544115076063
#<DIMENSION NAME: 団体, TYPE: NUMERIC, INDEX: 661.>    0.06737944999253236
#<DIMENSION NAME: 企業, TYPE: NUMERIC, INDEX: 67.>    0.04339754572033554
#<DIMENSION NAME: 会長, TYPE: NUMERIC, INDEX: 562.>    0.038083684503694974
#<DIMENSION NAME: 経団連, TYPE: NUMERIC, INDEX: 10.>    0.033406332374998245
#<DIMENSION NAME: 協会, TYPE: NUMERIC, INDEX: 371.>    0.030816612246920824
#<DIMENSION NAME: 議員, TYPE: NUMERIC, INDEX: 450.>    0.030507879928652764
#<DIMENSION NAME: 資金, TYPE: NUMERIC, INDEX: 793.>    0.03046416493551947

Feature 5
#<DIMENSION NAME: 参院, TYPE: NUMERIC, INDEX: 287.>    0.10063526024544853
#<DIMENSION NAME: 候補, TYPE: NUMERIC, INDEX: 391.>    0.08436674680887822
#<DIMENSION NAME: 擁立, TYPE: NUMERIC, INDEX: 39.>    0.07406278399057332
#<DIMENSION NAME: 県連, TYPE: NUMERIC, INDEX: 548.>    0.0686087518046187
#<DIMENSION NAME: 福島, TYPE: NUMERIC, INDEX: 427.>    0.04714642972004689
#<DIMENSION NAME: 選挙, TYPE: NUMERIC, INDEX: 20.>    0.044546924910568116
#<DIMENSION NAME: 公認, TYPE: NUMERIC, INDEX: 638.>    0.04026332624919377
#<DIMENSION NAME: 党首, TYPE: NUMERIC, INDEX: 612.>    0.030722159190120377
#<DIMENSION NAME: 党, TYPE: NUMERIC, INDEX: 846.>    0.02876427109517815
#<DIMENSION NAME: 方針, TYPE: NUMERIC, INDEX: 179.>    0.026093671523599045

Feature 6
#<DIMENSION NAME: 市議, TYPE: NUMERIC, INDEX: 432.>    0.07104901440836583
#<DIMENSION NAME: 調査, TYPE: NUMERIC, INDEX: 9.>    0.06122474490294428
#<DIMENSION NAME: 区, TYPE: NUMERIC, INDEX: 672.>    0.05230840670625255
#<DIMENSION NAME: 会派, TYPE: NUMERIC, INDEX: 392.>    0.05209002070844267
#<DIMENSION NAME: 政務, TYPE: NUMERIC, INDEX: 733.>    0.045479348041581595
#<DIMENSION NAME: 事務所, TYPE: NUMERIC, INDEX: 589.>    0.0363445060401095
#<DIMENSION NAME: 支出, TYPE: NUMERIC, INDEX: 583.>    0.03592759823593594
#<DIMENSION NAME: 議員, TYPE: NUMERIC, INDEX: 450.>    0.03554054950089249
#<DIMENSION NAME: 領収, TYPE: NUMERIC, INDEX: 24.>    0.02981212556959595
#<DIMENSION NAME: 添付, TYPE: NUMERIC, INDEX: 366.>    0.029198105929069015

Feature 7
#<DIMENSION NAME: 参院, TYPE: NUMERIC, INDEX: 287.>    0.2302914671452108
#<DIMENSION NAME: 議長, TYPE: NUMERIC, INDEX: 114.>    0.10001060551725187
#<DIMENSION NAME: 民主党, TYPE: NUMERIC, INDEX: 515.>    0.07963952664480942
#<DIMENSION NAME: 今泉, TYPE: NUMERIC, INDEX: 221.>    0.0683943981388446
#<DIMENSION NAME: 幹事, TYPE: NUMERIC, INDEX: 320.>    0.04625266279519676
#<DIMENSION NAME: 江田, TYPE: NUMERIC, INDEX: 829.>    0.0412846091320408
#<DIMENSION NAME: 議員, TYPE: NUMERIC, INDEX: 450.>    0.039855595020200425
#<DIMENSION NAME: 党, TYPE: NUMERIC, INDEX: 846.>    0.03920145139313325
#<DIMENSION NAME: 角田, TYPE: NUMERIC, INDEX: 847.>    0.033526165596856713
#<DIMENSION NAME: 選出, TYPE: NUMERIC, INDEX: 782.>    0.03067051784636498

Feature 8
#<DIMENSION NAME: 大統領, TYPE: NUMERIC, INDEX: 802.>    0.24273566860410964
#<DIMENSION NAME: クリントン, TYPE: NUMERIC, INDEX: 288.>    0.06717903218196353
#<DIMENSION NAME: 米, TYPE: NUMERIC, INDEX: 161.>    0.04788771245062496
#<DIMENSION NAME: 議員, TYPE: NUMERIC, INDEX: 450.>    0.04018224389913221
#<DIMENSION NAME: アイオワ, TYPE: NUMERIC, INDEX: 509.>    0.03671198355055741
#<DIMENSION NAME: ヒラリー, TYPE: NUMERIC, INDEX: 800.>    0.030533097323560746
#<DIMENSION NAME: 集会, TYPE: NUMERIC, INDEX: 552.>    0.024499634877510404
#<DIMENSION NAME: 夫, TYPE: NUMERIC, INDEX: 770.>    0.024328879933452445
#<DIMENSION NAME: 表明, TYPE: NUMERIC, INDEX: 279.>    0.02317979865382299
#<DIMENSION NAME: 誕生, TYPE: NUMERIC, INDEX: 180.>    0.018385897154338984

Feature 9
#<DIMENSION NAME: 代表, TYPE: NUMERIC, INDEX: 194.>    0.19767837002673272
#<DIMENSION NAME: 民主党, TYPE: NUMERIC, INDEX: 515.>    0.10057841441600769
#<DIMENSION NAME: 小沢, TYPE: NUMERIC, INDEX: 310.>    0.08317648279062609
#<DIMENSION NAME: 推薦, TYPE: NUMERIC, INDEX: 580.>    0.059336614008402795
#<DIMENSION NAME: 新党, TYPE: NUMERIC, INDEX: 739.>    0.04962479373199354
#<DIMENSION NAME: 記者, TYPE: NUMERIC, INDEX: 338.>    0.04111102113733761
#<DIMENSION NAME: 北海道, TYPE: NUMERIC, INDEX: 252.>    0.03621762518515728
#<DIMENSION NAME: 原, TYPE: NUMERIC, INDEX: 541.>    0.03595979877537408
#<DIMENSION NAME: 協力, TYPE: NUMERIC, INDEX: 443.>    0.03353620774612466
#<DIMENSION NAME: 大地, TYPE: NUMERIC, INDEX: 398.>    0.03223020224174646

Feature 10
#<DIMENSION NAME: 選挙, TYPE: NUMERIC, INDEX: 20.>    0.15465955692934608
#<DIMENSION NAME: 参院, TYPE: NUMERIC, INDEX: 287.>    0.10051830737719614
#<DIMENSION NAME: 議員, TYPE: NUMERIC, INDEX: 450.>    0.0962664468001589
#<DIMENSION NAME: 改選, TYPE: NUMERIC, INDEX: 25.>    0.07819072497153813
#<DIMENSION NAME: 定数, TYPE: NUMERIC, INDEX: 665.>    0.07253534614070455
#<DIMENSION NAME: 藤井, TYPE: NUMERIC, INDEX: 223.>    0.06117439974806194
#<DIMENSION NAME: 党, TYPE: NUMERIC, INDEX: 846.>    0.05803113161543316
#<DIMENSION NAME: 衆院, TYPE: NUMERIC, INDEX: 680.>    0.04760902902271393
#<DIMENSION NAME: 後援, TYPE: NUMERIC, INDEX: 112.>    0.03592740220835758
#<DIMENSION NAME: 小林, TYPE: NUMERIC, INDEX: 348.>    0.03187674531768665

Feature 11
#<DIMENSION NAME: 改革, TYPE: NUMERIC, INDEX: 424.>    0.10332743676036892
#<DIMENSION NAME: 政治, TYPE: NUMERIC, INDEX: 464.>    0.08850728147633138
#<DIMENSION NAME: 小沢, TYPE: NUMERIC, INDEX: 310.>    0.07329083022445768
#<DIMENSION NAME: 消費, TYPE: NUMERIC, INDEX: 201.>    0.06930199794396916
#<DIMENSION NAME: 国民, TYPE: NUMERIC, INDEX: 690.>    0.06079030093916852
#<DIMENSION NAME: 制度, TYPE: NUMERIC, INDEX: 312.>    0.060383922241139296
#<DIMENSION NAME: 税, TYPE: NUMERIC, INDEX: 466.>    0.0578470052083506
#<DIMENSION NAME: 安倍, TYPE: NUMERIC, INDEX: 649.>    0.057498279673884885
#<DIMENSION NAME: 問題, TYPE: NUMERIC, INDEX: 317.>    0.055864270362524115
#<DIMENSION NAME: 憲法, TYPE: NUMERIC, INDEX: 36.>    0.05123340018377364

Feature 12
#<DIMENSION NAME: 知事, TYPE: NUMERIC, INDEX: 563.>    0.16964542916635011
#<DIMENSION NAME: 宮崎, TYPE: NUMERIC, INDEX: 165.>    0.08553905444436946
#<DIMENSION NAME: メール, TYPE: NUMERIC, INDEX: 83.>    0.08254585371083883
#<DIMENSION NAME: 支援, TYPE: NUMERIC, INDEX: 139.>    0.06771064339945741
#<DIMENSION NAME: 選挙, TYPE: NUMERIC, INDEX: 20.>    0.06677458402723101
#<DIMENSION NAME: 沢, TYPE: NUMERIC, INDEX: 135.>    0.0662253258996177
#<DIMENSION NAME: 県知事, TYPE: NUMERIC, INDEX: 61.>    0.052693665756542454
#<DIMENSION NAME: 候補, TYPE: NUMERIC, INDEX: 391.>    0.04848928886254333
#<DIMENSION NAME: 自民党, TYPE: NUMERIC, INDEX: 822.>    0.04809095050877796
#<DIMENSION NAME: 投票, TYPE: NUMERIC, INDEX: 729.>    0.04523925023067896

Feature 13
#<DIMENSION NAME: 質問, TYPE: NUMERIC, INDEX: 373.>    0.29065903890693784
#<DIMENSION NAME: 首相, TYPE: NUMERIC, INDEX: 537.>    0.1747874421750466
#<DIMENSION NAME: 代表, TYPE: NUMERIC, INDEX: 194.>    0.14335453667161843
#<DIMENSION NAME: 格差, TYPE: NUMERIC, INDEX: 559.>    0.1399694477713725
#<DIMENSION NAME: 答弁, TYPE: NUMERIC, INDEX: 712.>    0.08168631733839488
#<DIMENSION NAME: 演説, TYPE: NUMERIC, INDEX: 767.>    0.07899881115312032
#<DIMENSION NAME: 参院, TYPE: NUMERIC, INDEX: 287.>    0.07717090057547457
#<DIMENSION NAME: 安倍, TYPE: NUMERIC, INDEX: 649.>    0.06830904334864901
#<DIMENSION NAME: 会長, TYPE: NUMERIC, INDEX: 562.>    0.06665797232982906
#<DIMENSION NAME: 国会, TYPE: NUMERIC, INDEX: 575.>    0.06460596681290132

Feature 14
#<DIMENSION NAME: 公認, TYPE: NUMERIC, INDEX: 638.>    0.2553091764039267
#<DIMENSION NAME: 県議, TYPE: NUMERIC, INDEX: 150.>    0.21388861327985392
#<DIMENSION NAME: 推薦, TYPE: NUMERIC, INDEX: 580.>    0.19101617579175445
#<DIMENSION NAME: 県連, TYPE: NUMERIC, INDEX: 548.>    0.18131706661635452
#<DIMENSION NAME: 候補, TYPE: NUMERIC, INDEX: 391.>    0.10663123993235972
#<DIMENSION NAME: 現職, TYPE: NUMERIC, INDEX: 387.>    0.08238778264891898
#<DIMENSION NAME: 新人, TYPE: NUMERIC, INDEX: 845.>    0.07087039740439352
#<DIMENSION NAME: 栃木, TYPE: NUMERIC, INDEX: 146.>    0.05922083204511512
#<DIMENSION NAME: 山本, TYPE: NUMERIC, INDEX: 462.>    0.05729637319831714
#<DIMENSION NAME: 自民党, TYPE: NUMERIC, INDEX: 822.>    0.053395532

PRE-NMF(50): (rho-k tf*idf*cosine-matrix 15)
0.9296358232437003


・大域的なrho-kの変化（スポーツ関連100記事、1202語の場合）

PRE-NMF(20): (rho-k tf*idf*cosine-matrix 5)
0.9158121491450255

PRE-NMF(42): (rho-k tf*idf*cosine-matrix 10)
0.9322666584869247

PRE-NMF(68):  (rho-k tf*idf*cosine-matrix 20)
0.9259371956900933

PRE-NMF(69):  (rho-k tf*idf*cosine-matrix 30)
0.9293633457680074


(10/9)NMF
・tf*idf法に代わる新しい重み付け手法として提案されているsqrt*igfs*cosine法を実装。
(cf. Erica Chisholm and Tamara G. Kolda, 
"NEW TERM WEIGHTING FORMULAS FOR THE VECTOR SPACE METHOD IN INFORMATION RETRIEVAL")
以下はsqrt*igfs*cosine法で構成した行列のNMF解析例。

PRE-NMF(91): (nmf-analysis sqrt*igfs*cosine-matrix 4)
; cpu time (non-gc) 8,400 msec user, 10 msec system
; cpu time (gc)     6,130 msec user, 0 msec system
; cpu time (total)  14,530 msec user, 10 msec system
; real time  14,620 msec
; space allocation:
;  1,212 cons cells, 12,645,443,104 other bytes, 0 static bytes
Feature 0
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>    2.4782271277879167
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>    1.693615342160671
#<DIMENSION NAME: 世界, TYPE: NUMERIC, INDEX: 1152.>    1.2253575863399568
#<DIMENSION NAME: 日本, TYPE: NUMERIC, INDEX: 759.>    1.1995540338753004
#<DIMENSION NAME: 選手, TYPE: NUMERIC, INDEX: 647.>    1.0801283478905879
#<DIMENSION NAME: 選手権, TYPE: NUMERIC, INDEX: 403.>    0.9893609972897248
#<DIMENSION NAME: 優勝, TYPE: NUMERIC, INDEX: 111.>    0.9388812518341965
#<DIMENSION NAME: マラソン, TYPE: NUMERIC, INDEX: 887.>    0.8583710686284787
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>    0.7790094790017389
#<DIMENSION NAME: 練習, TYPE: NUMERIC, INDEX: 122.>    0.7719871861076271

Feature 1
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>    2.770418727823775
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>    2.0350299191380214
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>    1.2715697261385774
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>    1.0417053818968638
#<DIMENSION NAME: 予選, TYPE: NUMERIC, INDEX: 391.>    0.8591269107746371
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>    0.7403552871231341
#<DIMENSION NAME: スピード, TYPE: NUMERIC, INDEX: 435.>    0.45167917737593516
#<DIMENSION NAME: スケート, TYPE: NUMERIC, INDEX: 707.>    0.332702969478121
#<DIMENSION NAME: 山梨学院大, TYPE: NUMERIC, INDEX: 685.>    0.30774123694926603
#<DIMENSION NAME: 青森, TYPE: NUMERIC, INDEX: 623.>    0.28635638549489995

Feature 2
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>    0.0030250846725820564
#<DIMENSION NAME: アイスホッケー, TYPE: NUMERIC, INDEX: 341.>    0.0029684794182179832
#<DIMENSION NAME: 群馬, TYPE: NUMERIC, INDEX: 1043.>    0.0027263886115688972
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>    0.002655027594434635
#<DIMENSION NAME: 国体, TYPE: NUMERIC, INDEX: 538.>    0.0023497788154936885
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>    0.001842378582316567
#<DIMENSION NAME: フィギュア, TYPE: NUMERIC, INDEX: 840.>    0.0017118761636060746
#<DIMENSION NAME: スピード, TYPE: NUMERIC, INDEX: 435.>    0.0015337284048840554
#<DIMENSION NAME: 競技, TYPE: NUMERIC, INDEX: 791.>    0.0014322517239156467
#<DIMENSION NAME: 得点, TYPE: NUMERIC, INDEX: 992.>    0.0013132893164086226

Feature 3
#<DIMENSION NAME: 選手, TYPE: NUMERIC, INDEX: 647.>    4.205575810386512
#<DIMENSION NAME: チーム, TYPE: NUMERIC, INDEX: 697.>    2.480154665912786
#<DIMENSION NAME: 監督, TYPE: NUMERIC, INDEX: 131.>    2.10963380751932
#<DIMENSION NAME: キャンプ, TYPE: NUMERIC, INDEX: 431.>    1.2726360496920197
#<DIMENSION NAME: リーグ, TYPE: NUMERIC, INDEX: 61.>    0.9525473041552992
#<DIMENSION NAME: 投手, TYPE: NUMERIC, INDEX: 454.>    0.944733258791625
#<DIMENSION NAME: 野球, TYPE: NUMERIC, INDEX: 357.>    0.8676387351016114
#<DIMENSION NAME: 宮崎, TYPE: NUMERIC, INDEX: 958.>    0.7953116500888362
#<DIMENSION NAME: 移籍, TYPE: NUMERIC, INDEX: 772.>    0.7817839352730265
#<DIMENSION NAME: 仙台, TYPE: NUMERIC, INDEX: 898.>    0.7766931966281372

Feature 0
00267780   1.2776320139866741
00267810   1.189529948147243
00261590   1.0987301685872217
00261720   1.067783811063503
00267800   0.9881111149552194
00266170   0.950179686057961
00267690   0.9442911761096668
00266680   0.9160503665086864
00267600   0.8805436345128602
00261630   0.8422822772404215

Feature 1
00265600   2.0583790717650015
00265320   2.0212392418686993
00264340   1.831137262888615
00266940   1.7648969904951661
00265420   1.695139884560269
00264470   1.6549658052911411
00264920   1.645737887993146
00264850   1.5679588551541748
00265130   1.552110099755647
00264720   1.5302026892067755

Feature 2
00264550   1044.7473735854755
00265790   871.6141136681335
00265830   727.8419147773564
00264380   678.2164258773643
00265250   646.1746472406098
00265180   638.0983481818985
00265060   626.8216481410975
00266820   595.5045264050087
00265920   574.5656748275428
00264720   573.8822096812814

Feature 3
00265240   0.919978301162834
00266260   0.8454297109431662
00264500   0.8405155037118783
00260660   0.8006533428045571
00266270   0.7997501180357027
00265580   0.7794419529691262
00266320   0.7697910409134459
00266110   0.7490565325017944
00266240   0.7174721543215722
00261750   0.6680527395949194
305.0321541041349

PRE-NMF(92): (rho-k sqrt*igfs*cosine-matrix 4)
0.9313388511874195


(10/7)NMFのクラスタリング安定度は元々の入力データの質の良さに依存することが肌で分かってきた。
そこで、目下の関心は与えられた文書集合から、どのように行列を構成するかに移りつつある。



・The success or failure of the vector space method　depends on the term weighting schemes.

(Erica Chisholm and Tamara G. Kolda, 
"NEW TERM WEIGHTING FORMULAS FOR THE VECTOR SPACE METHOD IN INFORMATION RETRIEVAL")


・現実のクラスタリング処理で最も重要なこと、つまり、最もクラスタリング結果に影響するのは、
クラスタリングのアルゴリズムの選択ではなく、現実のデータをN次元ベクトルに変換する方法である。

(新納浩幸,「WWWの記事をその内容によって自動的に分類する」)



・文書集合を行列Xに変換する過程には次の2つがあり、それぞれ様々な手法が提案されている。

1. 文書集合から特徴語を選出する。これは行列Xの次元を決めることに相当する。
高度な手法としては、単語を概念に汎化させ、その概念を次元にして行列を構成するものがある。

2. 1で選ばれた特徴語（あるいは概念）について、重み付けを行う。
これは行列Xの各要素を具体的に決めることに相当する。

(3. 1,2で構成された行列XをNMFにかけ、次元縮約・クラスタリング・特徴抽出を行う。)

(4. クエリをベクトル化し、3で加工された行列の中から、距離あるいは類似度に基づいてクエリベクトルに近いものを探す。)


・ここでは2の重み付け(weighting scheme)について考えることにする。
単語の重み付けの一般的なスキームは、

　　　　　　ローカル重み×グローバル重み×正規化項

である。

ここで、ローカル重みは、ある文書中にある単語が現れる頻度の指標、
グローバル重みは、全文書を通じてある単語が現れる頻度の指標である。
最後の正規化項は、文書長の影響を補正するために掛ける項である。

ローカル重み、グローバル重み、正規化項のそれぞれについて異なる指標が幾つも提案されている。
重み付けは、これら三者の積であるから、各指標の順列の数だけ存在することになる。
代表的な重み付け手法はtf*idf法が知られているが、これはローカル重みとしてtf(term frequency)を、
グローバル重みとしてidf(inverse document frequency)を、正規化項として1を掛けたものである。

問題は、このように数十以上存在する重み付け手法の中からどの手法を選ぶと良いのか、である。
再現率や適合率といった指標が、これら重み付けの良し悪しを測るために使えるが、
これら指標の計算のためには、人の認知パターンないし意味認識に基づいて、適合文書集合を作る必要があり、
そのコストはかなり高い。

そこで、NMFのクラスタリング安定度指標であるrho-kが、これら重み付け手法の評価に使えそうな気が逆にしてきている。
基本的な前提となる仮説は、NMFで安定的にクラスタリングできるほど、元の重み付け手法が文書集合の特徴をうまく
行列に表現できている、というものである。この仮説を裏付けるものとして以下の例が挙げられる。

matrix-Aは、ランダムに要素を生成した100*1202の行列、
matrix-Bは、単語の出現頻度を要素とする（つまり、もっとも素朴なローカル重みのみで重み付けした）100*1202の行列、
matrix-Cは、最も代表的な重み付け手法であるtf*idf法による100*1202の行列である。
これらそれぞれについて、特徴数4でNMFのクラスタリング安定度指標であるrho-kを計算してみると、次のようになる。

PRE-NMF(66): (rho-k matrix-A 4)
0.5285130849653269

PRE-NMF(69): (rho-k matrix-B 4)
0.9030292422969293

PRE-NMF(71): (rho-k matrix-C 4)
0.9976933761463115

rho-kの解釈は、NMFで繰り返しクラスタリングした際、データが同じクラスタに分類される確率と捉えると
分かりやすい。例えば、rho-kの値が1.0ならば、NMFによるクラスタリングで常に同じクラスに分類されている
ことを示す。上の結果を見てみると、tf*idf法ではrho-kの値はかなり1.0に近く、非常に安定したクラスタリングが
行えていることがわかる。逆に、ランダムに要素を生成した行列ではその値は0.50に近く、NMFで特徴がうまく
見つけられず、クラスタリングが不安定になっていることを示している。


・正規化とその影響について
今までの話は、正規化されていない（つまり、正規化項が1である）重み付けに関するものであった。
そこで、正規化手法としてもっとも代表的なcosineを採用し、tf*idf*cosine法によって行列を構成し、
NMFで特徴数を4に設定し、分析を試みた。

PRE-NMF(74): (nmf-analysis tf*idf*cosine-matrix 4)
; cpu time (non-gc) 8,450 msec user, 0 msec system
; cpu time (gc)     6,110 msec user, 0 msec system
; cpu time (total)  14,560 msec user, 0 msec system
; real time  14,659 msec
; space allocation:
;  1,212 cons cells, 12,645,443,104 other bytes, 0 static bytes
Feature 0
#<DIMENSION NAME: アイスホッケー, TYPE: NUMERIC, INDEX: 341.>    7.800539660172361e-13
#<DIMENSION NAME: 群馬, TYPE: NUMERIC, INDEX: 1043.>    7.397076221672198e-13
#<DIMENSION NAME: 国体, TYPE: NUMERIC, INDEX: 538.>    5.961027842442253e-13
#<DIMENSION NAME: フィギュア, TYPE: NUMERIC, INDEX: 840.>    5.205704942608375e-13
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>    4.297272987289668e-13
#<DIMENSION NAME: スケート, TYPE: NUMERIC, INDEX: 707.>    3.3230172444978226e-13
#<DIMENSION NAME: ショートトラック, TYPE: NUMERIC, INDEX: 1170.>    3.2404915609713106e-13
#<DIMENSION NAME: 渋川, TYPE: NUMERIC, INDEX: 562.>    3.2205519322879967e-13
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>    3.0256099162337574e-13
#<DIMENSION NAME: スピード, TYPE: NUMERIC, INDEX: 435.>    2.996609173642268e-13

Feature 1
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>    1.1549650903035218
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>    0.922693659397946
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>    0.894016973880188
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>    0.660449357316489
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>    0.6522719503833008
#<DIMENSION NAME: 予選, TYPE: NUMERIC, INDEX: 391.>    0.6281102408466429
#<DIMENSION NAME: スピード, TYPE: NUMERIC, INDEX: 435.>    0.5095012502841917
#<DIMENSION NAME: 山梨学院大, TYPE: NUMERIC, INDEX: 685.>    0.4729996099307121
#<DIMENSION NAME: スケート, TYPE: NUMERIC, INDEX: 707.>    0.4500954564431225
#<DIMENSION NAME: 篠原, TYPE: NUMERIC, INDEX: 1012.>    0.4468775602097603

Feature 2
#<DIMENSION NAME: マラソン, TYPE: NUMERIC, INDEX: 887.>    0.7849002604289812
#<DIMENSION NAME: 大阪, TYPE: NUMERIC, INDEX: 799.>    0.5319226438916164
#<DIMENSION NAME: 世界, TYPE: NUMERIC, INDEX: 1152.>    0.5097062847403322
#<DIMENSION NAME: 練習, TYPE: NUMERIC, INDEX: 122.>    0.3943418871603605
#<DIMENSION NAME: 日本, TYPE: NUMERIC, INDEX: 759.>    0.3511994280024298
#<DIMENSION NAME: 走り, TYPE: NUMERIC, INDEX: 116.>    0.31380824782631717
#<DIMENSION NAME: 昨年, TYPE: NUMERIC, INDEX: 1015.>    0.3076921080596898
#<DIMENSION NAME: 国際, TYPE: NUMERIC, INDEX: 411.>    0.29192000212271385
#<DIMENSION NAME: 選手権, TYPE: NUMERIC, INDEX: 403.>    0.27319603665869324
#<DIMENSION NAME: 駅伝, TYPE: NUMERIC, INDEX: 149.>    0.2657058937281702

Feature 3
#<DIMENSION NAME: キャンプ, TYPE: NUMERIC, INDEX: 431.>    1.0494558115328536
#<DIMENSION NAME: 監督, TYPE: NUMERIC, INDEX: 131.>    0.9892619039552812
#<DIMENSION NAME: 宮崎, TYPE: NUMERIC, INDEX: 958.>    0.9482832850447067
#<DIMENSION NAME: 投手, TYPE: NUMERIC, INDEX: 454.>    0.736726984500178
#<DIMENSION NAME: 野村, TYPE: NUMERIC, INDEX: 729.>    0.6840125553000935
#<DIMENSION NAME: 移籍, TYPE: NUMERIC, INDEX: 772.>    0.6145594425073584
#<DIMENSION NAME: 球団, TYPE: NUMERIC, INDEX: 678.>    0.5617536014719869
#<DIMENSION NAME: チーム, TYPE: NUMERIC, INDEX: 697.>    0.5565825722105744
#<DIMENSION NAME: リーグ, TYPE: NUMERIC, INDEX: 61.>    0.5412903933267438
#<DIMENSION NAME: 自主トレ, TYPE: NUMERIC, INDEX: 854.>    0.49581595192206074

Feature 0
00264550   3.6002012348150894e+12
00265130   3.0876961732401865e+12
00265790   3.0189412320179497e+12
00265250   2.996717691825943e+12
00264810   2.868229059245694e+12
00264380   2.625174205596399e+12
00265830   2.554206142797279e+12
00266820   2.145778747385423e+12
00265180   1.9748914514091147e+12
00265060   1.917302420423855e+12

Feature 1
00264340   2.4301788477915145
00265320   2.4028413128830977
00264850   2.377748973299961
00264920   2.280729508089238
00265600   2.2529587329551597
00265420   2.226703157408013
00264470   2.0270687986113387
00264720   1.9757231211117459
00265920   1.7869427871321508
00265130   1.1176349744599663

Feature 2
00267800   2.8855570724818134
00261590   2.672477096275443
00267780   2.5973820479838023
00267810   2.4971834751161954
00267690   1.7909345011014945
00261720   1.6621937998048948
00266680   1.5266973123738052
00264150   1.4475339605327717
00261630   1.2185383377007868
00267730   1.2130896585372877

Feature 3
00260660   1.3822559898707052
00264500   1.3101757351740184
00261710   1.2223112643438654
00260650   1.164927428865472
00261770   1.0758035901656002
00261740   1.053317300323777
00261780   1.0405928812061909
00261750   0.9720652873937402
00265240   0.9443843522319403
00261660   0.917092227238258
379.5175582485694


・対照用に、正規化していないtf*idf法で構成した行列を、特徴数4で分析した結果を示す。


PRE-NMF(80): (nmf-analysis tf*idf-matrix 4)
; cpu time (non-gc) 8,420 msec user, 10 msec system
; cpu time (gc)     5,950 msec user, 0 msec system
; cpu time (total)  14,370 msec user, 10 msec system
; real time  14,534 msec
; space allocation:
;  1,212 cons cells, 12,645,443,008 other bytes, 0 static bytes
Feature 0
#<DIMENSION NAME: 豊栄, TYPE: NUMERIC, INDEX: 1113.>    17.40844104069942
#<DIMENSION NAME: 新潟, TYPE: NUMERIC, INDEX: 29.>    17.246498469989003
#<DIMENSION NAME: 小千谷, TYPE: NUMERIC, INDEX: 120.>    13.926752832559535
#<DIMENSION NAME: 長岡, TYPE: NUMERIC, INDEX: 686.>    8.70422052034971
#<DIMENSION NAME: 渡辺, TYPE: NUMERIC, INDEX: 429.>    7.513856660692455
#<DIMENSION NAME: 鳥屋野, TYPE: NUMERIC, INDEX: 284.>    6.963376416279767
#<DIMENSION NAME: 津南, TYPE: NUMERIC, INDEX: 334.>    6.963376416279767
#<DIMENSION NAME: 妙高高原, TYPE: NUMERIC, INDEX: 808.>    6.963376416279767
#<DIMENSION NAME: 妙高, TYPE: NUMERIC, INDEX: 19.>    6.092954364244797
#<DIMENSION NAME: 下条, TYPE: NUMERIC, INDEX: 775.>    6.092954364244797

Feature 1
#<DIMENSION NAME: 浜松, TYPE: NUMERIC, INDEX: 166.>    5.449553608469183
#<DIMENSION NAME: 静岡, TYPE: NUMERIC, INDEX: 816.>    3.6256421873577795
#<DIMENSION NAME: 北, TYPE: NUMERIC, INDEX: 730.>    1.2197247652263015
#<DIMENSION NAME: 沼津, TYPE: NUMERIC, INDEX: 592.>    1.1882520350494659
#<DIMENSION NAME: 西, TYPE: NUMERIC, INDEX: 586.>    1.1555866371384647
#<DIMENSION NAME: 富士, TYPE: NUMERIC, INDEX: 494.>    1.117857150455217
#<DIMENSION NAME: 磐田, TYPE: NUMERIC, INDEX: 117.>    1.0687683093937514
#<DIMENSION NAME: 常葉, TYPE: NUMERIC, INDEX: 383.>    0.9781250066483149
#<DIMENSION NAME: 富士宮, TYPE: NUMERIC, INDEX: 771.>    0.9781250066483149
#<DIMENSION NAME: 藤枝, TYPE: NUMERIC, INDEX: 568.>    0.9488976268904663

Feature 2
#<DIMENSION NAME: 美術館, TYPE: NUMERIC, INDEX: 1044.>    0.9989169578818238
#<DIMENSION NAME: 福岡, TYPE: NUMERIC, INDEX: 361.>    0.6657285717641639
#<DIMENSION NAME: 美術, TYPE: NUMERIC, INDEX: 641.>    0.4682423240071049
#<DIMENSION NAME: 東京, TYPE: NUMERIC, INDEX: 410.>    0.4561255672003094
#<DIMENSION NAME: ５月, TYPE: NUMERIC, INDEX: 75.>    0.4244633235336098
#<DIMENSION NAME: ８月, TYPE: NUMERIC, INDEX: 703.>    0.39794566803965165
#<DIMENSION NAME: ７月, TYPE: NUMERIC, INDEX: 472.>    0.3718500412762838
#<DIMENSION NAME: 国立, TYPE: NUMERIC, INDEX: 427.>    0.3333636702478333
#<DIMENSION NAME: １０月, TYPE: NUMERIC, INDEX: 945.>    0.31914912258813327
#<DIMENSION NAME: ４月, TYPE: NUMERIC, INDEX: 1094.>    0.28676281312797514

Feature 3
#<DIMENSION NAME: 日立, TYPE: NUMERIC, INDEX: 333.>    8.76593813859351
#<DIMENSION NAME: 水戸, TYPE: NUMERIC, INDEX: 774.>    6.750429803051035
#<DIMENSION NAME: 友, TYPE: NUMERIC, INDEX: 526.>    6.13881979747673
#<DIMENSION NAME: 茨城, TYPE: NUMERIC, INDEX: 1155.>    5.882917785808396
#<DIMENSION NAME: 茨城大, TYPE: NUMERIC, INDEX: 873.>    2.893041344164729
#<DIMENSION NAME: キリスト, TYPE: NUMERIC, INDEX: 60.>    2.2501432676836783
#<DIMENSION NAME: 日立建機, TYPE: NUMERIC, INDEX: 617.>    2.2501432676836783
#<DIMENSION NAME: 常陸, TYPE: NUMERIC, INDEX: 657.>    2.2501432676836783
#<DIMENSION NAME: 美野里, TYPE: NUMERIC, INDEX: 1007.>    2.2501432676836783
#<DIMENSION NAME: 波崎, TYPE: NUMERIC, INDEX: 561.>    1.9286942294431528

Feature 0
00266090   4.667339195664722
00266020   1.1328585057945593
00265970   0.9996778532596281
00266040   0.36162514298976794
00266310   0.33172474147870645
00266120   0.25665271468538203
00266350   0.21227231186899725
00264920   0.20310727118527208
00265950   0.1914582647089607
00265920   0.1874478743211359

Feature 1
00266180   32.82121357954026
00265970   0.9994500060433935
00266310   0.9925722921134233
00266020   0.7368746892139764
00266160   0.7204233408262797
00266250   0.6401208433955938
00266120   0.6112985093548639
00266150   0.34519613409019084
00266230   0.33386189264059174
00266820   0.3116875829667755

Feature 2
00267730   147.09726121576435
00261590   3.8652288006357676
00266680   2.4296419829436835
00266050   1.733031643988428
00266310   1.692047110711665
00266150   1.6720934942188599
00265120   1.65090106384538
00261720   1.6276809467019109
00261620   1.2963946787439116
00266350   1.2563609387890093

Feature 3
00266190   14.109803722351034
00266020   1.1257454788583798
00265970   0.9995567058389067
00266310   0.7187986255976441
00266820   0.19907233894728982
00266040   0.19497170194059182
00265180   0.17250102001868983
00266350   0.16635238446188674
00266070   0.14790951928894672
00265950   0.10674582257875614
20753.05375808128


まず目につく相違点としては、正規化されていないtf*idf法では、地名・地域に関連した特徴が抽出されているのに対して、
正規化したtf*idf*cosine法では、スポーツに関連する特徴が抽出されている。
次に、こちらがより重要であるが、ある特徴0~3を最も反映する上位10記事のスコア分布が異なっていることがわかる。
例えば、正規化されていないtf*idf法で、特徴2を最も反映している記事は00267730、スコアは147.097で、他記事に比して突出している。

　　　　　　　　　　　　　　　　　Feature 2
　　　　　　　　　　00267730   147.09726121576435
　　　　　　　　　　00261590   3.8652288006357676
　　　　　　　　　　00266680   2.4296419829436835
　　　　　　　　　　00266050   1.733031643988428
　　　　　　　　　　00266310   1.692047110711665
　　　　　　　　　　00266150   1.6720934942188599
　　　　　　　　　　00265120   1.65090106384538
　　　　　　　　　　00261720   1.6276809467019109
　　　　　　　　　　00261620   1.2963946787439116
　　　　　　　　　　00266350   1.2563609387890093

実はこの記事0026773は、総文字数7277、単語数1361で他の記事に比べてかなり長い（第二位の記事00261590は、総文字数1421、単語数198）。
正規化されていない重み付けで構成した行列をNMFにかけると、このように長く多くの単語を含む記事が、ある特徴を
殆ど一手に反映してしまう。

では次に、正規化したtf*idf*cosine法で特徴2を反映する記事のスコアを見てみることにする
（特徴2というのに、ここでは特に意味はない）。

                             Feature 2
                 00267800   2.8855570724818134
                 00261590   2.672477096275443
                 00267780   2.5973820479838023
                 00267810   2.4971834751161954
                 00267690   1.7909345011014945
                 00261720   1.6621937998048948
                 00266680   1.5266973123738052
                 00264150   1.4475339605327717
　　　　　　　　　　00261630   1.2185383377007868
　　　　　　　　　　00267730   1.2130896585372877


正規化されていないtf*idf法の結果と比べてみると、第一位の記事0026780と第二位の記事00261590のスコアのギャップが
小さいことが分かる(これは他の特徴についても言える)。ちなみに記事002678は、総文字数749、単語数88であり、
記事00261590は、総文字数1421、単語数198である。以上の観察から、正規化によって、確かに文書長の影響が補正されていることがわかる。

しかし、正規化には問題点もある。正規化したtf*idf*cosine法で構成した行列に対して、特徴数4でのrho-kを計算してみると
次のようになる。

PRE-NMF(81): (rho-k tf*idf*cosine-matrix 4)
0.8706788732911777

これは、もっとも素朴な単語の出現頻度からなる行列や、正規化していないtf*idf法による行列のrho-kよりも低い。
すなわち、正規化するとNMFクラスタリングは安定しなくなる。以下はk=4で、別の特徴が出現している例である。

(まったくの憶測ながら、一般によく使われている重み付け手法が正規化されたtf*idf*cosine法ではなく、
正規化されていないtf*idf法であるのも、再現率や適合率といった指標から見て何か不利な点があるからかもしれない。）


PRE-NMF(82): (nmf-analysis tf*idf*cosine-matrix 4)
; cpu time (non-gc) 8,490 msec user, 10 msec system
; cpu time (gc)     5,920 msec user, 0 msec system
; cpu time (total)  14,410 msec user, 10 msec system
; real time  14,531 msec
; space allocation:
;  1,212 cons cells, 12,645,438,976 other bytes, 0 static bytes
Feature 0
#<DIMENSION NAME: 移籍, TYPE: NUMERIC, INDEX: 772.>    0.44198185744208685
#<DIMENSION NAME: ロ, TYPE: NUMERIC, INDEX: 1082.>    0.3965268392942539
#<DIMENSION NAME: リーグ, TYPE: NUMERIC, INDEX: 61.>    0.3316625064120749
#<DIMENSION NAME: ＦＷ, TYPE: NUMERIC, INDEX: 525.>    0.29859910024463154
#<DIMENSION NAME: ユーロ, TYPE: NUMERIC, INDEX: 609.>    0.29320309362191177
#<DIMENSION NAME: ナウ, TYPE: NUMERIC, INDEX: 138.>    0.2534384820383572
#<DIMENSION NAME: ブラジル, TYPE: NUMERIC, INDEX: 649.>    0.23213525212284886
#<DIMENSION NAME: 今季, TYPE: NUMERIC, INDEX: 158.>    0.2306497456500555
#<DIMENSION NAME: 契約, TYPE: NUMERIC, INDEX: 257.>    0.21834393204373323
#<DIMENSION NAME: スペイン, TYPE: NUMERIC, INDEX: 323.>    0.21708113609171428

Feature 1
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>    0.6479997371109788
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>    0.6077984693962615
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>    0.5641335281297369
#<DIMENSION NAME: アイスホッケー, TYPE: NUMERIC, INDEX: 341.>    0.49734737782361077
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>    0.4887795936138678
#<DIMENSION NAME: 群馬, TYPE: NUMERIC, INDEX: 1043.>    0.45183483079379294
#<DIMENSION NAME: スピード, TYPE: NUMERIC, INDEX: 435.>    0.4174116971974782
#<DIMENSION NAME: 予選, TYPE: NUMERIC, INDEX: 391.>    0.41378800430546075
#<DIMENSION NAME: 国体, TYPE: NUMERIC, INDEX: 538.>    0.4130822329878636
#<DIMENSION NAME: スケート, TYPE: NUMERIC, INDEX: 707.>    0.40483709763747633

Feature 2
#<DIMENSION NAME: キャンプ, TYPE: NUMERIC, INDEX: 431.>    1.3274191124324428
#<DIMENSION NAME: 宮崎, TYPE: NUMERIC, INDEX: 958.>    1.260844279724558
#<DIMENSION NAME: 野村, TYPE: NUMERIC, INDEX: 729.>    0.8553206790068745
#<DIMENSION NAME: 監督, TYPE: NUMERIC, INDEX: 131.>    0.8201520843439264
#<DIMENSION NAME: 投手, TYPE: NUMERIC, INDEX: 454.>    0.8133639539840958
#<DIMENSION NAME: 自主トレ, TYPE: NUMERIC, INDEX: 854.>    0.6468640931067473
#<DIMENSION NAME: 巨人, TYPE: NUMERIC, INDEX: 299.>    0.5358102282411067
#<DIMENSION NAME: 祈願, TYPE: NUMERIC, INDEX: 982.>    0.5326456530837209
#<DIMENSION NAME: 球団, TYPE: NUMERIC, INDEX: 678.>    0.5203478012742659
#<DIMENSION NAME: ブルペン, TYPE: NUMERIC, INDEX: 5.>    0.5126143582650414

Feature 3
#<DIMENSION NAME: マラソン, TYPE: NUMERIC, INDEX: 887.>    0.8141083012870686
#<DIMENSION NAME: 大阪, TYPE: NUMERIC, INDEX: 799.>    0.5530799702312452
#<DIMENSION NAME: 世界, TYPE: NUMERIC, INDEX: 1152.>    0.5315404751642431
#<DIMENSION NAME: 練習, TYPE: NUMERIC, INDEX: 122.>    0.42906007761154036
#<DIMENSION NAME: 日本, TYPE: NUMERIC, INDEX: 759.>    0.3498937171018965
#<DIMENSION NAME: 走り, TYPE: NUMERIC, INDEX: 116.>    0.32574019797835074
#<DIMENSION NAME: 昨年, TYPE: NUMERIC, INDEX: 1015.>    0.31997239791432447
#<DIMENSION NAME: 国際, TYPE: NUMERIC, INDEX: 411.>    0.29648807165179974
#<DIMENSION NAME: 選手権, TYPE: NUMERIC, INDEX: 403.>    0.2881096536844976
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>    0.28187743071658217

Feature 0
00260650   5.500463081403098
00261660   5.0368635471403795
00266240   3.5868783430544555
00266260   3.2928726208981405
00261710   2.3063183079334615
00264530   2.0557927193523318
00266270   2.00051972866897
00267600   1.4203127882097277
00260700   1.3720974005354547
00265580   1.2815415787544306

Feature 1
00264720   3.948146249309361
00265130   3.8633880237446157
00264810   3.6486502703230057
00265920   3.3015268947174343
00265250   3.2104909929390044
00264380   3.041357052644518
00264850   3.0269148243528887
00264470   2.8254443792686628
00265320   2.756724120701944
00264920   2.731209002204451

Feature 2
00260660   1.8344459621813447
00264500   1.675878262166744
00261770   1.4357180947325134
00261740   1.413700185217898
00261780   1.3137899460695486
00261750   1.2573691749159561
00266000   1.2220479216143207
00261760   1.034405107710225
00265240   0.9982008358604495
00267320   0.9657094591045806

Feature 3
00267800   2.724078432765598
00261590   2.5201674845092406
00267780   2.4383376645753447
00267810   2.3305049337990162
00267690   1.7135513284703547
00261720   1.5745781053067602
00266680   1.455431155045164
00264150   1.3561545291300863
00267730   1.1715544536355613
00266340   1.1290705167504917
374.26491374983954



(10/5)今までNMFを行っていた記事-単語行列は、ある記事中のある単語の出現頻度を要素とする素朴なものであった。
一方、情報検索におけるベクトル空間モデルのベクトル表現には、tf*idf法などが一般に用いられている。
そこで、今までの記事-単語行列をtf*idf法による行列に変換し、NMFによる特徴抽出を試みた。
結果は良好で、より明解な特徴抽出がより安定的に行われている。今後は文書長の影響を受けづらくするために、
正規化されたtf*idf法を試してみたいと考えている。

・オーソドックスなtf*idf法によるnew-matrixのNMFでの特徴抽出例　(k=4)、スポーツ関連100記事、1202単語。

PRE-NMF(41): (nmf-analysis new-matrix 4)
; cpu time (non-gc) 8,460 msec user, 0 msec system
; cpu time (gc)     5,950 msec user, 0 msec system
; cpu time (total)  14,410 msec user, 0 msec system
; real time  14,535 msec
; space allocation:
;  1,212 cons cells, 12,645,438,976 other bytes, 0 static bytes
Feature 0
#<DIMENSION NAME: 美術館, TYPE: NUMERIC, INDEX: 1044.>    1.0805434624548544
#<DIMENSION NAME: 福岡, TYPE: NUMERIC, INDEX: 361.>    0.7201289945499076
#<DIMENSION NAME: 美術, TYPE: NUMERIC, INDEX: 641.>    0.506504748025713
#<DIMENSION NAME: 東京, TYPE: NUMERIC, INDEX: 410.>    0.49335305501646953
#<DIMENSION NAME: ５月, TYPE: NUMERIC, INDEX: 75.>    0.4591483287213907
#<DIMENSION NAME: ８月, TYPE: NUMERIC, INDEX: 703.>    0.4304637828664625
#<DIMENSION NAME: ７月, TYPE: NUMERIC, INDEX: 472.>    0.40223612812576265
#<DIMENSION NAME: 国立, TYPE: NUMERIC, INDEX: 427.>    0.360606322986944
#<DIMENSION NAME: １０月, TYPE: NUMERIC, INDEX: 945.>    0.34522845918381045
#<DIMENSION NAME: ４月, TYPE: NUMERIC, INDEX: 1094.>    0.31019669281458906

Feature 1
#<DIMENSION NAME: 日立, TYPE: NUMERIC, INDEX: 333.>    8.767748278290457
#<DIMENSION NAME: 水戸, TYPE: NUMERIC, INDEX: 774.>    6.751807284101358
#<DIMENSION NAME: 友, TYPE: NUMERIC, INDEX: 526.>    6.144259434841277
#<DIMENSION NAME: 茨城, TYPE: NUMERIC, INDEX: 1155.>    5.884126685427919
#<DIMENSION NAME: 茨城大, TYPE: NUMERIC, INDEX: 873.>    2.8936316931862964
#<DIMENSION NAME: キリスト, TYPE: NUMERIC, INDEX: 60.>    2.250602428033786
#<DIMENSION NAME: 日立建機, TYPE: NUMERIC, INDEX: 617.>    2.250602428033786
#<DIMENSION NAME: 常陸, TYPE: NUMERIC, INDEX: 657.>    2.250602428033786
#<DIMENSION NAME: 美野里, TYPE: NUMERIC, INDEX: 1007.>    2.250602428033786
#<DIMENSION NAME: 波崎, TYPE: NUMERIC, INDEX: 561.>    1.9290877954575312

Feature 2
#<DIMENSION NAME: 浜松, TYPE: NUMERIC, INDEX: 166.>    5.468001718050128
#<DIMENSION NAME: 静岡, TYPE: NUMERIC, INDEX: 816.>    3.6379171816489664
#<DIMENSION NAME: 北, TYPE: NUMERIC, INDEX: 730.>    1.2238851629908023
#<DIMENSION NAME: 沼津, TYPE: NUMERIC, INDEX: 592.>    1.1922754368240445
#<DIMENSION NAME: 西, TYPE: NUMERIC, INDEX: 586.>    1.159467023292865
#<DIMENSION NAME: 富士, TYPE: NUMERIC, INDEX: 494.>    1.1216413780615648
#<DIMENSION NAME: 磐田, TYPE: NUMERIC, INDEX: 117.>    1.07238639746956
#<DIMENSION NAME: 常葉, TYPE: NUMERIC, INDEX: 383.>    0.9814362058038691
#<DIMENSION NAME: 富士宮, TYPE: NUMERIC, INDEX: 771.>    0.9814362058038691
#<DIMENSION NAME: 藤枝, TYPE: NUMERIC, INDEX: 568.>    0.9520990363328196

Feature 3
#<DIMENSION NAME: 豊栄, TYPE: NUMERIC, INDEX: 1113.>    17.358054722576046
#<DIMENSION NAME: 新潟, TYPE: NUMERIC, INDEX: 29.>    17.19636770145399
#<DIMENSION NAME: 小千谷, TYPE: NUMERIC, INDEX: 120.>    13.886443778060839
#<DIMENSION NAME: 長岡, TYPE: NUMERIC, INDEX: 686.>    8.679027361288023
#<DIMENSION NAME: 渡辺, TYPE: NUMERIC, INDEX: 429.>    7.485229107512254
#<DIMENSION NAME: 鳥屋野, TYPE: NUMERIC, INDEX: 284.>    6.943221889030419
#<DIMENSION NAME: 津南, TYPE: NUMERIC, INDEX: 334.>    6.943221889030419
#<DIMENSION NAME: 妙高高原, TYPE: NUMERIC, INDEX: 808.>    6.943221889030419
#<DIMENSION NAME: 妙高, TYPE: NUMERIC, INDEX: 19.>    6.075319152901615
#<DIMENSION NAME: 下条, TYPE: NUMERIC, INDEX: 775.>    6.075319152901615


・tf*idf法による行列のk=4でのrho-kの値。

PRE-NMF(123): (rho-k new-matrix 4)
0.9974561839170065

参考：以前の、単語の出現頻度を要素とする記事-単語行列のk=4でのrho-kの値。

PRE-NMF(53): (rho-k matrix 4)
0.8856559188604354


tf*idf法に基づくベクトル空間表現の方が、NMFで安定的にクラスタリングされていることが分かる。
また、rho-kという指標は、文書集合をベクトル空間表現する際の手法の評価にも使えそうである。
つまり、NMFで安定的にクラスタリングしやすいほど、各文書の特徴を捉えたベクトル表現が行えている、
と言えるのではないか。


・tf*idf法による行列の各kでのrho-kの値。

PRE-NMF(126): (rho-k new-matrix 2)
1.0

PRE-NMF(125): (rho-k new-matrix 3)
0.9993342229496355

PRE-NMF(123): (rho-k new-matrix 4)
0.9974561839170065

PRE-NMF(124): (rho-k new-matrix 5)
0.9913069629800338

PRE-NMF(127): (rho-k new-matrix 6)
0.9918766418410694

PRE-NMF(128): (rho-k new-matrix 7)
0.9729305323086376

PRE-NMF(129): (rho-k new-matrix 8)
0.9670595228922566


(10/1)NMF

・カルバック・ライブラー情報量を目的関数とするNMFを実装し、rho-kの値を、スポーツ分野100記事、1202単語の
行列について計算した。ユークリッド・ノルムベースNMFのクラスタリング結果の方が、記事-単語行列については安定している上に、
人の直感にもより合致しているように思われる。


・カルバック・ライブラー情報量ベースNMFでのrho-kの値の変化（スポーツ分野100記事、1202単語）。

PRE-NMF(96): (rho-k matrix 2)
0.7389051355422956

PRE-NMF(97): (rho-k matrix 3)
0.8994424198311901

PRE-NMF(98): (rho-k matrix 4)
0.796518964430358

PRE-NMF(99): (rho-k matrix 5)
0.8477326425957111


・カルバック・ライブラー情報量ベースNMFでの特徴抽出例 (k=4)

PRE-NMF(103): (nmf-analysis matrix 4)
; cpu time (non-gc) 3,030 msec user, 10 msec system
; cpu time (gc)     1,780 msec user, 0 msec system
; cpu time (total)  4,810 msec user, 10 msec system
; real time  4,853 msec
; space allocation:
;  168,522 cons cells, 4,131,879,584 other bytes, 0 static bytes
Feature 0
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>    14.357953163486457
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>    12.073628490605003
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>    11.793828458266395
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>    10.005637486713683
#<DIMENSION NAME: クラブ, TYPE: NUMERIC, INDEX: 596.>    9.540128184295122
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>    8.129311283114058
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>    6.137369276493192
#<DIMENSION NAME: 渡辺, TYPE: NUMERIC, INDEX: 429.>    5.448893862988857
#<DIMENSION NAME: 青森, TYPE: NUMERIC, INDEX: 623.>    5.265072016649753
#<DIMENSION NAME: 体育館, TYPE: NUMERIC, INDEX: 214.>    4.628772802880702

Feature 1
#<DIMENSION NAME: チーム, TYPE: NUMERIC, INDEX: 697.>    2.368097331941723
#<DIMENSION NAME: 鶴岡, TYPE: NUMERIC, INDEX: 72.>    2.17659003716943
#<DIMENSION NAME: 浜松, TYPE: NUMERIC, INDEX: 166.>    2.0704149134050667
#<DIMENSION NAME: 静岡, TYPE: NUMERIC, INDEX: 816.>    2.017327351521808
#<DIMENSION NAME: 選手, TYPE: NUMERIC, INDEX: 647.>    1.9296020661717599
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>    1.9252687201229153
#<DIMENSION NAME: 練習, TYPE: NUMERIC, INDEX: 122.>    1.5866692123414001
#<DIMENSION NAME: 試合, TYPE: NUMERIC, INDEX: 1.>    1.3967224185577636
#<DIMENSION NAME: 優勝, TYPE: NUMERIC, INDEX: 111.>    1.2702508552022984
#<DIMENSION NAME: 北, TYPE: NUMERIC, INDEX: 730.>    1.2081374788171475

Feature 2
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>    1.9298457437138319
#<DIMENSION NAME: 選手, TYPE: NUMERIC, INDEX: 647.>    1.8147578742370996
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>    1.5508027336803836
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>    1.5490228588686086
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>    1.3379754987327708
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>    0.9891689138757406
#<DIMENSION NAME: スピード, TYPE: NUMERIC, INDEX: 435.>    0.8286409077602086
#<DIMENSION NAME: アイスホッケー, TYPE: NUMERIC, INDEX: 341.>    0.8137465151172992
#<DIMENSION NAME: 群馬, TYPE: NUMERIC, INDEX: 1043.>    0.7667996007836092
#<DIMENSION NAME: 予選, TYPE: NUMERIC, INDEX: 391.>    0.7439583858824407

Feature 3
#<DIMENSION NAME: 東京, TYPE: NUMERIC, INDEX: 410.>    3.2082952489400126e-5
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>    3.02233781361876e-5
#<DIMENSION NAME: 日本, TYPE: NUMERIC, INDEX: 759.>    2.6771051727223987e-5
#<DIMENSION NAME: 世界, TYPE: NUMERIC, INDEX: 1152.>    2.5390126090599302e-5
#<DIMENSION NAME: 美術館, TYPE: NUMERIC, INDEX: 1044.>    1.900670684442662e-5
#<DIMENSION NAME: 日立, TYPE: NUMERIC, INDEX: 333.>    1.9006706792401787e-5
#<DIMENSION NAME: 福岡, TYPE: NUMERIC, INDEX: 361.>    1.7224828077760906e-5
#<DIMENSION NAME: 選手, TYPE: NUMERIC, INDEX: 647.>    1.6989692328085438e-5
#<DIMENSION NAME: 選手権, TYPE: NUMERIC, INDEX: 403.>    1.6876282996113423e-5
#<DIMENSION NAME: 競技, TYPE: NUMERIC, INDEX: 791.>    1.655741626985096e-5



A.回帰分析

1.実装済み、及び実装中の統計量について

・単回帰分析、重回帰分析共に、回帰式、標準誤差、t値、決定係数R^2、
調整済み決定係数R^2を求めることができる。

・ベータ関数の広義積分を漸化式によって計算する方法が、
九州産業大学国際文化学部紀要（川口俊郎・川上弘泰、「t分布のBASICによる数値計算」、1998）に紹介されている。
それに基づいて、t値に対応するp値（両側確率）を求める関数を実装した（8/25）。

・F値とそれに対応するp値を求める関数を、九州産業大学国際文化学部紀要（川口俊郎・川上弘泰、「F分布のBASICによる数値計算」、1997）を
参考に実装した（8/26）。しかし、まだ改善の余地あり。2の関連項目を参照のこと。

・赤池情報量基準（AIC）を求める関数を実装した。AICの定義は複数あるが、Rで用いられているものを採用（8/27）。以下は計算例。

> AIC(lm(dist~speed, cars))
[1] 419.1569
> AIC(lm(formula = Ozone ~ Solar.R + Wind + Temp, data = airquality))
[1] 998.7171

LINEAR-REGRESSION(38): (aic cars '(0 1))
419.15686302735327
LINEAR-REGRESSION(39): (aic air '(2 3 4 1))
998.7171028738219

・残差の四分位数を求める関数を実装した（8/27）。

・回帰モデルのF検定におけるp値の計算にまだ問題があるが、Rの線形回帰分析で用いられている統計量はほぼ実装できた（8/27）。


2.問題点、及び改善点

・行列計算パッケージに問題があり、逆行列が存在しない行列に関しても逆行列を計算してしまうケースがある。
そのため、データセットによってはおかしな統計量が返ってきてしまう。

・gnuplotなどと連携して散布図と回帰直線が表示できるとよい。

・F値と自由度Φ1、Φ2から、F分布における下側確率を計算する関数pf（Rに同名・同機能の関数がある）を
実装してみたが、F値がある程度大きいと、求めた値の大きさが1を超えてしまう。なお、F値が小さいケースでは
Rで計算した期待される値と一致する。以下に例を示す。


> pf(54.8336, 3, 107)
[1] 1
> 

LINEAR-REGRESSION(159): (pf 54.8336 3 107)
1.0000000020382769


> pf(3.0, 4, 5)
[1] 0.8702965
> pf(3.0, 5, 4)
[1] 0.8452565

LINEAR-REGRESSION(156): (pf 3.0 4 5)
0.8702965153994906
LINEAR-REGRESSION(157): (pf 3.0 5 4)
0.8452565448413933


3.Rによる計算結果との比較。


<Rによる重回帰分析の計算結果>

lm(formula = Ozone ~ Solar.R + Wind + Temp, data = airquality)

Residuals:
    Min      1Q  Median      3Q     Max 
-40.485 -14.219  -3.551  10.097  95.619 

Coefficients: Estimate Std. Error t value Pr(>|t|)    
(Intercept) -64.34208   23.05472  -2.791  0.00623 ** 
Solar.R       0.05982    0.02319   2.580  0.01124 *  
Wind         -3.33359    0.65441  -5.094 1.52e-06 ***
Temp          1.65209    0.25353   6.516 2.42e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 21.18 on 107 degrees of freedom
  (42 observations deleted due to missingness)
Multiple R-squared: 0.6059,	Adjusted R-squared: 0.5948 
F-statistic: 54.83 on 3 and 107 DF,  p-value: < 2.2e-16 



<LINEAR-REGRESSIONパッケージによる計算結果>

#<NUMERIC-DATASET>
DIMENSIONS: id | Ozone | Solar | Wind | Temp
TYPES:      NUMERIC | NUMERIC | NUMERIC | NUMERIC | NUMERIC
NUMERIC DATA POINTS: 111 POINTS

LINEAR-REGRESSION(40): (mlr air '(2 3 4 1))
#(-64.34207892859138 0.05982058996849854 -3.333591305512754 1.6520929109927098)

LINEAR-REGRESSION(41): (std-err-vector air '(2 3 4 1))
#(23.05472434747092 0.023186465941345838 0.6544071020541858 0.2535297930323602)

LINEAR-REGRESSION(42): (t-value-vector air '(2 3 4 1))
#(-2.790841389333273 2.5799787738168045 -5.094063458432222 6.516365951443976)

LINEAR-REGRESSION(43): (r^2 air '(2 3 4 1))
0.6058946000066227

LINEAR-REGRESSION(44): (adjusted-r^2 air '(2 3 4 1))
0.5948449158946586

LINEAR-REGRESSION(34): (pt-value-vector air '(2 3 4 1))
#(0.006226638088198122 0.011236635497233305 1.5159344077808612e-6 2.423506284543464e-9)

LINEAR-REGRESSION(39): (f-value air '(2 3 4 1))
54.83365803648639

LINEAR-REGRESSION(113): (quantile-vector-of-residuals air '(2 3 4 1))
#(-40.484747912377 -14.218959548460077 -3.5512644119576464 10.09683963800827 95.6194631644226)

LINEAR-REGRESSION(121): (d.f air '(2 3 4 1))
107
LINEAR-REGRESSION(122): (residual-std-err air '(2 3 4 1))
21.180750921047665


B.NMF(非負行列因子分解)

・テーマ:NMFを用いたクラスタリング手法の調査・研究

・(9/8)現在の進捗状況…与えられた記事の集合から、単語の出現頻度を要素とする行列を構成し、
それにNMFを適用することで、記事及び単語のクラスタリングを行うことができる。
"metagene"論文に基づいて、特徴数kを決めるためにコーフェン相関係数を求める必要があるため、
NMFを一旦中断し、階層型クラスタリングを実装中。

・課題…NMFはランダムな初期値から出発するアルゴリズムなため、抽出されてくる特徴が分解毎に異なりうる。
それを何とか安定化して、常に（ほぼ）同一のクラスタリングがなされるようにできないか。

特徴数kを何らかの意味で「自然に」決める規準を見出すことはできないだろうか?
論文"Metagenes and molecular pattern discovery using matrix factorization"では、
それに対する試みがなされている。今後は先の論文の結果を記事-単語行列に適用するために、
階層的クラスター分析をRを元に実装し、特徴数kを決める指標となる量を計算してみる予定。

・注意点…NMFの前提は、特徴たちの正の成分の「足し合わせ」で分析対象のデータが構成されているということである。
したがって、ある特徴が別の特徴の影響を相殺してしまうようなケースは、元々想定されていない。


（記録）

・非負行列分解（NMF）を行う関数のプロトタイプを実装。ランダムに設定する行列の初期値は0から1の範囲で指定しないと、
行列要素が限りなく0に近くなったり、正の無限大の方向に発散する傾向がある（8/28）。

・NMF実行例(8/31)

LINEAR-REGRESSION(126): x
#2A((15.0 18.0 3.0) (14.0 0.0 1.0) (19.0 19.0 4.0))
LINEAR-REGRESSION(127): (multiple-value-setq (a b) (nmf x 2))
#2A((0.42390690223861993 1.5798673331284714)
    (0.3969317921825442 5.0e-324)
    (0.5385169820985586 1.6737349419273522))
LINEAR-REGRESSION(128): b
#2A((35.25872331287699 0.00445240875425857 2.6751092284383255)
    (0.019954962951010916 11.3700925626481 1.365169593277584))
LINEAR-REGRESSION(129): (m*m a b)
#2A((14.977942370550387 17.96512522117724 3.290784110776772)
    (13.995308234648716 0.0017673025863571034 1.0618359003280877)
    (19.02082058985458 19.032918912777852 3.7255237984080547))



・NMFの問題点と疑問点に関するメモ(9/1)

(1)　分解がユニークではない。分解毎に、異なる基底（特徴）を選んでいるのでは？
(2)　事前に設定すべき特徴の数が分からないデータに対して、特徴の数をどう設定すべきか。
(3)　分解時のランダムな初期値をどのように選ぶとよいのか。目下、経験的に0から1の範囲が良い結果を出している。
(4)　更新規則の実行順序。
(5)　終了条件をどう設定するか。反復させるなら何回が妥当か。ノルムならどこまで近ければよいか。
(6)　NMFによって得られた行列の解釈



・実行効率(9/4現在）

LINEAR-REGRESSION(135): (type-of matrix)
(SIMPLE-ARRAY DOUBLE-FLOAT (80 849))
LINEAR-REGRESSION(136): (nmf-analysis matrix 5)

; cpu time (non-gc) 46,320 msec user, 180 msec system
; cpu time (gc)     16,400 msec user, 30 msec system
; cpu time (total)  62,720 msec (00:01:02.720) user, 210 msec system
; real time  64,872 msec (00:01:04.872)
; space allocation:
;  7,903,131 cons cells, 18,358,472,384 other bytes, 0 static bytes


・記事数100、単語数1202で、その出現頻度を成分とする行列(/machine-learning/sample/matrix)に
NMFを適用して分析を試みた。特徴数は5に設定。特徴行列の中で、成分の大きい上位10単語を抽出した結果を以下に示す。
今回の分解の場合、主に地域で分類されている様子がうかがえる（9/2）。


（特徴0の成分が大きい上位10単語）
LINEAR-REGRESSION(121): (pick-up-words b words 0)
#<DIMENSION NAME: 浜松, TYPE: NUMERIC, INDEX: 166.>
#<DIMENSION NAME: 静岡, TYPE: NUMERIC, INDEX: 816.>
#<DIMENSION NAME: 北, TYPE: NUMERIC, INDEX: 730.>
#<DIMENSION NAME: 西, TYPE: NUMERIC, INDEX: 586.>
#<DIMENSION NAME: 南, TYPE: NUMERIC, INDEX: 689.>
#<DIMENSION NAME: 学園, TYPE: NUMERIC, INDEX: 42.>
#<DIMENSION NAME: 中央, TYPE: NUMERIC, INDEX: 392.>
#<DIMENSION NAME: 沼津, TYPE: NUMERIC, INDEX: 592.>
#<DIMENSION NAME: 加藤, TYPE: NUMERIC, INDEX: 1186.>
#<DIMENSION NAME: 磐田, TYPE: NUMERIC, INDEX: 117.>


（特徴1の成分が大きい上位10単語）
LINEAR-REGRESSION(122): (pick-up-words b words 1)
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: クラブ, TYPE: NUMERIC, INDEX: 596.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>
#<DIMENSION NAME: 選手, TYPE: NUMERIC, INDEX: 647.>
#<DIMENSION NAME: 予選, TYPE: NUMERIC, INDEX: 391.>
#<DIMENSION NAME: 盛岡, TYPE: NUMERIC, INDEX: 866.>


（特徴2の成分が大きい上位10単語）
LINEAR-REGRESSION(123): (pick-up-words b words 2)
#<DIMENSION NAME: 東京, TYPE: NUMERIC, INDEX: 410.>
#<DIMENSION NAME: 美術館, TYPE: NUMERIC, INDEX: 1044.>
#<DIMENSION NAME: 福岡, TYPE: NUMERIC, INDEX: 361.>
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>
#<DIMENSION NAME: ３月, TYPE: NUMERIC, INDEX: 890.>
#<DIMENSION NAME: ５月, TYPE: NUMERIC, INDEX: 75.>
#<DIMENSION NAME: ４月, TYPE: NUMERIC, INDEX: 1094.>
#<DIMENSION NAME: ８月, TYPE: NUMERIC, INDEX: 703.>
#<DIMENSION NAME: 美術, TYPE: NUMERIC, INDEX: 641.>
#<DIMENSION NAME: 国立, TYPE: NUMERIC, INDEX: 427.>

（特徴3の成分が大きい上位10単語）
LINEAR-REGRESSION(124): (pick-up-words b words 3)
#<DIMENSION NAME: 日立, TYPE: NUMERIC, INDEX: 333.>
#<DIMENSION NAME: 友, TYPE: NUMERIC, INDEX: 526.>
#<DIMENSION NAME: 茨城, TYPE: NUMERIC, INDEX: 1155.>
#<DIMENSION NAME: 水戸, TYPE: NUMERIC, INDEX: 774.>
#<DIMENSION NAME: 鈴木, TYPE: NUMERIC, INDEX: 199.>
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>
#<DIMENSION NAME: 茨城大, TYPE: NUMERIC, INDEX: 873.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: クラブ, TYPE: NUMERIC, INDEX: 596.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>


（特徴4の成分が大きい上位10単語）
LINEAR-REGRESSION(125): (pick-up-words b words 4)
#<DIMENSION NAME: 新潟, TYPE: NUMERIC, INDEX: 29.>
#<DIMENSION NAME: 豊栄, TYPE: NUMERIC, INDEX: 1113.>
#<DIMENSION NAME: 渡辺, TYPE: NUMERIC, INDEX: 429.>
#<DIMENSION NAME: 小千谷, TYPE: NUMERIC, INDEX: 120.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: 東京, TYPE: NUMERIC, INDEX: 410.>
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>


・特徴0~特徴4のそれぞれについて、成分が大きい上位10記事を抽出してみた。各数字は記事IDである(9/3)。


（特徴0の成分が大きい上位10記事）
LINEAR-REGRESSION(140): (pick-up-articles a articles-vector 0)
00266180-「サッカー、高校新人地区大会、沼津東高グラウンド」
00266310
00266250
00266120
00266160
00266230
00266070
00266820
00266350
00261710

（特徴1の成分が大きい上位10記事）
LINEAR-REGRESSION(141): (pick-up-articles a articles-vector 1)
00265970-「卓球、花巻市総合体育館」
00266020
00264920
00264850
00265920
00265180
00266820
00265420
00264470
00264340

（特徴2の成分が大きい上位10記事）
LINEAR-REGRESSION(142): (pick-up-articles a articles-vector 2)
00267730-「ベルギー王立美術館展」
00266680
00261590
00261720
00266050
00266310
00266100
00261620
00265120
00266150

（特徴3の成分が大きい上位10記事）
LINEAR-REGRESSION(143): (pick-up-articles a articles-vector 3)
00266190-「勝田全国マラソン(注:茨城県ひたちなか市で開催)」
00266310
00266040
00266020
00266350
00266070
00265970
00261710
00261590
00265120

（特徴4の成分が大きい上位10記事）
LINEAR-REGRESSION(144): (pick-up-articles a articles-vector 4)
00266090-「バスケットボール、新潟市鳥屋総合体育館」
00266020
00266310
00266120
00266040
00266350
00266250
00266070
00265950
00261720

・上のものと同じ記事-単語行列をもう一度NMFにかけて、再度分析した結果を示す。
NMFは初期値をランダムに設定し、分解結果は毎回異なる。それゆえ、分解毎に異なる基底（特徴）を
選んでいるのでは、という疑問があった。しかし結果は、抽出された特徴の順番こそ違うが、同種の特徴を補足していることを
示唆するものになっている（9/3）。

LINEAR-REGRESSION(147): (pick-up-words feature words 0)
#<DIMENSION NAME: 東京, TYPE: NUMERIC, INDEX: 410.>
#<DIMENSION NAME: 美術館, TYPE: NUMERIC, INDEX: 1044.>
#<DIMENSION NAME: 福岡, TYPE: NUMERIC, INDEX: 361.>
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>
#<DIMENSION NAME: ３月, TYPE: NUMERIC, INDEX: 890.>
#<DIMENSION NAME: ５月, TYPE: NUMERIC, INDEX: 75.>
#<DIMENSION NAME: ４月, TYPE: NUMERIC, INDEX: 1094.>
#<DIMENSION NAME: ８月, TYPE: NUMERIC, INDEX: 703.>
#<DIMENSION NAME: 美術, TYPE: NUMERIC, INDEX: 641.>
#<DIMENSION NAME: 国立, TYPE: NUMERIC, INDEX: 427.>
NIL
LINEAR-REGRESSION(150): (pick-up-words feature words 1)
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>
#<DIMENSION NAME: クラブ, TYPE: NUMERIC, INDEX: 596.>
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>
#<DIMENSION NAME: 仙台, TYPE: NUMERIC, INDEX: 898.>
#<DIMENSION NAME: 盛岡, TYPE: NUMERIC, INDEX: 866.>
#<DIMENSION NAME: 体育館, TYPE: NUMERIC, INDEX: 214.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: 佐々木, TYPE: NUMERIC, INDEX: 671.>
#<DIMENSION NAME: 卓球, TYPE: NUMERIC, INDEX: 895.>
NIL
LINEAR-REGRESSION(151): (pick-up-words feature words 2)
#<DIMENSION NAME: 浜松, TYPE: NUMERIC, INDEX: 166.>
#<DIMENSION NAME: 静岡, TYPE: NUMERIC, INDEX: 816.>
#<DIMENSION NAME: 北, TYPE: NUMERIC, INDEX: 730.>
#<DIMENSION NAME: 西, TYPE: NUMERIC, INDEX: 586.>
#<DIMENSION NAME: 南, TYPE: NUMERIC, INDEX: 689.>
#<DIMENSION NAME: 学園, TYPE: NUMERIC, INDEX: 42.>
#<DIMENSION NAME: 中央, TYPE: NUMERIC, INDEX: 392.>
#<DIMENSION NAME: 沼津, TYPE: NUMERIC, INDEX: 592.>
#<DIMENSION NAME: 加藤, TYPE: NUMERIC, INDEX: 1186.>
#<DIMENSION NAME: 磐田, TYPE: NUMERIC, INDEX: 117.>
NIL
LINEAR-REGRESSION(152): (pick-up-words feature words 3)
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: 選手, TYPE: NUMERIC, INDEX: 647.>
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>
#<DIMENSION NAME: スピード, TYPE: NUMERIC, INDEX: 435.>
#<DIMENSION NAME: 予選, TYPE: NUMERIC, INDEX: 391.>
#<DIMENSION NAME: 山梨学院大, TYPE: NUMERIC, INDEX: 685.>
NIL
LINEAR-REGRESSION(153): (pick-up-words feature words 4)
#<DIMENSION NAME: 日立, TYPE: NUMERIC, INDEX: 333.>
#<DIMENSION NAME: 友, TYPE: NUMERIC, INDEX: 526.>
#<DIMENSION NAME: 茨城, TYPE: NUMERIC, INDEX: 1155.>
#<DIMENSION NAME: 水戸, TYPE: NUMERIC, INDEX: 774.>
#<DIMENSION NAME: 鈴木, TYPE: NUMERIC, INDEX: 199.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>
#<DIMENSION NAME: 茨城大, TYPE: NUMERIC, INDEX: 873.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
#<DIMENSION NAME: クラブ, TYPE: NUMERIC, INDEX: 596.>
NIL


LINEAR-REGRESSION(154): (pick-up-articles weight articles-vector 0)
00267730-「ベルギー王立美術館展」
00266090
00266680
00261590
00266310
00261720
00261620
00266050
00266100
00265120
NIL
LINEAR-REGRESSION(155): (pick-up-articles weight articles-vector 1)
00265970-「卓球、花巻市総合体育館」
00266020
00266090
00265950
00266250
00266350
00266040
00264850
00264920
00266120
NIL
LINEAR-REGRESSION(156): (pick-up-articles weight articles-vector 2)
00266180-「サッカー、高校新人地区大会、沼津東高グラウンド」
00266310
00266250
00266120
00266090
00266160
00266070
00266350
00266230
00266820
NIL
LINEAR-REGRESSION(157): (pick-up-articles weight articles-vector 3)
00264920-「スケート、アイスホッケー競技会、群馬県渋川市」
00265180
00264850
00265920
00266820
00264470
00265250
00265420
00264600
00266310
NIL
LINEAR-REGRESSION(158): (pick-up-articles weight articles-vector 4)
00266190-「勝田全国マラソン(注:茨城県ひたちなか市で開催)」
00266310
00266040
00266350
00266090
00266070
00261710
00261590
00266120
00261720
NIL

・3回目のNMFの分析結果(9/3)

LINEAR-REGRESSION(160): (pick-up-words feature words 0)
#<DIMENSION NAME: 日立, TYPE: NUMERIC, INDEX: 333.>
#<DIMENSION NAME: 友, TYPE: NUMERIC, INDEX: 526.>
#<DIMENSION NAME: 茨城, TYPE: NUMERIC, INDEX: 1155.>
#<DIMENSION NAME: 水戸, TYPE: NUMERIC, INDEX: 774.>
#<DIMENSION NAME: 鈴木, TYPE: NUMERIC, INDEX: 199.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: 茨城大, TYPE: NUMERIC, INDEX: 873.>
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
#<DIMENSION NAME: クラブ, TYPE: NUMERIC, INDEX: 596.>
NIL
LINEAR-REGRESSION(161): (pick-up-words feature words 1)
#<DIMENSION NAME: 東京, TYPE: NUMERIC, INDEX: 410.>
#<DIMENSION NAME: 美術館, TYPE: NUMERIC, INDEX: 1044.>
#<DIMENSION NAME: 福岡, TYPE: NUMERIC, INDEX: 361.>
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>
#<DIMENSION NAME: ３月, TYPE: NUMERIC, INDEX: 890.>
#<DIMENSION NAME: ５月, TYPE: NUMERIC, INDEX: 75.>
#<DIMENSION NAME: ４月, TYPE: NUMERIC, INDEX: 1094.>
#<DIMENSION NAME: ８月, TYPE: NUMERIC, INDEX: 703.>
#<DIMENSION NAME: 美術, TYPE: NUMERIC, INDEX: 641.>
#<DIMENSION NAME: 国立, TYPE: NUMERIC, INDEX: 427.>
NIL
LINEAR-REGRESSION(162): (pick-up-words feature words 2)
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: 選手, TYPE: NUMERIC, INDEX: 647.>
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>
#<DIMENSION NAME: スピード, TYPE: NUMERIC, INDEX: 435.>
#<DIMENSION NAME: 予選, TYPE: NUMERIC, INDEX: 391.>
#<DIMENSION NAME: 山梨学院大, TYPE: NUMERIC, INDEX: 685.>
NIL
LINEAR-REGRESSION(163): (pick-up-words feature words 3)
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>
#<DIMENSION NAME: クラブ, TYPE: NUMERIC, INDEX: 596.>
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>
#<DIMENSION NAME: 仙台, TYPE: NUMERIC, INDEX: 898.>
#<DIMENSION NAME: 盛岡, TYPE: NUMERIC, INDEX: 866.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: 体育館, TYPE: NUMERIC, INDEX: 214.>
#<DIMENSION NAME: 佐々木, TYPE: NUMERIC, INDEX: 671.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
NIL
LINEAR-REGRESSION(164): (pick-up-words feature words 4)
#<DIMENSION NAME: 浜松, TYPE: NUMERIC, INDEX: 166.>
#<DIMENSION NAME: 静岡, TYPE: NUMERIC, INDEX: 816.>
#<DIMENSION NAME: 北, TYPE: NUMERIC, INDEX: 730.>
#<DIMENSION NAME: 西, TYPE: NUMERIC, INDEX: 586.>
#<DIMENSION NAME: 南, TYPE: NUMERIC, INDEX: 689.>
#<DIMENSION NAME: 学園, TYPE: NUMERIC, INDEX: 42.>
#<DIMENSION NAME: 中央, TYPE: NUMERIC, INDEX: 392.>
#<DIMENSION NAME: 沼津, TYPE: NUMERIC, INDEX: 592.>
#<DIMENSION NAME: 加藤, TYPE: NUMERIC, INDEX: 1186.>
#<DIMENSION NAME: 磐田, TYPE: NUMERIC, INDEX: 117.>
NIL
LINEAR-REGRESSION(165): (pick-up-articles weight articles-vector 0)
00266190
00266310
00266040
00266350
00266090
00266070
00261710
00261590
00266120
00261720
NIL
LINEAR-REGRESSION(166): (pick-up-articles weight articles-vector 1)
00267730
00266090
00266680
00261590
00266310
00261720
00261620
00266050
00266100
00265120
NIL
LINEAR-REGRESSION(167): (pick-up-articles weight articles-vector 2)
00264920
00265180
00264850
00265920
00266820
00264470
00265250
00265420
00264600
00264340
NIL
LINEAR-REGRESSION(168): (pick-up-articles weight articles-vector 3)
00266020
00265970
00266090
00265950
00266250
00266350
00266040
00264850
00266310
00264920
NIL
LINEAR-REGRESSION(169): (pick-up-articles weight articles-vector 4)
00266180
00266310
00266250
00266120
00266090
00266160
00266070
00266350
00266230
00266820
NIL


・特徴の数を2にしたケースでのNMF分析結果。

LINEAR-REGRESSION(176): (pick-up-words feature words 0)
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
#<DIMENSION NAME: クラブ, TYPE: NUMERIC, INDEX: 596.>
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>
#<DIMENSION NAME: 選手, TYPE: NUMERIC, INDEX: 647.>
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>
NIL
LINEAR-REGRESSION(177): (pick-up-words feature words 1)
#<DIMENSION NAME: 東京, TYPE: NUMERIC, INDEX: 410.>
#<DIMENSION NAME: 美術館, TYPE: NUMERIC, INDEX: 1044.>
#<DIMENSION NAME: 福岡, TYPE: NUMERIC, INDEX: 361.>
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>
#<DIMENSION NAME: ３月, TYPE: NUMERIC, INDEX: 890.>
#<DIMENSION NAME: ５月, TYPE: NUMERIC, INDEX: 75.>
#<DIMENSION NAME: ４月, TYPE: NUMERIC, INDEX: 1094.>
#<DIMENSION NAME: ８月, TYPE: NUMERIC, INDEX: 703.>
#<DIMENSION NAME: 美術, TYPE: NUMERIC, INDEX: 641.>
#<DIMENSION NAME: 国立, TYPE: NUMERIC, INDEX: 427.>
NIL
LINEAR-REGRESSION(178): (pick-up-articles weight articles-vector 0)
00266020
00265970
00266090
00264920
00264850
00265920
00265180
00266190
00266310
00266180
NIL
LINEAR-REGRESSION(179): (pick-up-articles weight articles-vector 1)
00267730
00266090
00266680
00261590
00266310
00261720
00261620
00266050
00266100
00265120
NIL


・特徴の数を10にしたケースでのNMFとその分析結果

LINEAR-REGRESSION(196): (result-words feature words)
Feature 0
#<DIMENSION NAME: 長野, TYPE: NUMERIC, INDEX: 980.>
#<DIMENSION NAME: ジュニア, TYPE: NUMERIC, INDEX: 813.>
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>
#<DIMENSION NAME: イーグル, TYPE: NUMERIC, INDEX: 1133.>
#<DIMENSION NAME: チーム, TYPE: NUMERIC, INDEX: 697.>
#<DIMENSION NAME: 軽井沢, TYPE: NUMERIC, INDEX: 178.>
#<DIMENSION NAME: スキー, TYPE: NUMERIC, INDEX: 968.>
#<DIMENSION NAME: 甲府, TYPE: NUMERIC, INDEX: 1120.>
#<DIMENSION NAME: 小学生, TYPE: NUMERIC, INDEX: 488.>
#<DIMENSION NAME: ＪＲ, TYPE: NUMERIC, INDEX: 1180.>
Feature 1
#<DIMENSION NAME: 浜松, TYPE: NUMERIC, INDEX: 166.>
#<DIMENSION NAME: 静岡, TYPE: NUMERIC, INDEX: 816.>
#<DIMENSION NAME: 北, TYPE: NUMERIC, INDEX: 730.>
#<DIMENSION NAME: 西, TYPE: NUMERIC, INDEX: 586.>
#<DIMENSION NAME: 南, TYPE: NUMERIC, INDEX: 689.>
#<DIMENSION NAME: 学園, TYPE: NUMERIC, INDEX: 42.>
#<DIMENSION NAME: 中央, TYPE: NUMERIC, INDEX: 392.>
#<DIMENSION NAME: 沼津, TYPE: NUMERIC, INDEX: 592.>
#<DIMENSION NAME: 加藤, TYPE: NUMERIC, INDEX: 1186.>
#<DIMENSION NAME: 磐田, TYPE: NUMERIC, INDEX: 117.>
Feature 2
#<DIMENSION NAME: 東京, TYPE: NUMERIC, INDEX: 410.>
#<DIMENSION NAME: 美術館, TYPE: NUMERIC, INDEX: 1044.>
#<DIMENSION NAME: 福岡, TYPE: NUMERIC, INDEX: 361.>
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>
#<DIMENSION NAME: ３月, TYPE: NUMERIC, INDEX: 890.>
#<DIMENSION NAME: ５月, TYPE: NUMERIC, INDEX: 75.>
#<DIMENSION NAME: ４月, TYPE: NUMERIC, INDEX: 1094.>
#<DIMENSION NAME: ８月, TYPE: NUMERIC, INDEX: 703.>
#<DIMENSION NAME: 美術, TYPE: NUMERIC, INDEX: 641.>
#<DIMENSION NAME: ７月, TYPE: NUMERIC, INDEX: 472.>
Feature 3
#<DIMENSION NAME: 新潟, TYPE: NUMERIC, INDEX: 29.>
#<DIMENSION NAME: 豊栄, TYPE: NUMERIC, INDEX: 1113.>
#<DIMENSION NAME: 小千谷, TYPE: NUMERIC, INDEX: 120.>
#<DIMENSION NAME: 渡辺, TYPE: NUMERIC, INDEX: 429.>
#<DIMENSION NAME: 東京, TYPE: NUMERIC, INDEX: 410.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
#<DIMENSION NAME: 長岡, TYPE: NUMERIC, INDEX: 686.>
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>
#<DIMENSION NAME: 南, TYPE: NUMERIC, INDEX: 689.>
Feature 4
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>
#<DIMENSION NAME: 仙台, TYPE: NUMERIC, INDEX: 898.>
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>
#<DIMENSION NAME: 佐々木, TYPE: NUMERIC, INDEX: 671.>
#<DIMENSION NAME: 伊藤, TYPE: NUMERIC, INDEX: 130.>
#<DIMENSION NAME: 協会, TYPE: NUMERIC, INDEX: 534.>
#<DIMENSION NAME: 鈴木, TYPE: NUMERIC, INDEX: 199.>
#<DIMENSION NAME: 宮城, TYPE: NUMERIC, INDEX: 844.>
#<DIMENSION NAME: 加藤, TYPE: NUMERIC, INDEX: 1186.>
Feature 5
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 660.>
#<DIMENSION NAME: ブロック, TYPE: NUMERIC, INDEX: 141.>
#<DIMENSION NAME: 市役所, TYPE: NUMERIC, INDEX: 921.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: 横浜, TYPE: NUMERIC, INDEX: 408.>
#<DIMENSION NAME: 県, TYPE: NUMERIC, INDEX: 260.>
#<DIMENSION NAME: 鎌倉, TYPE: NUMERIC, INDEX: 345.>
#<DIMENSION NAME: 総合, TYPE: NUMERIC, INDEX: 1035.>
#<DIMENSION NAME: 高校, TYPE: NUMERIC, INDEX: 1132.>
Feature 6
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 796.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 837.>
#<DIMENSION NAME: 選手, TYPE: NUMERIC, INDEX: 647.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>
#<DIMENSION NAME: スピード, TYPE: NUMERIC, INDEX: 435.>
#<DIMENSION NAME: 予選, TYPE: NUMERIC, INDEX: 391.>
#<DIMENSION NAME: 山梨学院大, TYPE: NUMERIC, INDEX: 685.>
Feature 7
#<DIMENSION NAME: 鶴岡, TYPE: NUMERIC, INDEX: 72.>
#<DIMENSION NAME: 酒田, TYPE: NUMERIC, INDEX: 864.>
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>
#<DIMENSION NAME: 水泳, TYPE: NUMERIC, INDEX: 1070.>
#<DIMENSION NAME: 山形, TYPE: NUMERIC, INDEX: 398.>
#<DIMENSION NAME: 教室, TYPE: NUMERIC, INDEX: 510.>
#<DIMENSION NAME: 天童, TYPE: NUMERIC, INDEX: 301.>
#<DIMENSION NAME: 庄司, TYPE: NUMERIC, INDEX: 76.>
#<DIMENSION NAME: リレー, TYPE: NUMERIC, INDEX: 433.>
#<DIMENSION NAME: メドレー, TYPE: NUMERIC, INDEX: 167.>
Feature 8
#<DIMENSION NAME: 日立, TYPE: NUMERIC, INDEX: 333.>
#<DIMENSION NAME: 友, TYPE: NUMERIC, INDEX: 526.>
#<DIMENSION NAME: 茨城, TYPE: NUMERIC, INDEX: 1155.>
#<DIMENSION NAME: 水戸, TYPE: NUMERIC, INDEX: 774.>
#<DIMENSION NAME: 鈴木, TYPE: NUMERIC, INDEX: 199.>
#<DIMENSION NAME: 茨城大, TYPE: NUMERIC, INDEX: 873.>
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 591.>
#<DIMENSION NAME: クラブ, TYPE: NUMERIC, INDEX: 596.>
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 127.>
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 353.>
Feature 9
#<DIMENSION NAME: クラブ, TYPE: NUMERIC, INDEX: 596.>
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 468.>
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 737.>
#<DIMENSION NAME: 盛岡, TYPE: NUMERIC, INDEX: 866.>
#<DIMENSION NAME: 青森, TYPE: NUMERIC, INDEX: 623.>
#<DIMENSION NAME: 卓球, TYPE: NUMERIC, INDEX: 895.>
#<DIMENSION NAME: 体育館, TYPE: NUMERIC, INDEX: 214.>
#<DIMENSION NAME: トーナメント, TYPE: NUMERIC, INDEX: 855.>
#<DIMENSION NAME: 江刈, TYPE: NUMERIC, INDEX: 276.>
#<DIMENSION NAME: 中部, TYPE: NUMERIC, INDEX: 598.>
NIL
LINEAR-REGRESSION(197): (result-articles weight articles-vector)
Feature 0
00266100-「第１６回ジュニア親善アイスホッケー長野大会」
00266120-「テニス、県冬季室内ジュニア大会ダブルス（２７、２８日、松本市南部屋内運動場）」
00266250
00266230
00266680
00266350
00266150
00265960
00263050
00266330
Feature 1
00266180
00266250
00266120
00266160
00266820
00266230
00266070
00266150
00266170
00265250
Feature 2
00267730
00266680
00261590
00261620
00261720
00265120
00266050
00267320
00267810
00265920
Feature 3
00266090
00266350
00266120
00265920
00266070
00261620
00265420
00266250
00266280
00261740
Feature 4
00266020
00265950
00266250
00264850
00264920
00265920
00266820
00266940
00266070
00261590
Feature 5
00266310
00266350
00266070
00261710
00266250
00261720
00266230
00266030
00261590
00266680
Feature 6
00264920
00265180
00264850
00265920
00266820
00264470
00265420
00265250
00264600
00264340
Feature 7
00266040-「水泳、鶴岡市民プール」
00264620
00264600
00261590
00266350
00264650
00265120
00264340
00261620
00264470
Feature 8
00266190
00266350
00266070
00265180
00266120
00265120
00266280
00266260
00265060
00266820
Feature 9
00265970
00265950
00264920
00266350
00265920
00264850
00264340
00266940
00266080
00266250
NIL


・特徴行列の各列は各特徴を基底とした際の、各単語の座標を表している。特徴数をkとすれば、
各単語はk次元ユークリッド空間内の点と同一視でき、単語間にユークリッド距離が定義できる。
この距離は、与えられた記事-単語行列における単語間の関連性を示すものと解釈することが可能である。
このアイディアに基づき、ある単語と近い単語を拾ってくる関数を実装した。(9/4)。

実行結果1-「静岡」と近い単語(右の数字は「静岡」と各単語の距離である)。

LINEAR-REGRESSION(107): (pick-up-similar-words (make-word-distance-matrix feature) words 738)
#<DIMENSION NAME: 静岡, TYPE: NUMERIC, INDEX: 738.>    0.0
#<DIMENSION NAME: 浜松, TYPE: NUMERIC, INDEX: 150.>    0.2895603481419302
#<DIMENSION NAME: 学園, TYPE: NUMERIC, INDEX: 37.>    1.8540210447782586
#<DIMENSION NAME: 中央, TYPE: NUMERIC, INDEX: 359.>    1.9251551607922905
#<DIMENSION NAME: 沼津, TYPE: NUMERIC, INDEX: 538.>    2.0074647558239436
#<DIMENSION NAME: 磐田, TYPE: NUMERIC, INDEX: 104.>    2.087376556797266
#<DIMENSION NAME: 加藤, TYPE: NUMERIC, INDEX: 1073.>    2.094576453734966
#<DIMENSION NAME: 市立, TYPE: NUMERIC, INDEX: 976.>    2.1393037014663316
#<DIMENSION NAME: 三島, TYPE: NUMERIC, INDEX: 995.>    2.167423299633494
#<DIMENSION NAME: 富士, TYPE: NUMERIC, INDEX: 453.>    2.1681552689297905


実行結果2-「決勝」と近い単語。

LINEAR-REGRESSION(108): (pick-up-similar-words (make-word-distance-matrix feature) words 431)
18871872 bytes have been tenured, next gc will be global.
See the documentation for variable EXCL:*GLOBAL-GC-BEHAVIOR* for more information.
#<DIMENSION NAME: 決勝, TYPE: NUMERIC, INDEX: 431.>    0.0
#<DIMENSION NAME: 準決勝, TYPE: NUMERIC, INDEX: 673.>    1.6938026991826487
#<DIMENSION NAME: 男子, TYPE: NUMERIC, INDEX: 537.>    1.762343622665731
#<DIMENSION NAME: 女子, TYPE: NUMERIC, INDEX: 327.>    1.9516950090048275
#<DIMENSION NAME: クラブ, TYPE: NUMERIC, INDEX: 542.>    2.6121491500934737
#<DIMENSION NAME: 大会, TYPE: NUMERIC, INDEX: 605.>    2.728595011493942
#<DIMENSION NAME: 少年, TYPE: NUMERIC, INDEX: 724.>    2.854669410630615
#<DIMENSION NAME: 選手, TYPE: NUMERIC, INDEX: 592.>    2.8588445988287488
#<DIMENSION NAME: 佐藤, TYPE: NUMERIC, INDEX: 115.>    2.8667545595208366
#<DIMENSION NAME: 成年, TYPE: NUMERIC, INDEX: 756.>    2.877692723445677


他の記事-単語行列（政治分野）での実行例。

実行結果3-「民主党」と近い単語。

#<DIMENSION NAME: 民主党, TYPE: NUMERIC, INDEX: 515.>    0.0
#<DIMENSION NAME: 代表, TYPE: NUMERIC, INDEX: 194.>    0.46894772827810527
#<DIMENSION NAME: 小沢, TYPE: NUMERIC, INDEX: 310.>    1.0355924427491712
#<DIMENSION NAME: 推薦, TYPE: NUMERIC, INDEX: 580.>    1.1032521210904218
#<DIMENSION NAME: 県連, TYPE: NUMERIC, INDEX: 548.>    1.1324499709545732
#<DIMENSION NAME: 候補, TYPE: NUMERIC, INDEX: 391.>    1.234786590801039
#<DIMENSION NAME: 党, TYPE: NUMERIC, INDEX: 846.>    1.2398647871052257
#<DIMENSION NAME: 辞任, TYPE: NUMERIC, INDEX: 177.>    1.265715791212841
#<DIMENSION NAME: 公認, TYPE: NUMERIC, INDEX: 638.>    1.2660509504658546
#<DIMENSION NAME: 県議, TYPE: NUMERIC, INDEX: 150.>    1.2704275415985349


実行結果4-「自民党」と近い単語。

#<DIMENSION NAME: 自民党, TYPE: NUMERIC, INDEX: 822.>    0.0
#<DIMENSION NAME: 経団連, TYPE: NUMERIC, INDEX: 10.>    1.0980580045730688
#<DIMENSION NAME: 献金, TYPE: NUMERIC, INDEX: 206.>    1.153344662956514
#<DIMENSION NAME: 会長, TYPE: NUMERIC, INDEX: 562.>    1.161855490293435
#<DIMENSION NAME: 団体, TYPE: NUMERIC, INDEX: 661.>    1.2314470304313299
#<DIMENSION NAME: 財界, TYPE: NUMERIC, INDEX: 597.>    1.2956040164272886
#<DIMENSION NAME: 資金, TYPE: NUMERIC, INDEX: 793.>    1.4099663323153833
#<DIMENSION NAME: 支援, TYPE: NUMERIC, INDEX: 139.>    1.4179124599650397
#<DIMENSION NAME: 銀行, TYPE: NUMERIC, INDEX: 828.>    1.4255887076187517
#<DIMENSION NAME: 党, TYPE: NUMERIC, INDEX: 846.>    1.4673332763445661


・重み行列の各行は、各特徴を基底とした際の、各記事の座標を表している。
したがって、記事間の距離も同様に定義することができる。そこで、距離的に近い記事を拾ってくる関数を実装した（9/4）。

実行例1

LINEAR-REGRESSION(164): (pick-up-similar-articles (make-article-distance-matrix weight) article-id 0)
00240250    0.0
00251030    0.3313524521728975
00249880    0.4062109001520689
00253500    0.41283133660030763
00249070    0.5177425193748424
00249170    0.5187746873880595
00233800    0.6410562095437863
00262390    0.6467955800182887
00264070    0.6468569295450186
00263650    0.7429697060464135

この結果からすると、記事240250に対して、記事251030が距離0.331で全記事中もっとも近くに位置していることがわかる。

<記事240250>
参院副議長後任　江田氏軸に最終調整／民主党
　民主党は２９日午前、辞任を表明した角田義一参院副議長の後任人事について、江田五月・元科学技術庁長官（６５）を軸に最終調整に入った。２９日午後の参院常任役員会などを経て内定し、３０日午前の参院本会議で正式に選出される見通しだ。
　江田氏は、判事補出身。政策通で知られるとともに、党副代表や党参院議員会長などを歴任し、与野党にも幅広い人脈を持つことなどから、副議長に有力となった。現在は党倫理委員長を務めている。
　参院副議長は、野党第１党の民主党から選ばれることが慣例になっている。

<記事251030>
参院幹事長に小川敏夫氏昇格／民主党
　民主党は２９日、参院副議長に内定した今泉昭参院幹事長の後任に、小川敏夫参院幹事長代理（５８）を昇格させることを決めた。輿石東参院議員会長が参院議員総会で指名し、了承された。

　◇小川敏夫氏（おがわ・としお）東京選挙区。当選２回。東京地検検事、立教大講師。立教大卒。

　写真＝小川敏夫氏


実行例2

LINEAR-REGRESSION(165): (pick-up-similar-articles (make-article-distance-matrix weight) article-id 1)
00240260    0.0
00240860    0.15144413134967
00235100    0.24933966424880935
00232740    0.25123469789665787
00262340    0.2663322334336288
00233740    0.2821782946632389
00233660    0.30116689142442754
00234430    0.3072568209537702
00233800    0.31548767142913836
00264130    0.3378504338010126
NIL

記事240260に対して、全記事中もっとも近いのは記事240860である。

<記事240260>
米大統領選　ヒラリー氏、当選なら夫を積極登用　人気あやかり戦略
　【ダベンポート（米アイオワ州東部）＝五十嵐文】２００８年の次期米大統領選に挑む民主党のヒラリー・クリントン上院議員（５９）＝写真上、ＡＰ＝は２８日、遊説先の当地で記者会見し、大統領に就任した場合、夫のビル・クリントン前大統領（６０）＝同下、ＡＰ＝を積極的に登用する考えを明らかにした。
　クリントン議員は、ブッシュ大統領がインドネシア・スマトラ沖地震の津波被害や超大型ハリケーン「カトリーナ」被災者支援のため、大統領の父、ブッシュ元大統領とクリントン前大統領に募金集めの先頭に立つよう協力を求めたことを「すばらしい決断」と称賛。「大統領が元大統領を使うのは生産的」であり、「ヒラリー大統領」が誕生した場合には、「大統領経験者、特に私の夫の能力と経験」を政策立案・遂行のため積極的に活用する考えを強調した。
　クリントン議員は大統領夫人時代、クリントン前大統領から医療制度改革の旗振り役に任命され、「ファーストレディー」としては異例の政策への関与が話題を呼んだ。クリントン前大統領は退任後も国民の人気が高く、夫の政界の表舞台への「再登板」を公約することで、自らの選挙戦をさらに有利にする狙いもありそうだ。

<記事240860>
「女性大統領、機は熟した」　ヒラリー氏、遊説開始／米アイオワ州
　【デモイン（米アイオワ州）＝五十嵐文】２００８年の次期米大統領選への立候補を表明した民主党のヒラリー・クリントン上院議員は２７日、出馬表明後初めてとなる大規模な有権者との対話集会を、アイオワ州の州都デモインで開き、本格的な遊説を開始した。クリントン議員は集会で、「女性大統領が誕生してもいいころだ」と述べ、米史上初となる女性大統領誕生への機は熟しているとの見方を示し、勝利に向けた強い決意を表明した。
　クリントン議員は約１０００人の聴衆を前に、大統領を目指す意欲を前面に打ち出し、米社会に男性優位という壁が依然として残るものの、「挑戦するつもりだ」と語り、有権者の支持を訴えた。
　アイオワ州では来年１月、全米のトップを切って、共和、民主両党の党員集会が行われ、結果は大統領候補指名争いに大きな影響を与える。
　大統領選には、民主９人、共和１０人の有力政治家が立候補表明するか、出馬を見極めるための準備委員会を設立している。〈関連記事４面〉

　写真＝２７日、米アイオワ州で開かれた対話集会で演説するクリントン上院議員（ＡＰ）



(考察)

・重み行列は、記事の集合が形作るk次元ベクトル空間内の図形に、特徴行列は、単語の集合が形作るk次元ベクトル空間内の図形とみなせる。
したがって、これらの図形が可視化できると面白い。また、これら図形の幾何的性質から何か導出できないか。k=2,3ならそのままグラフに
描くこともできる。

・目下気になっているのは、特徴数kの適切な設定の規準である。記事図形や単語図形の幾何的性質ないしは情報量のようなものから
逆にkが決められると面白い。k=2では潰れすぎであろうし、逆に大きすぎるkは次元を増やしても幾何的性質や情報量が増えないと考えられる。

・記事-単語行列のNMFに限って言えば、ここで表れる行列は殆どの成分がゼロのスパースな行列であるため、その性質を利用した高速な分解が
（もし可能なら）できると良い。


・"Document Clustering Based On Non-negative Matrix Factorization"(Wei Xu, Xin Liu, Yihong Gong)という論文に
基づいて、正規化されたNMFを実装して検証した。正規化されたNMFとは、重み行列の各列の長さが1になるように、
重み行列と特徴行列を補正したものである。正規化によってNMF自体は一意にはならないが、表れる特徴は同種のものが出現する。
正規化されたNMFを用いれば、ランダムに設定する初期値に依らずに、(ほぼ)同一のクラスタリング結果を
毎回得ることができる。なお、クラスタリングの方法は各記事・各単語において最大の大きさの特徴グループに帰属させる（9/7）。

・上の記述は誤りで、特徴の数kがある程度大きくなると破綻することが分かった（9/8）。

・単語と記事を各特徴のクラスタに分類する関数を実装した（9/8）。


(9/29)NMF

"Metagenes and molecular pattern discovery using matrix factorization"の内容を、
政治分野の80記事、849単語の行列で試し、各kについてrho_k(C^bar)を計算した。なお、average consensus matrix を
計算する際の反復回数は50回である。k=6で値が落ち込むものの、k=7では再び上昇に転じている。

PRE-NMF(23): (rho-k matrix 2)
0.9999709802645134

PRE-NMF(24): (rho-k matrix 3)
0.9998817204625452

PRE-NMF(25): (rho-k matrix 4)
0.9552129825052409

PRE-NMF(28): (rho-k matrix 5)
0.9299251834042924

PRE-NMF(29): (rho-k matrix 6)
0.8969703807976694

PRE-NMF(31): (rho-k matrix 7)
0.9259224230877287

PRE-NMF(33): (rho-k matrix 8)
0.9500035726991295

PRE-NMF(34): (rho-k matrix 9)
0.9474790873550318

PRE-NMF(37): (rho-k matrix 10)
0.9182725360788816


スポーツ関係記事100記事、1202単語でのrho-kの値の変化

PRE-NMF(51): (rho-k matrix 2)
1.0

PRE-NMF(52): (rho-k matrix 3)
0.9400174938545344

PRE-NMF(53): (rho-k matrix 4)
0.8856559188604354

PRE-NMF(54): (rho-k matrix 5)
0.986246080659728

PRE-NMF(55): (rho-k matrix 6)
0.976698772046135

PRE-NMF(56): (rho-k matrix 7)
0.9871857979467507


参考：ランダムに生成した行列(100*100行列)でのrho-kの値の変化

PRE-NMF(53): (rho-k test 2)
0.6575766396030658

PRE-NMF(54): (rho-k test 3)
0.7107913031212324

PRE-NMF(55): (rho-k test 4)
0.6364341226175744

PRE-NMF(56): (rho-k test 5)
0.6424937326351395

PRE-NMF(57): (rho-k test 6)
0.659165787665558

PRE-NMF(58): (rho-k test 7)
0.6436081020008851

PRE-NMF(59): (rho-k test 8)
0.6160311944187843




C.階層型クラスタリング

・Rとの照合結果。群平均法(average)におけるコーフェン行列とコーフェン相関係数。

HC(388): distance-matrix
#2A((0.0 68.65857557508748 33.77869150810907 60.13318551349163 28.478061731796284 63.37191807101944
     67.88225099390856)
    (68.65857557508748 0.0 81.11103500757464 64.1404708432983 60.753600716336145 12.409673645990857
     38.1051177665153)
    (33.77869150810907 81.11103500757464 0.0 52.67826876426369 21.307275752662516 75.66372975210778
     87.53856293085921)
    (60.13318551349163 64.1404708432983 52.67826876426369 0.0 47.10626285325551 54.31390245600108
     91.53141537199127)
    (28.478061731796284 60.753600716336145 21.307275752662516 47.10626285325551 0.0 56.382621436041795
     67.72739475278819)
    (63.37191807101944 12.409673645990857 75.66372975210778 54.31390245600108 56.382621436041795 0.0
     45.58508528016593)
    (67.88225099390856 38.1051177665153 87.53856293085921 91.53141537199127 67.72739475278819
     45.58508528016593 0.0))
HC(389): (cophenetic-matrix distance-matrix)
#2A((0.0 69.92295649225116 31.128376619952675 53.30590571033695 31.128376619952675 69.92295649225116
     69.92295649225116)
    (69.92295649225116 0.0 69.92295649225116 69.92295649225116 69.92295649225116 12.409673645990857
     41.84510152334062)
    (31.128376619952675 69.92295649225116 0.0 53.30590571033695 21.307275752662516 69.92295649225116
     69.92295649225116)
    (53.30590571033695 69.92295649225116 53.30590571033695 0.0 53.30590571033695 69.92295649225116
     69.92295649225116)
    (31.128376619952675 69.92295649225116 21.307275752662516 53.30590571033695 0.0 69.92295649225116
     69.92295649225116)
    (69.92295649225116 12.409673645990857 69.92295649225116 69.92295649225116 69.92295649225116 0.0
     41.84510152334062)
    (69.92295649225116 41.84510152334062 69.92295649225116 69.92295649225116 69.92295649225116
     41.84510152334062 0.0))
#2A((-5 -1) (-4 -2) (2 0) (-6 1) (3 -3) (4 5))
HC(390): (cophenetic-cc distance-matrix (cophenetic-matrix distance-matrix))
0.9001070791369229

> seiseki.d
         田中     佐藤     鈴木     本田     川端     吉野
佐藤 68.65858                                             
鈴木 33.77869 81.11104                                    
本田 60.13319 64.14047 52.67827                           
川端 28.47806 60.75360 21.30728 47.10626                  
吉野 63.37192 12.40967 75.66373 54.31390 56.38262         
斎藤 67.88225 38.10512 87.53856 91.53142 67.72739 45.58509
> cophenetic(average)
         田中     佐藤     鈴木     本田     川端     吉野
佐藤 69.92296                                             
鈴木 31.12838 69.92296                                    
本田 53.30591 69.92296 53.30591                           
川端 31.12838 69.92296 21.30728 53.30591                  
吉野 69.92296 12.40967 69.92296 69.92296 69.92296         
斎藤 69.92296 41.84510 69.92296 69.92296 69.92296 41.84510
> cor(seiseki.d, cophenetic(average))
[1] 0.900107


・最近隣法(single)

HC(391): (cophenetic-matrix distance-matrix #'single)
#2A((0.0 54.31390245600109 28.47806173179628 47.106262853255515 28.47806173179628 54.31390245600109
     54.31390245600109)
    (54.31390245600109 0.0 54.31390245600109 54.31390245600109 54.31390245600109 12.409673645990857
     38.105117766515306)
    (28.47806173179628 54.31390245600109 0.0 47.106262853255515 21.307275752662516 54.31390245600109
     54.31390245600109)
    (47.106262853255515 54.31390245600109 47.106262853255515 0.0 47.106262853255515 54.31390245600109
     54.31390245600109)
    (28.47806173179628 54.31390245600109 21.307275752662516 47.106262853255515 0.0 54.31390245600109
     54.31390245600109)
    (54.31390245600109 12.409673645990857 54.31390245600109 54.31390245600109 54.31390245600109 0.0
     38.105117766515306)
    (54.31390245600109 38.105117766515306 54.31390245600109 54.31390245600109 54.31390245600109
     38.105117766515306 0.0))
#2A((-5 -1) (-4 -2) (2 0) (-6 1) (3 -3) (4 5))
HC(392): (cophenetic-cc distance-matrix (cophenetic-matrix distance-matrix #'single))
0.8915766971886213

> cophenetic(single)
         田中     佐藤     鈴木     本田     川端     吉野
佐藤 54.31390                                             
鈴木 28.47806 54.31390                                    
本田 47.10626 54.31390 47.10626                           
川端 28.47806 54.31390 21.30728 47.10626                  
吉野 54.31390 12.40967 54.31390 54.31390 54.31390         
斎藤 54.31390 38.10512 54.31390 54.31390 54.31390 38.10512
> cor(seiseki.d, cophenetic(single))
[1] 0.8915767


・最遠隣法(complete)

HC(393): (cophenetic-matrix distance-matrix #'complete)
#2A((0.0 91.53141537199127 33.77869150810907 60.13318551349164 33.77869150810907 91.53141537199127
     91.53141537199127)
    (91.53141537199127 0.0 91.53141537199127 91.53141537199127 91.53141537199127 12.409673645990857
     45.58508528016593)
    (33.77869150810907 91.53141537199127 0.0 60.13318551349164 21.307275752662516 91.53141537199127
     91.53141537199127)
    (60.13318551349164 91.53141537199127 60.13318551349164 0.0 60.13318551349164 91.53141537199127
     91.53141537199127)
    (33.77869150810907 91.53141537199127 21.307275752662516 60.13318551349164 0.0 91.53141537199127
     91.53141537199127)
    (91.53141537199127 12.409673645990857 91.53141537199127 91.53141537199127 91.53141537199127 0.0
     45.58508528016593)
    (91.53141537199127 45.58508528016593 91.53141537199127 91.53141537199127 91.53141537199127 45.58508528016593
     0.0))
#2A((-5 -1) (-4 -2) (2 0) (-6 1) (3 -3) (4 5))
HC(394): (cophenetic-cc distance-matrix (cophenetic-matrix distance-matrix #'complete))
0.8944868973315788

> cophenetic(complete)
         田中     佐藤     鈴木     本田     川端     吉野
佐藤 91.53142                                             
鈴木 33.77869 91.53142                                    
本田 60.13319 91.53142 60.13319                           
川端 33.77869 91.53142 21.30728 60.13319                  
吉野 91.53142 12.40967 91.53142 91.53142 91.53142         
斎藤 91.53142 45.58509 91.53142 91.53142 91.53142 45.58509
> cor(seiseki.d, cophenetic(complete))
[1] 0.8944869


・重心法(centroid)

HC(395): (cophenetic-matrix distance-matrix #'centroid)
#2A((0.0 44.02758328256393 25.801557681787045 44.02101360005163 25.801557681787045 44.02758328256393
     44.02758328256393)
    (44.02758328256393 0.0 44.02758328256393 44.02758328256393 44.02758328256393 12.409673645990857
     38.7426831118429)
    (25.801557681787045 44.02758328256393 0.0 44.02101360005163 21.307275752662516 44.02758328256393
     44.02758328256393)
    (44.02101360005163 44.02758328256393 44.02101360005163 0.0 44.02101360005163 44.02758328256393
     44.02758328256393)
    (25.801557681787045 44.02758328256393 21.307275752662516 44.02101360005163 0.0 44.02758328256393
     44.02758328256393)
    (44.02758328256393 12.409673645990857 44.02758328256393 44.02758328256393 44.02758328256393 0.0
     38.7426831118429)
    (44.02758328256393 38.7426831118429 44.02758328256393 44.02758328256393 44.02758328256393 38.7426831118429 0.0))
#2A((-5 -1) (-4 -2) (2 0) (-6 1) (3 -3) (4 5))
HC(396): (cophenetic-cc distance-matrix (cophenetic-matrix distance-matrix #'centroid))
0.8276276825126891

> cophenetic(centroid)
         田中     佐藤     鈴木     本田     川端     吉野
佐藤 44.02758                                             
鈴木 25.80156 44.02758                                    
本田 44.02101 44.02758 44.02101                           
川端 25.80156 44.02758 21.30728 44.02101                  
吉野 44.02758 12.40967 44.02758 44.02758 44.02758         
斎藤 44.02758 38.74268 44.02758 44.02758 44.02758 38.74268
> cor(seiseki.d, cophenetic(centroid))
[1] 0.8276277


・メディアン法(median)

HC(397): (cophenetic-matrix distance-matrix #'median)
#2A((0.0 45.42216730738696 25.801557681787045 45.898926771596045 25.801557681787045 45.42216730738696
     45.42216730738696)
    (45.42216730738696 0.0 45.42216730738696 45.42216730738696 45.42216730738696 12.409673645990857
     38.7426831118429)
    (25.801557681787045 45.42216730738696 0.0 45.898926771596045 21.307275752662516 45.42216730738696
     45.42216730738696)
    (45.898926771596045 45.42216730738696 45.898926771596045 0.0 45.898926771596045 45.42216730738696
     45.42216730738696)
    (25.801557681787045 45.42216730738696 21.307275752662516 45.898926771596045 0.0 45.42216730738696
     45.42216730738696)
    (45.42216730738696 12.409673645990857 45.42216730738696 45.42216730738696 45.42216730738696 0.0
     38.7426831118429)
    (45.42216730738696 38.7426831118429 45.42216730738696 45.42216730738696 45.42216730738696 38.7426831118429 0.0))
#2A((-5 -1) (-4 -2) (2 0) (-6 1) (3 -3) (4 5))
HC(398): (cophenetic-cc distance-matrix (cophenetic-matrix distance-matrix #'median))
0.8305270496918602

> cophenetic(median)
         田中     佐藤     鈴木     本田     川端     吉野
佐藤 45.42217                                             
鈴木 25.80156 45.42217                                    
本田 45.89893 45.42217 45.89893                           
川端 25.80156 45.42217 21.30728 45.89893                  
吉野 45.42217 12.40967 45.42217 45.42217 45.42217         
斎藤 45.42217 38.74268 45.42217 45.42217 45.42217 38.74268
> cor(seiseki.d, cophenetic(median))
[1] 0.830527


・ウォード法(ward)

HC(26): (cophenetic-matrix distance-matrix #'ward)
#2A((0.0 150.95171411164776 34.40207690904939 66.03152040007744 34.40207690904939 150.95171411164776
     150.95171411164776)
    (150.95171411164776 0.0 150.95171411164776 150.95171411164776 150.95171411164776 12.409673645990857
     51.65691081579053)
    (34.40207690904939 150.95171411164776 0.0 66.03152040007744 21.307275752662516 150.95171411164776
     150.95171411164776)
    (66.03152040007744 150.95171411164776 66.03152040007744 0.0 66.03152040007744 150.95171411164776
     150.95171411164776)
    (34.40207690904939 150.95171411164776 21.307275752662516 66.03152040007744 0.0 150.95171411164776
     150.95171411164776)
    (150.95171411164776 12.409673645990857 150.95171411164776 150.95171411164776 150.95171411164776 0.0
     51.65691081579053)
    (150.95171411164776 51.65691081579053 150.95171411164776 150.95171411164776 150.95171411164776
     51.65691081579053 0.0))
#2A((-5 -1) (-4 -2) (2 0) (-6 1) (3 -3) (4 5))
HC(27): (cophenetic-cc distance-matrix (cophenetic-matrix distance-matrix #'ward))
0.8627398008333016

> cophenetic(ward)
          田中      佐藤      鈴木      本田      川端      吉野
佐藤 150.95171                                                  
鈴木  34.40208 150.95171                                        
本田  66.03152 150.95171  66.03152                              
川端  34.40208 150.95171  21.30728  66.03152                    
吉野 150.95171  12.40967 150.95171 150.95171 150.95171          
斎藤 150.95171  51.65691 150.95171 150.95171 150.95171  51.65691
> cor(seiseki.d, cophenetic(ward))
[1] 0.8627398


(9/25):Rで言うところのcutree関数を実装。cutreeは階層型クラスタリングの結果に基づいて、
対象データがどのクラスタに属するのかをベクトルで示す。

例

HC(41): merge-matrix
#2A((-5 -1) (-4 -2) (2 0) (-6 1) (3 -3) (4 5))
HC(42): (cutree 4 merge-matrix)
#(2 1 2 3 2 1 4)

この場合、対象0,2,4が属するクラスタは2、対象1,5が属するクラスタは1、という風に読む。
注意点としては、クラスタ番号は1から始まる。下は全対象を二群に分ける例である。

HC(49): (cutree 2 merge-matrix)
#(2 1 2 2 2 1 1)
